{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import random\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Dropout, Lambda, Concatenate\n",
    "\n",
    "# Have to download the stopwords\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Get the fasttext model (we are using the largest one they offer [600B tokens])\n",
    "fasttext_model = fasttext.load_model('models/crawl-300d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Useful Function\n",
    "Functions that are continually used throughout this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LEN: 43 EMBEDDING_SHAPE: (300,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Definitions of some sizes in the training set\n",
    "\"\"\"\n",
    "MAX_LEN = 43\n",
    "EMBEDDING_SHAPE = (300,)\n",
    "print('MAX_LEN: ' + str(MAX_LEN), 'EMBEDDING_SHAPE: ' + str(EMBEDDING_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(df):\n",
    "    max_len = 0\n",
    "    for row in df.itertuples():\n",
    "        if len(row.title_one.split(' ')) > max_len:\n",
    "            max_len = len(row.title_one.split(' '))\n",
    "            \n",
    "        if len(row.title_two.split(' ')) > max_len:\n",
    "            max_len = len(row.title_two.split(' '))\n",
    "    \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataframe(df):\n",
    "    for idx in range(len(df)):\n",
    "        print(df.iloc[idx].title_one + '\\n' + df.iloc[idx].title_two)\n",
    "        print('________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_data(pos_df, neg_df):\n",
    "    pos_df.sample(frac=1)\n",
    "    neg_df.sample(frac=1)\n",
    "    final_df = pd.concat([pos_df[:min(len(pos_df), len(neg_df))], neg_df[:min(len(pos_df), len(neg_df))]])\n",
    "    final_df = final_df.sample(frac=1)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(phrase):\n",
    "    # Creates the stopwords\n",
    "    to_stop = stopwords.words('english')\n",
    "    punctuation = \"!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~ \"\n",
    "    for c in punctuation:\n",
    "        to_stop.append(c)\n",
    "\n",
    "    to_stop.append('null')\n",
    "    \n",
    "    for punc in punctuation:\n",
    "        phrase = phrase.replace(punc, ' ')\n",
    "    \n",
    "    return ' '.join((' '.join([x for x in phrase.split(' ') if x not in to_stop])).split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processsing and Organization\n",
    "Here, all we really want to do is prepare the data for training. This is **only** the data from **Gold Standard** This includes:\n",
    "* Simplifying the original data\n",
    "* Normalizing the data \n",
    "* Balancing the positive and negative examples\n",
    "* Creating the embedding representations that will actually get fed into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing and normalizing the data\n",
    "\"\"\"\n",
    "Essentially, we want to only have three attributes for each training example: title_one, title_two, label\n",
    "For normalization, we are just going to use the nltk stopwords and punctuation\n",
    "\"\"\"\n",
    "\n",
    "def preprocessing(orig_data):\n",
    "    \"\"\"\n",
    "    Normalizes the data by getting rid of stopwords and punctuation\n",
    "    \"\"\"\n",
    "    \n",
    "    # The new names of the columns\n",
    "    column_names = ['title_one', 'title_two', 'label']\n",
    "    # A new dataframe for the data we are going to be creating\n",
    "    norm_data = pd.DataFrame(columns = column_names)\n",
    "    # Iterate over the original dataframe (I know it is slow and there are probably better ways to do it)\n",
    "    iloc_data = orig_data.iloc\n",
    "    for idx in tqdm(range(len(orig_data))):\n",
    "        row = iloc_data[idx]\n",
    "        title_left = remove_stop_words(row.title_left)\n",
    "        title_right = remove_stop_words(row.title_right)\n",
    "        \n",
    "        # Append the newly created row (title_left, title_right, label) to the new dataframe\n",
    "        norm_data = norm_data.append(pd.DataFrame([[title_left, title_right, row.label]], columns=column_names))\n",
    "    \n",
    "    return norm_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_df(df):\n",
    "    \"\"\"\n",
    "    Returns a shuffled dataframe with an equal amount of positive and negative examples\n",
    "    \"\"\"\n",
    "    # Get the positive and negative examples\n",
    "    pos_df = df.loc[df['label'] == 1]\n",
    "    neg_df = df.loc[df['label'] == 0]\n",
    "    \n",
    "    # Shuffle the data\n",
    "    pos_df = pos_df.sample(frac=1)\n",
    "    neg_df = neg_df.sample(frac=1)\n",
    "    \n",
    "    # Concatenate the positive and negative examples and \n",
    "    # make sure there are only as many negative examples as positive examples\n",
    "    final_df = pd.concat([pos_df[:min(len(pos_df), len(neg_df))], neg_df[:min(len(pos_df), len(neg_df))]])\n",
    "    \n",
    "    # Shuffle the final data once again\n",
    "    final_df.sample(frac=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(df, path):\n",
    "    \"\"\"\n",
    "    Creates and saves a simpler version of the original data that only contains the the two titles and the label.\n",
    "    \"\"\"\n",
    "    \n",
    "    norm_bal_data = create_train_df(preprocessing(df))\n",
    "    \n",
    "    # Save the new normalized and simplified data to a CSV file to load later\n",
    "    norm_bal_data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "computer_df = pd.read_json('data/train/computers_train_xlarge_normalized.json.gz', compression='gzip', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See some of the data. There is clearly a separation between the positive and negative examples\n",
    "computer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the data if the simple and normalized data does not exist\n",
    "computer_data_path = 'data/train/computers_train_bal_shuffle.csv'\n",
    "\n",
    "# If the computer data has not been made yet, make it\n",
    "if not os.path.exists(computer_data_path):\n",
    "    create_training_data(computer_df, computer_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cameras data\n",
    "camera_df = pd.read_json('data/train/cameras_train_xlarge_normalized.json.gz', compression='gzip', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the data if the simple and normalized data does not exist\n",
    "camera_data_path = 'data/train/cameras_train_bal_shuffle.csv'\n",
    "\n",
    "# If the computer data has not been made yet, make it\n",
    "if not os.path.exists(camera_data_path):\n",
    "    create_training_data(camera_df, camera_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_computer_df = pd.read_csv('data/train/computers_train_bal_shuffle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_computer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_camera_df = pd.read_csv('data/train/cameras_train_bal_shuffle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_camera_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptop Data Preprocessing\n",
    "* Normalize the data\n",
    "* Create negative examples that represent when only a couple of attributes of the laptop data changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the laptop data\n",
    "laptop_df = pd.read_csv('data/train/laptops.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Inches</th>\n",
       "      <th>ScreenResolution</th>\n",
       "      <th>Cpu</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Gpu</th>\n",
       "      <th>OpSys</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price_euros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>IPS Panel Retina Display 2560x1600</td>\n",
       "      <td>Intel Core i5 2.3GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>128GB SSD</td>\n",
       "      <td>Intel Iris Plus Graphics 640</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.37kg</td>\n",
       "      <td>1339.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Macbook Air</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1440x900</td>\n",
       "      <td>Intel Core i5 1.8GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>128GB Flash Storage</td>\n",
       "      <td>Intel HD Graphics 6000</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.34kg</td>\n",
       "      <td>898.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HP</td>\n",
       "      <td>250 G6</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>Full HD 1920x1080</td>\n",
       "      <td>Intel Core i5 7200U 2.5GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>256GB SSD</td>\n",
       "      <td>Intel HD Graphics 620</td>\n",
       "      <td>No OS</td>\n",
       "      <td>1.86kg</td>\n",
       "      <td>575.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>15.4</td>\n",
       "      <td>IPS Panel Retina Display 2880x1800</td>\n",
       "      <td>Intel Core i7 2.7GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>512GB SSD</td>\n",
       "      <td>AMD Radeon Pro 455</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.83kg</td>\n",
       "      <td>2537.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>IPS Panel Retina Display 2560x1600</td>\n",
       "      <td>Intel Core i5 3.1GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>256GB SSD</td>\n",
       "      <td>Intel Iris Plus Graphics 650</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.37kg</td>\n",
       "      <td>1803.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1316</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>Yoga 500-14ISK</td>\n",
       "      <td>2 in 1 Convertible</td>\n",
       "      <td>14.0</td>\n",
       "      <td>IPS Panel Full HD / Touchscreen 1920x1080</td>\n",
       "      <td>Intel Core i7 6500U 2.5GHz</td>\n",
       "      <td>4GB</td>\n",
       "      <td>128GB SSD</td>\n",
       "      <td>Intel HD Graphics 520</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.8kg</td>\n",
       "      <td>638.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1317</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>Yoga 900-13ISK</td>\n",
       "      <td>2 in 1 Convertible</td>\n",
       "      <td>13.3</td>\n",
       "      <td>IPS Panel Quad HD+ / Touchscreen 3200x1800</td>\n",
       "      <td>Intel Core i7 6500U 2.5GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>512GB SSD</td>\n",
       "      <td>Intel HD Graphics 520</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.3kg</td>\n",
       "      <td>1499.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1318</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>IdeaPad 100S-14IBR</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Celeron Dual Core N3050 1.6GHz</td>\n",
       "      <td>2GB</td>\n",
       "      <td>64GB Flash Storage</td>\n",
       "      <td>Intel HD Graphics</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.5kg</td>\n",
       "      <td>229.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1319</td>\n",
       "      <td>HP</td>\n",
       "      <td>15-AC110nv (i7-6500U/6GB/1TB/Radeon</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Core i7 6500U 2.5GHz</td>\n",
       "      <td>6GB</td>\n",
       "      <td>1TB HDD</td>\n",
       "      <td>AMD Radeon R5 M330</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.19kg</td>\n",
       "      <td>764.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1320</td>\n",
       "      <td>Asus</td>\n",
       "      <td>X553SA-XX031T (N3050/4GB/500GB/W10)</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Celeron Dual Core N3050 1.6GHz</td>\n",
       "      <td>4GB</td>\n",
       "      <td>500GB HDD</td>\n",
       "      <td>Intel HD Graphics</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.2kg</td>\n",
       "      <td>369.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Company                              Product  \\\n",
       "0              1   Apple                          MacBook Pro   \n",
       "1              2   Apple                          Macbook Air   \n",
       "2              3      HP                               250 G6   \n",
       "3              4   Apple                          MacBook Pro   \n",
       "4              5   Apple                          MacBook Pro   \n",
       "...          ...     ...                                  ...   \n",
       "1298        1316  Lenovo                       Yoga 500-14ISK   \n",
       "1299        1317  Lenovo                       Yoga 900-13ISK   \n",
       "1300        1318  Lenovo                   IdeaPad 100S-14IBR   \n",
       "1301        1319      HP  15-AC110nv (i7-6500U/6GB/1TB/Radeon   \n",
       "1302        1320    Asus  X553SA-XX031T (N3050/4GB/500GB/W10)   \n",
       "\n",
       "                TypeName  Inches                            ScreenResolution  \\\n",
       "0              Ultrabook    13.3          IPS Panel Retina Display 2560x1600   \n",
       "1              Ultrabook    13.3                                    1440x900   \n",
       "2               Notebook    15.6                           Full HD 1920x1080   \n",
       "3              Ultrabook    15.4          IPS Panel Retina Display 2880x1800   \n",
       "4              Ultrabook    13.3          IPS Panel Retina Display 2560x1600   \n",
       "...                  ...     ...                                         ...   \n",
       "1298  2 in 1 Convertible    14.0   IPS Panel Full HD / Touchscreen 1920x1080   \n",
       "1299  2 in 1 Convertible    13.3  IPS Panel Quad HD+ / Touchscreen 3200x1800   \n",
       "1300            Notebook    14.0                                    1366x768   \n",
       "1301            Notebook    15.6                                    1366x768   \n",
       "1302            Notebook    15.6                                    1366x768   \n",
       "\n",
       "                                       Cpu   Ram               Memory  \\\n",
       "0                     Intel Core i5 2.3GHz   8GB            128GB SSD   \n",
       "1                     Intel Core i5 1.8GHz   8GB  128GB Flash Storage   \n",
       "2               Intel Core i5 7200U 2.5GHz   8GB            256GB SSD   \n",
       "3                     Intel Core i7 2.7GHz  16GB            512GB SSD   \n",
       "4                     Intel Core i5 3.1GHz   8GB            256GB SSD   \n",
       "...                                    ...   ...                  ...   \n",
       "1298            Intel Core i7 6500U 2.5GHz   4GB            128GB SSD   \n",
       "1299            Intel Core i7 6500U 2.5GHz  16GB            512GB SSD   \n",
       "1300  Intel Celeron Dual Core N3050 1.6GHz   2GB   64GB Flash Storage   \n",
       "1301            Intel Core i7 6500U 2.5GHz   6GB              1TB HDD   \n",
       "1302  Intel Celeron Dual Core N3050 1.6GHz   4GB            500GB HDD   \n",
       "\n",
       "                               Gpu       OpSys  Weight  Price_euros  \n",
       "0     Intel Iris Plus Graphics 640       macOS  1.37kg      1339.69  \n",
       "1           Intel HD Graphics 6000       macOS  1.34kg       898.94  \n",
       "2            Intel HD Graphics 620       No OS  1.86kg       575.00  \n",
       "3               AMD Radeon Pro 455       macOS  1.83kg      2537.45  \n",
       "4     Intel Iris Plus Graphics 650       macOS  1.37kg      1803.60  \n",
       "...                            ...         ...     ...          ...  \n",
       "1298         Intel HD Graphics 520  Windows 10   1.8kg       638.00  \n",
       "1299         Intel HD Graphics 520  Windows 10   1.3kg      1499.00  \n",
       "1300             Intel HD Graphics  Windows 10   1.5kg       229.00  \n",
       "1301            AMD Radeon R5 M330  Windows 10  2.19kg       764.00  \n",
       "1302             Intel HD Graphics  Windows 10   2.2kg       369.00  \n",
       "\n",
       "[1303 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will be used in order to exchange the different attributes\n",
    "# to create negative examples\n",
    "class Attributes():\n",
    "    company = {'Apple'}\n",
    "    product = {'MacBook Pro'}\n",
    "    inches = {'13.3'}\n",
    "    cpu = {'Intel Core i5 2.3GHz'}\n",
    "    ram = {'4GB'}\n",
    "    memory = {'256GB SSD'}\n",
    "    gpu = {'Intel HD Graphics 520'}\n",
    "    screen = {'1440x900'}\n",
    "    \n",
    "    def get_all_data():\n",
    "        return {\n",
    "            'company': Attributes.company,\n",
    "            'product': Attributes.product,\n",
    "            'inches': Attributes.inches,\n",
    "            'cpu': Attributes.cpu,\n",
    "            'ram': Attributes.ram,\n",
    "            'memory': Attributes.memory,\n",
    "            'gpu': Attributes.gpu,\n",
    "            'screen': Attributes.screen\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attribute sets\n",
    "def create_attribute_sets(df):\n",
    "    Attributes.company.update([row.Company for row in laptop_df[['Company']].itertuples()])\n",
    "    Attributes.product.update([row.Product for row in laptop_df[['Product']].itertuples()])\n",
    "    Attributes.inches.update([str(row.Inches) for row in laptop_df[['Inches']].itertuples()])\n",
    "    Attributes.cpu.update([row.Cpu for row in laptop_df[['Cpu']].itertuples()])\n",
    "    Attributes.ram.update([row.Ram for row in laptop_df[['Ram']].itertuples()])\n",
    "    Attributes.memory.update([row.Memory for row in laptop_df[['Memory']].itertuples()])\n",
    "    Attributes.gpu.update([row.Gpu for row in laptop_df[['Gpu']].itertuples()])\n",
    "    Attributes.screen.update([row.ScreenResolution for row in laptop_df[['ScreenResolution']].itertuples()])\n",
    "\n",
    "create_attribute_sets(laptop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_row(row):\n",
    "    # Note: got rid of everything after the '(' because it has info about the actual specs of the laptop\n",
    "    # so if we change the specs, we need to fix that too\n",
    "    \n",
    "    # Special tags at the end of the amount of inches of the laptop and the RAM to simulate real data\n",
    "    inch_attr = str(row['Inches']) + random.choice([' inch', '', '\"'])\n",
    "    ram_attr = row['Ram'] + random.choice([' ram', ' memory', ''])\n",
    "    \n",
    "    # These are words that commonly come up with laptops\n",
    "    modifiers = ['premium', 'new', 'fast', 'latest model']\n",
    "    add_ins = ['USB 3.0', 'USB 3.1 Type-C', 'USB Type-C', 'Bluetooth', 'WIFI', 'Webcam', 'FP Reader',\n",
    "               'HDMI', '802.11ac', '802.11 ac', 'home', 'flagship', 'business', 'GbE LAN', 'DVD-RW', 'DVD', 'Windows 10']\n",
    "    \n",
    "    cpu_attr = row['Cpu']\n",
    "    if random.choice([0, 1]):\n",
    "        cpu_attr = cpu_attr.split(' ')\n",
    "        if random.choice([0, 1]):\n",
    "            if 'Intel' in cpu_attr:\n",
    "                cpu_attr.remove('Intel')\n",
    "        if random.choice([0, 1]):\n",
    "            if 'Core' in cpu_attr:\n",
    "                cpu_attr.remove('Core')\n",
    "        if random.choice([0, 1]):\n",
    "            if 'AMD' in cpu_attr:\n",
    "                cpu_attr.remove('AMD')\n",
    "    \n",
    "        cpu_attr = ' '.join(cpu_attr)\n",
    "\n",
    "    # Create a list for all the product attributes\n",
    "    order_attrs = [random.choice(modifiers),\n",
    "                   row['Company'],\n",
    "                   row['Product'].split('(')[0],\n",
    "                   row['TypeName'],\n",
    "                   inch_attr,\n",
    "                   row['ScreenResolution'],\n",
    "                   cpu_attr,\n",
    "                   ram_attr,\n",
    "                   row['Memory'],\n",
    "                   row['Gpu']]\n",
    "    \n",
    "    order_attrs = order_attrs + random.sample(add_ins, random.choice([1, 2, 3, 4]))\n",
    "    \n",
    "    # Shuffle the data because in real data, it does not really matter what order the attributes are in\n",
    "    random.shuffle(order_attrs)\n",
    "    \n",
    "    return ' '.join(order_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the negative examples for the laptop data\n",
    "# The laptop_df is the original data, the new_df is the dataframe to append the new data to\n",
    "# and the attributes are the attributes to swap for the new data\n",
    "def create_neg_laptop_data(laptop_df, attributes):\n",
    "    new_column_names = ['title_one', 'title_two', 'label']\n",
    "    negative_df = pd.DataFrame(columns = new_column_names)\n",
    "    for row in tqdm(range(len(laptop_df))):\n",
    "        # Create a copy of the row for the negative example\n",
    "        neg_row = laptop_df.iloc[row]\n",
    "        for attribute_class in attributes:\n",
    "            # Get the row in the laptop_data\n",
    "            orig_row = laptop_df.iloc[row]\n",
    "            \n",
    "            # Get the attribute that we are trying to change\n",
    "            attribute_val = orig_row[attribute_class]\n",
    "            \n",
    "            # Temporarily value for the new value\n",
    "            new_val = attribute_val\n",
    "            \n",
    "            # Make sure we really get a new attribute\n",
    "            while new_val == attribute_val:\n",
    "                new_val = random.sample(Attributes.get_all_data()[attribute_class.lower()], 1)[0]\n",
    "            \n",
    "            # Change the value in the neg_row to the new value\n",
    "            neg_row[attribute_class] = new_val\n",
    "            \n",
    "            # Concatenate and normalize the data\n",
    "            title_one = remove_stop_words(concatenate_row(orig_row).lower())\n",
    "            title_two = remove_stop_words(concatenate_row(neg_row).lower())\n",
    "            \n",
    "            # Append the data to the new df\n",
    "            negative_df = negative_df.append(pd.DataFrame([[title_one, title_two, 0]], columns=new_column_names))\n",
    "    \n",
    "    return negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/1303 [00:00<?, ?it/s]C:\\Users\\Jason\\miniconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1303/1303 [00:18<00:00, 68.93it/s]\n"
     ]
    }
   ],
   "source": [
    "neg_df = create_neg_laptop_data(laptop_df, attributes=['Cpu', 'Memory', 'Ram', 'Inches', 'Product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataframe(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the postive examples for the laptop data\n",
    "# The laptop_df is the original data, the new_df is the dataframe to append the new data to\n",
    "# and the attributes are the attributes to swap or delete for the new data\n",
    "def create_pos_laptop_data(laptop_df, rm_attrs, add_attrs):\n",
    "    new_column_names = ['title_one', 'title_two', 'label']\n",
    "    pos_df = pd.DataFrame(columns = new_column_names)\n",
    "    for row in tqdm(range(len(laptop_df))):\n",
    "        # Remove the attribute from the new title\n",
    "        for attr_list in rm_attrs:\n",
    "            # Create a copy of the row for the negative example\n",
    "            new_row = laptop_df.iloc[row]\n",
    "            orig_row = laptop_df.iloc[row]\n",
    "            for attr in attr_list:\n",
    "                new_row[attr] = ''\n",
    "        \n",
    "            title_one = remove_stop_words(concatenate_row(orig_row).lower())\n",
    "            title_two = remove_stop_words(concatenate_row(new_row).lower())\n",
    "\n",
    "            pos_df = pos_df.append(pd.DataFrame([[title_one, title_two, 1]], columns=new_column_names))\n",
    "\n",
    "    return pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/1303 [00:00<?, ?it/s]C:\\Users\\Jason\\miniconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1303/1303 [00:17<00:00, 75.30it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_df = create_pos_laptop_data(laptop_df, rm_attrs = [['Company'], ['TypeName'], ['ScreenResolution'], ['Product'], ['TypeName', 'ScreenResolution']], add_attrs = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataframe(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_laptop_df = create_final_data(pos_df, neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_laptop_df = final_laptop_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCPartPicker Data\n",
    "* Organize the data\n",
    "* Preprocess the data\n",
    "* Create negative and positive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ram_df = pd.read_csv('data/train/pos_ram_titles.csv')\n",
    "cpu_df = pd.read_csv('data/train/pos_cpu_titles.csv')\n",
    "hard_drive_df = pd.read_csv('data/train/pos_hard_drive_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>amazon</th>\n",
       "      <th>bestbuy</th>\n",
       "      <th>newegg</th>\n",
       "      <th>walmart</th>\n",
       "      <th>memoryc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Corsair Vengeance LPX 16GB (2x8GB) DDR4 DRAM 3...</td>\n",
       "      <td>CORSAIR - Vengeance LPX 16GB (2PK x 8GB) 3.2 G...</td>\n",
       "      <td>CORSAIR Vengeance LPX 16GB (2 x 8GB) 288-Pin D...</td>\n",
       "      <td>Corsair CMK16GX4M2B3200C16 Vengeance LPX 16GB ...</td>\n",
       "      <td>16GB Corsair Vengeance LPX PC4-25600 3200MHz D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Corsair Vengeance RGB PRO 16GB (2x8GB) DDR4 32...</td>\n",
       "      <td>CORSAIR - Vengeance RGB PRO 16GB (2PK 8GB) 3.2...</td>\n",
       "      <td>CORSAIR Vengeance RGB Pro 16GB (2 x 8GB) 288-P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16GB Corsair Vengeance RGB Pro DDR4 3200MHz CL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>G.Skill RipJaws V Series 16GB (2 x 8GB) 288-Pi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G.SKILL Ripjaws V Series 16GB (2 x 8GB) 288-Pi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Corsair Vengeance RGB Pro 32GB (2x16GB) DDR4 3...</td>\n",
       "      <td>CORSAIR - Vengeance RGB PRO 32GB (2PK 16GB) 3....</td>\n",
       "      <td>CORSAIR Vengeance RGB Pro 32GB (2 x 16GB) 288-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32GB Corsair Vengeance Pro RGB DDR4 3200MHz CL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G.SKILL Trident Z RGB (For AMD) 16GB (2 x 8GB)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16GB G.Skill DDR4 TridentZ RGB 3600Mhz PC4-288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0</td>\n",
       "      <td>Corsair Vengeance LPX 32GB (4x8GB) DDR4 3600 (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORSAIR Vengeance LPX 32GB (4 x 8GB) 288-Pin D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32GB Corsair Vengeance LPX DDR4 3600MHz PC4-28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>Corsair Vengeance LPX 16GB (2x8GB) DDR4 DRAM 3...</td>\n",
       "      <td>CORSAIR - VENGEANCE LPX Series 16GB (2PK 8GB) ...</td>\n",
       "      <td>CORSAIR Vengeance LPX 16GB (2 x 8GB) 288-Pin D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16GB Corsair Vengeance LPX DDR4 3000MHz PC4-24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>CORSAIR VENGEANCELPX32GB (1x 32GB) DDR43000(PC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORSAIR Vengeance LPX 32GB 288-Pin DDR4 SDRAM ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32GB Corsair Vengeance LPX DDR4 3000MHz CL16 M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>Corsair Dominator Platinum RGB 16GB (2x8GB) DD...</td>\n",
       "      <td>CORSAIR - Dominator Platinum RGB 16GB (2PK 8GB...</td>\n",
       "      <td>CORSAIR Dominator Platinum RGB 16GB (2 x 8GB) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16GB Corsair Dominator Platinum RGB 3200MHz CL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             amazon  \\\n",
       "0             0  Corsair Vengeance LPX 16GB (2x8GB) DDR4 DRAM 3...   \n",
       "1             0  Corsair Vengeance RGB PRO 16GB (2x8GB) DDR4 32...   \n",
       "2             0  G.Skill RipJaws V Series 16GB (2 x 8GB) 288-Pi...   \n",
       "3             0  Corsair Vengeance RGB Pro 32GB (2x16GB) DDR4 3...   \n",
       "4             0                                                NaN   \n",
       "..          ...                                                ...   \n",
       "218           0  Corsair Vengeance LPX 32GB (4x8GB) DDR4 3600 (...   \n",
       "219           0                                                NaN   \n",
       "220           0  Corsair Vengeance LPX 16GB (2x8GB) DDR4 DRAM 3...   \n",
       "221           0  CORSAIR VENGEANCELPX32GB (1x 32GB) DDR43000(PC...   \n",
       "222           0  Corsair Dominator Platinum RGB 16GB (2x8GB) DD...   \n",
       "\n",
       "                                               bestbuy  \\\n",
       "0    CORSAIR - Vengeance LPX 16GB (2PK x 8GB) 3.2 G...   \n",
       "1    CORSAIR - Vengeance RGB PRO 16GB (2PK 8GB) 3.2...   \n",
       "2                                                  NaN   \n",
       "3    CORSAIR - Vengeance RGB PRO 32GB (2PK 16GB) 3....   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "218                                                NaN   \n",
       "219                                                NaN   \n",
       "220  CORSAIR - VENGEANCE LPX Series 16GB (2PK 8GB) ...   \n",
       "221                                                NaN   \n",
       "222  CORSAIR - Dominator Platinum RGB 16GB (2PK 8GB...   \n",
       "\n",
       "                                                newegg  \\\n",
       "0    CORSAIR Vengeance LPX 16GB (2 x 8GB) 288-Pin D...   \n",
       "1    CORSAIR Vengeance RGB Pro 16GB (2 x 8GB) 288-P...   \n",
       "2    G.SKILL Ripjaws V Series 16GB (2 x 8GB) 288-Pi...   \n",
       "3    CORSAIR Vengeance RGB Pro 32GB (2 x 16GB) 288-...   \n",
       "4    G.SKILL Trident Z RGB (For AMD) 16GB (2 x 8GB)...   \n",
       "..                                                 ...   \n",
       "218  CORSAIR Vengeance LPX 32GB (4 x 8GB) 288-Pin D...   \n",
       "219                                                NaN   \n",
       "220  CORSAIR Vengeance LPX 16GB (2 x 8GB) 288-Pin D...   \n",
       "221  CORSAIR Vengeance LPX 32GB 288-Pin DDR4 SDRAM ...   \n",
       "222  CORSAIR Dominator Platinum RGB 16GB (2 x 8GB) ...   \n",
       "\n",
       "                                               walmart  \\\n",
       "0    Corsair CMK16GX4M2B3200C16 Vengeance LPX 16GB ...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "218                                                NaN   \n",
       "219                                                NaN   \n",
       "220                                                NaN   \n",
       "221                                                NaN   \n",
       "222                                                NaN   \n",
       "\n",
       "                                               memoryc  \n",
       "0    16GB Corsair Vengeance LPX PC4-25600 3200MHz D...  \n",
       "1    16GB Corsair Vengeance RGB Pro DDR4 3200MHz CL...  \n",
       "2                                                  NaN  \n",
       "3    32GB Corsair Vengeance Pro RGB DDR4 3200MHz CL...  \n",
       "4    16GB G.Skill DDR4 TridentZ RGB 3600Mhz PC4-288...  \n",
       "..                                                 ...  \n",
       "218  32GB Corsair Vengeance LPX DDR4 3600MHz PC4-28...  \n",
       "219                                                NaN  \n",
       "220  16GB Corsair Vengeance LPX DDR4 3000MHz PC4-24...  \n",
       "221  32GB Corsair Vengeance LPX DDR4 3000MHz CL16 M...  \n",
       "222  16GB Corsair Dominator Platinum RGB 3200MHz CL...  \n",
       "\n",
       "[223 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>amazon</th>\n",
       "      <th>bestbuy</th>\n",
       "      <th>newegg</th>\n",
       "      <th>walmart</th>\n",
       "      <th>memoryc</th>\n",
       "      <th>bhphotovideo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AMD Ryzen 5 3600 6-Core, 12-Thread Unlocked De...</td>\n",
       "      <td>AMD - Ryzen 5 3600 3rd Generation 6-Core - 12-...</td>\n",
       "      <td>AMD RYZEN 5 3600 6-Core 3.6 GHz (4.2 GHz Max B...</td>\n",
       "      <td>AMD Ryzen 5 3600 6-Core, 12-Thread 4.2 GHz AM4...</td>\n",
       "      <td>AMD Ryzen 5 3600 AM4 3.6GHZ 32MB CPU Desktop P...</td>\n",
       "      <td>AMD Ryzen 5 3600 3.6 GHz Six-Core AM4 Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>AMD Ryzen 7 3700X 8-Core, 16-Thread Unlocked D...</td>\n",
       "      <td>AMD - Ryzen 7 3700X 3rd Generation 8-Core - 16...</td>\n",
       "      <td>AMD RYZEN 7 3700X 8-Core 3.6 GHz (4.4 GHz Max ...</td>\n",
       "      <td>AMD Ryzen 7 3700X 8-Core, 16-Thread 4.4 GHz AM...</td>\n",
       "      <td>AMD Ryzen 7 3700x 3.6GHz 32MB AM4 CPU Desktop ...</td>\n",
       "      <td>AMD Ryzen 7 3700X 3.6 GHz Eight-Core AM4 Proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>AMD Ryzen 5 2600 Processor with Wraith Stealth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMD Ryzen 5 2600 Six-Core 3.4GHz Socket AM4 19...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>AMD Ryzen 9 3900X 12-core, 24-thread unlocked ...</td>\n",
       "      <td>AMD - Ryzen 9 3900X 3rd Generation 12-core - 2...</td>\n",
       "      <td>AMD RYZEN 9 3900X 12-Core 3.8 GHz (4.6 GHz Max...</td>\n",
       "      <td>AMD RYZEN 9 3900X 12-Core 3.8 GHz (4.6 GHz Max...</td>\n",
       "      <td>AMD Ryzen 9 3900X 3.8GHz 64MB Desktop Processo...</td>\n",
       "      <td>AMD Ryzen 9 3900X 3.8 GHz 12-Core AM4 Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>AMD Ryzen 3 3200G 4-Core Unlocked Desktop Proc...</td>\n",
       "      <td>AMD - Ryzen 3 3200G 3rd Generation 4-Core - 4-...</td>\n",
       "      <td>AMD RYZEN 3 3200G 4-Core 3.6 GHz (4.0 GHz Max ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMD Ryzen 3 AM4 3.6GHZ 4MB Desktop Processor B...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>Intel Xeon E3-1220 V6 Processors BX80677E31220V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intel Xeon E3-1220 V6 Kaby Lake 3.0 GHz (3.5 G...</td>\n",
       "      <td>XEON E3-1220 V6 FC-LGA14C 3G 8MB CACHE BOXED</td>\n",
       "      <td>Intel Xeon E3-1220 V6 3GHz Kaby Lake CPU LGA11...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>Intel - BX80684E2134 - Intel Xeon E-2134-3.5 G...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intel BX80684E2134 Xeon Quad-core E-2134 3.5GH...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>Intel BX80662E31230V5 XEON E3-1230V5, 3.4 GHZ,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>Intel BX80557E2140 Pentium Dual-Core E2140 1.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             amazon  \\\n",
       "0             0  AMD Ryzen 5 3600 6-Core, 12-Thread Unlocked De...   \n",
       "1             0  AMD Ryzen 7 3700X 8-Core, 16-Thread Unlocked D...   \n",
       "2             0  AMD Ryzen 5 2600 Processor with Wraith Stealth...   \n",
       "3             0  AMD Ryzen 9 3900X 12-core, 24-thread unlocked ...   \n",
       "4             0  AMD Ryzen 3 3200G 4-Core Unlocked Desktop Proc...   \n",
       "..          ...                                                ...   \n",
       "499           0                                                NaN   \n",
       "500           0   Intel Xeon E3-1220 V6 Processors BX80677E31220V6   \n",
       "501           0  Intel - BX80684E2134 - Intel Xeon E-2134-3.5 G...   \n",
       "502           0  Intel BX80662E31230V5 XEON E3-1230V5, 3.4 GHZ,...   \n",
       "503           0  Intel BX80557E2140 Pentium Dual-Core E2140 1.6...   \n",
       "\n",
       "                                               bestbuy  \\\n",
       "0    AMD - Ryzen 5 3600 3rd Generation 6-Core - 12-...   \n",
       "1    AMD - Ryzen 7 3700X 3rd Generation 8-Core - 16...   \n",
       "2                                                  NaN   \n",
       "3    AMD - Ryzen 9 3900X 3rd Generation 12-core - 2...   \n",
       "4    AMD - Ryzen 3 3200G 3rd Generation 4-Core - 4-...   \n",
       "..                                                 ...   \n",
       "499                                                NaN   \n",
       "500                                                NaN   \n",
       "501                                                NaN   \n",
       "502                                                NaN   \n",
       "503                                                NaN   \n",
       "\n",
       "                                                newegg  \\\n",
       "0    AMD RYZEN 5 3600 6-Core 3.6 GHz (4.2 GHz Max B...   \n",
       "1    AMD RYZEN 7 3700X 8-Core 3.6 GHz (4.4 GHz Max ...   \n",
       "2                                                  NaN   \n",
       "3    AMD RYZEN 9 3900X 12-Core 3.8 GHz (4.6 GHz Max...   \n",
       "4    AMD RYZEN 3 3200G 4-Core 3.6 GHz (4.0 GHz Max ...   \n",
       "..                                                 ...   \n",
       "499                                                NaN   \n",
       "500  Intel Xeon E3-1220 V6 Kaby Lake 3.0 GHz (3.5 G...   \n",
       "501                                                NaN   \n",
       "502                                                NaN   \n",
       "503                                                NaN   \n",
       "\n",
       "                                               walmart  \\\n",
       "0    AMD Ryzen 5 3600 6-Core, 12-Thread 4.2 GHz AM4...   \n",
       "1    AMD Ryzen 7 3700X 8-Core, 16-Thread 4.4 GHz AM...   \n",
       "2                                                  NaN   \n",
       "3    AMD RYZEN 9 3900X 12-Core 3.8 GHz (4.6 GHz Max...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "499                                                NaN   \n",
       "500       XEON E3-1220 V6 FC-LGA14C 3G 8MB CACHE BOXED   \n",
       "501  Intel BX80684E2134 Xeon Quad-core E-2134 3.5GH...   \n",
       "502                                                NaN   \n",
       "503                                                NaN   \n",
       "\n",
       "                                               memoryc  \\\n",
       "0    AMD Ryzen 5 3600 AM4 3.6GHZ 32MB CPU Desktop P...   \n",
       "1    AMD Ryzen 7 3700x 3.6GHz 32MB AM4 CPU Desktop ...   \n",
       "2    AMD Ryzen 5 2600 Six-Core 3.4GHz Socket AM4 19...   \n",
       "3    AMD Ryzen 9 3900X 3.8GHz 64MB Desktop Processo...   \n",
       "4    AMD Ryzen 3 AM4 3.6GHZ 4MB Desktop Processor B...   \n",
       "..                                                 ...   \n",
       "499                                                NaN   \n",
       "500  Intel Xeon E3-1220 V6 3GHz Kaby Lake CPU LGA11...   \n",
       "501                                                NaN   \n",
       "502                                                NaN   \n",
       "503                                                NaN   \n",
       "\n",
       "                                          bhphotovideo  \n",
       "0      AMD Ryzen 5 3600 3.6 GHz Six-Core AM4 Processor  \n",
       "1    AMD Ryzen 7 3700X 3.6 GHz Eight-Core AM4 Proce...  \n",
       "2                                                  NaN  \n",
       "3      AMD Ryzen 9 3900X 3.8 GHz 12-Core AM4 Processor  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "499                                                NaN  \n",
       "500                                                NaN  \n",
       "501                                                NaN  \n",
       "502                                                NaN  \n",
       "503                                                NaN  \n",
       "\n",
       "[504 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>amazon</th>\n",
       "      <th>bestbuy</th>\n",
       "      <th>newegg</th>\n",
       "      <th>walmart</th>\n",
       "      <th>memoryc</th>\n",
       "      <th>bhphotovideo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Seagate Barracuda ST2000DM008 2 TB 3.5\" Intern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seagate BarraCuda ST2000DM008 2TB 7200 RPM 256...</td>\n",
       "      <td>Seagate ST2000DM008 BarraCuda 2TB 3.5 SATA HDD...</td>\n",
       "      <td>2TB Seagate Barracuda Serial ATA III 3.5-inch ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Samsung  (MZ-V7E500BW) 970 EVO SSD 500GB - M.2...</td>\n",
       "      <td>Samsung - 970 EVO 500GB Internal PCI Express 3...</td>\n",
       "      <td>SAMSUNG 970 EVO M.2 2280 500GB PCIe Gen3. X4, ...</td>\n",
       "      <td>SAMSUNG 970 EVO Series - 500GB PCIe NVMe - M.2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samsung 500GB 970 EVO NVMe M.2 Internal SSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Samsung (MZ-V7E1T0BW) 970 EVO SSD 1TB - M.2 NV...</td>\n",
       "      <td>Samsung - 970 EVO 1TB Internal PCI Express 3.0...</td>\n",
       "      <td>SAMSUNG 970 EVO M.2 2280 1TB PCIe Gen3. X4, NV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samsung 1TB 970 EVO NVMe M.2 Internal SSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>WD Blue 1TB PC Hard Drive - 7200 RPM Class, SA...</td>\n",
       "      <td>WD - Blue 1TB Internal SATA Hard Drive for Des...</td>\n",
       "      <td>WD Blue 1TB Desktop Hard Disk Drive - 7200 RPM...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1TB Western Digital Blue 3.5-inch SATA III 6Gb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Crucial P1 1TB 3D NAND NVMe PCIe Internal SSD,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crucial P1 1TB 3D NAND NVMe PCIe Internal SSD,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1TB Crucial P1 M.2 2280 PCI Express 3.0 x 4 So...</td>\n",
       "      <td>Crucial 1TB P1 NVMe M.2 2280 Internal SSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XPG - Ultimate Series SU800 2TB Internal SATA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADATA Technology 2TB Ultimate SU800 SATA III 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SanDisk - Ultra 2TB Internal SATA Solid State ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SanDisk Ultra 2TB 2.5\" SATA Internal Solid Sta...</td>\n",
       "      <td>2TB SanDisk Ultra 3D Serial ATA III 6GB 2.5-in...</td>\n",
       "      <td>SanDisk 2TB 3D SATA III 2.5\" Internal SSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0</td>\n",
       "      <td>ADATA SU655 480GB 3D NAND 2.5 inch SATA III Hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             amazon  \\\n",
       "0             0  Seagate Barracuda ST2000DM008 2 TB 3.5\" Intern...   \n",
       "1             0  Samsung  (MZ-V7E500BW) 970 EVO SSD 500GB - M.2...   \n",
       "2             0  Samsung (MZ-V7E1T0BW) 970 EVO SSD 1TB - M.2 NV...   \n",
       "3             0  WD Blue 1TB PC Hard Drive - 7200 RPM Class, SA...   \n",
       "4             0  Crucial P1 1TB 3D NAND NVMe PCIe Internal SSD,...   \n",
       "..          ...                                                ...   \n",
       "317           0                                                NaN   \n",
       "318           0                                                NaN   \n",
       "319           0                                                NaN   \n",
       "320           0                                                NaN   \n",
       "321           0  ADATA SU655 480GB 3D NAND 2.5 inch SATA III Hi...   \n",
       "\n",
       "                                               bestbuy  \\\n",
       "0                                                  NaN   \n",
       "1    Samsung - 970 EVO 500GB Internal PCI Express 3...   \n",
       "2    Samsung - 970 EVO 1TB Internal PCI Express 3.0...   \n",
       "3    WD - Blue 1TB Internal SATA Hard Drive for Des...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "317                                                NaN   \n",
       "318  XPG - Ultimate Series SU800 2TB Internal SATA ...   \n",
       "319                                                NaN   \n",
       "320  SanDisk - Ultra 2TB Internal SATA Solid State ...   \n",
       "321                                                NaN   \n",
       "\n",
       "                                                newegg  \\\n",
       "0    Seagate BarraCuda ST2000DM008 2TB 7200 RPM 256...   \n",
       "1    SAMSUNG 970 EVO M.2 2280 500GB PCIe Gen3. X4, ...   \n",
       "2    SAMSUNG 970 EVO M.2 2280 1TB PCIe Gen3. X4, NV...   \n",
       "3    WD Blue 1TB Desktop Hard Disk Drive - 7200 RPM...   \n",
       "4    Crucial P1 1TB 3D NAND NVMe PCIe Internal SSD,...   \n",
       "..                                                 ...   \n",
       "317                                                NaN   \n",
       "318                                                NaN   \n",
       "319                                                NaN   \n",
       "320                                                NaN   \n",
       "321                                                NaN   \n",
       "\n",
       "                                               walmart  \\\n",
       "0    Seagate ST2000DM008 BarraCuda 2TB 3.5 SATA HDD...   \n",
       "1    SAMSUNG 970 EVO Series - 500GB PCIe NVMe - M.2...   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "317                                                NaN   \n",
       "318                                                NaN   \n",
       "319                                                NaN   \n",
       "320  SanDisk Ultra 2TB 2.5\" SATA Internal Solid Sta...   \n",
       "321                                                NaN   \n",
       "\n",
       "                                               memoryc  \\\n",
       "0    2TB Seagate Barracuda Serial ATA III 3.5-inch ...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    1TB Western Digital Blue 3.5-inch SATA III 6Gb...   \n",
       "4    1TB Crucial P1 M.2 2280 PCI Express 3.0 x 4 So...   \n",
       "..                                                 ...   \n",
       "317                                                NaN   \n",
       "318                                                NaN   \n",
       "319                                                NaN   \n",
       "320  2TB SanDisk Ultra 3D Serial ATA III 6GB 2.5-in...   \n",
       "321                                                NaN   \n",
       "\n",
       "                                          bhphotovideo  \n",
       "0                                                  NaN  \n",
       "1          Samsung 500GB 970 EVO NVMe M.2 Internal SSD  \n",
       "2            Samsung 1TB 970 EVO NVMe M.2 Internal SSD  \n",
       "3                                                  NaN  \n",
       "4            Crucial 1TB P1 NVMe M.2 2280 Internal SSD  \n",
       "..                                                 ...  \n",
       "317                                                NaN  \n",
       "318  ADATA Technology 2TB Ultimate SU800 SATA III 2...  \n",
       "319                                                NaN  \n",
       "320          SanDisk 2TB 3D SATA III 2.5\" Internal SSD  \n",
       "321                                                NaN  \n",
       "\n",
       "[322 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_drive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Unnamed: 0 column and drop any row where it is all NaN\n",
    "def remove_misc(df):\n",
    "    columns = list(df.columns)[1:]\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    df = df.dropna(how='all')\n",
    "    print(len(df))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "315\n",
      "233\n"
     ]
    }
   ],
   "source": [
    "ram_df = remove_misc(ram_df)\n",
    "cpu_df = remove_misc(cpu_df)\n",
    "hard_drive_df = remove_misc(hard_drive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos_pcpartpicker_data(df):\n",
    "    columns = list(df.columns)\n",
    "    pos_df = pd.DataFrame(columns=['title_one', 'title_two', 'label'])\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        row = df.iloc()[idx]\n",
    "        titles = []\n",
    "        for col in columns:\n",
    "            if not pd.isnull(row[col]): titles.append(row[col])\n",
    "        if len(titles) > 1:\n",
    "            combs = combinations(titles, 2)\n",
    "            for comb in combs:\n",
    "                comb = list(comb)\n",
    "                comb.append(1)\n",
    "                pos_df = pos_df.append(pd.DataFrame([comb], columns=['title_one', 'title_two', 'label']))\n",
    "    \n",
    "    return pos_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 210/210 [00:00<00:00, 459.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 315/315 [00:00<00:00, 488.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 233/233 [00:00<00:00, 354.32it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_ram_data = generate_pos_pcpartpicker_data(ram_df)\n",
    "\n",
    "pos_cpu_data = generate_pos_pcpartpicker_data(cpu_df)\n",
    "\n",
    "pos_hard_drive_data = generate_pos_pcpartpicker_data(hard_drive_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg_pcpartpicker_data(df):\n",
    "    columns = list(df.columns)\n",
    "    neg_df = pd.DataFrame(columns=['title_one', 'title_two', 'label'])\n",
    "    df_list = df.iloc()\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        row = df_list[idx]\n",
    "        for col in columns:\n",
    "            if not pd.isnull(row[col]):\n",
    "                neg_idx = None\n",
    "                while neg_idx == idx or neg_idx is None:\n",
    "                    neg_idx = random.randint(0, len(df) - 1)\n",
    "                \n",
    "                neg_title = None\n",
    "                while neg_title == None or pd.isnull(neg_title):\n",
    "                    neg_title = df_list[neg_idx][random.choice(columns)]\n",
    "                \n",
    "                neg_df = neg_df.append(pd.DataFrame([[row[col], neg_title, 0]], columns=['title_one', 'title_two', 'label']))\n",
    "    \n",
    "    return neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 210/210 [00:00<00:00, 301.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 315/315 [00:00<00:00, 317.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 233/233 [00:00<00:00, 273.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962 696 1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "neg_ram_data = generate_neg_pcpartpicker_data(ram_df)\n",
    "\n",
    "neg_cpu_data = generate_neg_pcpartpicker_data(cpu_df)\n",
    "\n",
    "neg_hard_drive_data = generate_neg_pcpartpicker_data(hard_drive_df)\n",
    "\n",
    "final_ram_data = create_final_data(pos_ram_data, neg_ram_data)\n",
    "\n",
    "final_cpu_data = create_final_data(pos_cpu_data, neg_cpu_data)\n",
    "\n",
    "final_hard_drive_data = create_final_data(pos_hard_drive_data, neg_hard_drive_data)\n",
    "\n",
    "print(len(final_cpu_data), len(final_ram_data), len(final_hard_drive_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Creation Functions\n",
    "Generates the embeddings and saves them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the numpy files of all the training embedddings\n",
    "We will have two numpy files:\n",
    "1. The training/validation/test sets\n",
    "2. The labels\n",
    "\"\"\"\n",
    "\n",
    "def create_embeddings(df):\n",
    "    # Create the numpy arrays for storing the embeddings and labels\n",
    "    total_embeddings = np.zeros(shape=(len(df), 2, MAX_LEN, EMBEDDING_SHAPE[0]))\n",
    "    labels = np.zeros(shape=(len(df)))\n",
    "    \n",
    "    # I know this is a terrible way of doing this, but iterate over the dataframe\n",
    "    # and generate the embeddings to add to the numpy array\n",
    "    for idx, row in enumerate(tqdm(df.itertuples())):\n",
    "        for word_idx, word in enumerate(row.title_one.split()):\n",
    "            total_embeddings[idx, 0, word_idx] = fasttext_model[word]\n",
    "            \n",
    "        for word_idx, word in enumerate(row.title_two.split()):\n",
    "            total_embeddings[idx, 1, word_idx] = fasttext_model[word]\n",
    "            \n",
    "        labels[idx] = row.label\n",
    "        \n",
    "    return total_embeddings, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(df, embeddings_name, labels_name):\n",
    "    \"\"\"\n",
    "    Saves the embeddings given the embeddings file name and labels file name\n",
    "    \"\"\"\n",
    "    if not os.path.exists('data/numpy_data/' + embeddings_name + '.npy'):\n",
    "        embeddings, labels = create_embeddings(df)\n",
    "        with open('data/numpy_data/' + embeddings_name + '.npy', 'wb') as f:\n",
    "            np.save(f, embeddings)\n",
    "\n",
    "        with open('data/numpy_data/' + labels_name + '.npy', 'wb') as f:\n",
    "            np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_and_labels(embeddings_name, labels_name):\n",
    "    loaded_embeddings = None\n",
    "    labels = None\n",
    "    with open('data/numpy_data/' + embeddings_name + '.npy', 'rb') as f:\n",
    "        loaded_embeddings = np.load(f)\n",
    "        loaded_embeddings = np.transpose(loaded_embeddings, (1, 0, 2, 3))\n",
    "    \n",
    "    with open('data/numpy_data/' + labels_name + '.npy', 'rb') as f:\n",
    "        labels = np.load(f)\n",
    "    \n",
    "    return loaded_embeddings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Embeddings\n",
    "Save the embeddings for the different types of data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29158it [00:11, 2441.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-dbc6556d089b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtotal_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mMAX_LEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_max_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcreate_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# save_embeddings(total_data, 'all_embeddings', 'all_labels')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-b7922304d064>\u001b[0m in \u001b[0;36mcreate_embeddings\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle_two\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mtotal_embeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Concatenate everything\n",
    "total_data = pd.concat([final_computer_df, final_laptop_df, final_hard_drive_data, final_cpu_data, final_ram_data])\n",
    "total_data = total_data.sample(frac=1)\n",
    "MAX_LEN = get_max_len(total_data)\n",
    "save_embeddings(total_data, 'all_embeddings', 'all_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels = load_embeddings_and_labels('all_embeddings', 'all_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35078"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (2, 31078, 43, 300)\n",
      "Val shape: (2, 2000, 43, 300)\n",
      "Test shape: (2, 2000, 43, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train1 = embeddings[0, :len(labels) - 4000]\n",
    "X_train2 = embeddings[1, :len(labels) - 4000]\n",
    "X_train = np.stack((X_train1, X_train2))\n",
    "print('Training shape: ' + str(X_train.shape))\n",
    "\n",
    "X_val1 = embeddings[0, len(labels) - 4000:len(labels) - 2000]\n",
    "X_val2 = embeddings[1, len(labels) - 4000:len(labels) - 2000]\n",
    "X_val = np.stack((X_val1, X_val2))\n",
    "print('Val shape: ' + str(X_val.shape))\n",
    "\n",
    "\n",
    "X_test1 = embeddings[0, len(labels) - 2000:]\n",
    "X_test2 = embeddings[1, len(labels) - 2000:]\n",
    "X_test = np.stack((X_test1, X_test2))\n",
    "print('Test shape: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (31078,)\n",
      "Val shape: (2000,)\n",
      "Test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "Y_train = labels[:len(labels) - 4000]\n",
    "print('Training labels shape:', str(Y_train.shape))\n",
    "\n",
    "Y_val = labels[len(labels) - 4000:len(labels) - 2000]\n",
    "print('Val shape:', str(Y_val.shape))\n",
    "\n",
    "Y_test = labels[len(labels) - 2000:]\n",
    "print('Test shape:', str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = convert_to_one_hot(Y_train.astype(np.int32), 2)\n",
    "Y_val = convert_to_one_hot(Y_val.astype(np.int32), 2)\n",
    "Y_test = convert_to_one_hot(Y_test.astype(np.int32), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Info\n",
    "\n",
    "For the model, we are going to use LSTMs with a Constrastive Loss Function \n",
    "that will also be used to predict whether the two products are the same \n",
    "\n",
    "First, we have to convert the titles to embeddings through FastText before feeding into the LSTM.\n",
    "The embedding part of this model will not be a layer because:\n",
    "* The fasttext model would be time consuming and annoying to get to work with an embedding layer in Keras\n",
    "* The fasttext model is not going to be getting its embeddings optimized, so there is really no point in adding it as an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_distance(vectors):\n",
    "    x, y = vectors\n",
    "    return tf.square(x - y)\n",
    "\n",
    "def euclidean_dist_out_shape(shapes):\n",
    "    # Both inputs are fed in, so just use one of them and get the first value in the shape\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],)\n",
    "\n",
    "def siamese_network(input_shape):\n",
    "    # Defines our inputs\n",
    "    left_title = Input(input_shape, dtype='float32')\n",
    "    right_title = Input(input_shape, dtype='float32')\n",
    "    \n",
    "    # The LSTM units\n",
    "    model = tf.keras.Sequential(name='siamese_model')\n",
    "    model.add(LSTM(units=256, return_sequences=True, name='lstm_1'))\n",
    "    model.add(Dropout(rate=0.6))\n",
    "    model.add(LSTM(units=128, return_sequences=True, name='lstm_2'))\n",
    "    model.add(Dropout(rate=0.6))\n",
    "    model.add(LSTM(units=128, name='lstm_3'))\n",
    "    model.add(Dropout(rate=0.6))\n",
    "    \n",
    "    # The dense layers\n",
    "    model.add(Dense(units=1024, activation='elu', name='dense_1'))\n",
    "    model.add(Dropout(rate=0.6))\n",
    "    model.add(Dense(units=512, activation='elu', name='dense_2'))\n",
    "    \n",
    "    # Forward propagate through the model to generate the encodings\n",
    "    encoded_left_title = model(left_title)\n",
    "    encoded_right_title = model(right_title)\n",
    "\n",
    "    SquareDistanceLayer = Lambda(square_distance)\n",
    "    distance = SquareDistanceLayer([encoded_left_title, encoded_right_title])\n",
    "    \n",
    "    prediction = Dense(units=2, activation='softmax')(distance)\n",
    "    # Create and return the network\n",
    "    siamese_net = tf.keras.Model(inputs=[left_title, right_title], outputs=prediction, name='siamese_network')\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: for the constrastive loss, because 0 denotes that they are from the same class\n",
    "# and one denotes they are from a different class, I swaped the (Y) and (1 - Y) terms\n",
    "\n",
    "def constrastive_loss(y_true, y_pred):\n",
    "    margin = 2.0\n",
    "    d = y_pred\n",
    "    d_sqrt = tf.sqrt(d)\n",
    "    #tf.print('\\nY Pred: ', d, 'Shape: ', tf.shape(d))\n",
    "    #tf.print('\\nY True: ', y_true, 'Shape: ', tf.shape(y_true))\n",
    "    \n",
    "    loss = (y_true * d) + ((1 - y_true) * tf.square(tf.maximum(0., margin - d_sqrt)))\n",
    "    \n",
    "    #tf.print('\\n Constrastive Loss: ', loss, 'Shape: ', tf.shape(loss))\n",
    "    loss = 0.5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metric for constrastive loss because values close to 0 are equal and values high are different\n",
    "# 0.5 is the threshold here\n",
    "def constrastive_accuracy(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_true, tf.cast(y_pred < 0.5, y_true.dtype)), y_true.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    \"\"\"\n",
    "    Saves a model with a particular name\n",
    "    \"\"\"\n",
    "    model.save('models/' + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"siamese_network\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 43, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 43, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "siamese_model (Sequential)      (None, 512)          1555968     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 512)          0           siamese_model[0][0]              \n",
      "                                                                 siamese_model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1026        lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,556,994\n",
      "Trainable params: 1,556,994\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = siamese_network((MAX_LEN, EMBEDDING_SHAPE[0],))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x=[X_train1, X_train2], y=Y_train, batch_size=128, epochs=80, validation_data=([X_val[0], X_val[1]], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "results = model.evaluate([X_test1, X_test2], Y_test, batch_size=16)\n",
    "print('test loss, test acc: ', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's name\n",
    "model_name = '0.2_Softmax-LSTM-128_batch_80_epochs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Testing\n",
    "Converts titles into embeddings arrays and allow the model to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_one = 'ASUS VivoBook 15 Thin and Light Laptop, 15.6” FHD Display, Intel Core i3 1005G1 CPU, 64GB RAM, 128GB SSD, Backlit Keyboard, Fingerprint, Windows 10 Home in S Mode, Slate Gray, F512JA-AS34'\n",
    "title_two = '2020 ASUS VivoBook 15 Laptop Computer_ 15.6\" FHD_ 10th Gen Intel Core i3 1005G1 Up to 3.4GHz 16GB DDR4 RAM, 128GB PCIe SSD_ Backlit KB_ Fingerprint Reader_ BROAGE Mouse Pad'\n",
    "#title_one = '128GB ram'\n",
    "#title_two = '12gb ram'\n",
    "title_one_arr = np.zeros((1, MAX_LEN, 300))\n",
    "title_two_arr = np.zeros((1, MAX_LEN, 300))\n",
    "title_one = remove_stop_words(title_one.lower())\n",
    "title_two = remove_stop_words(title_two.lower())\n",
    "\n",
    "for idx, word in enumerate(title_one.split(' ')):\n",
    "    title_one_arr[0, idx] = fasttext_model[word]\n",
    "    \n",
    "for idx, word in enumerate(title_two.split(' ')):\n",
    "    title_two_arr[0, idx] = fasttext_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00846809, 0.9915319 ]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([title_one_arr, title_two_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
