{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Dropout, Lambda, Concatenate\n",
    "\n",
    "# Have to download the stopwords\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Get the fasttext model (we are using the largest one they offer [600B tokens])\n",
    "fasttext_model = fasttext.load_model('models/crawl-300d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processsing and Organization\n",
    "Here, all we really want to do is prepare the data for training. This is **only** the data from **Gold Standard** This includes:\n",
    "* Simplifying the original data\n",
    "* Normalizing the data \n",
    "* Balancing the positive and negative examples\n",
    "* Creating the embedding representations that will actually get fed into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(phrase):\n",
    "    # Creates the stopwords\n",
    "    to_stop = stopwords.words('english')\n",
    "    punctuation = \"!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~ \"\n",
    "    for c in punctuation:\n",
    "        to_stop.append(c)\n",
    "\n",
    "    to_stop.append('null')\n",
    "    \n",
    "    for punc in punctuation:\n",
    "        phrase = phrase.replace(punc, ' ')\n",
    "    \n",
    "    return ' '.join((' '.join([x for x in phrase.split(' ') if x not in to_stop])).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing and normalizing the data\n",
    "\"\"\"\n",
    "Essentially, we want to only have three attributes for each training example: title_one, title_two, label\n",
    "For normalization, we are just going to use the nltk stopwords and punctuation\n",
    "\"\"\"\n",
    "\n",
    "def preprocessing(orig_data):\n",
    "    \"\"\"\n",
    "    Normalizes the data by getting rid of stopwords and punctuation\n",
    "    \"\"\"\n",
    "    \n",
    "    # The new names of the columns\n",
    "    column_names = ['title_one', 'title_two', 'label']\n",
    "    # A new dataframe for the data we are going to be creating\n",
    "    norm_computers = pd.DataFrame(columns = column_names)\n",
    "    # Iterate over the original dataframe (I know it is slow and there are probably better ways to do it)\n",
    "    for row in orig_data.itertuples():\n",
    "        title_left = remove_stop_words(row.title_left)\n",
    "        title_right = remove_stop_words(row.title_right)\n",
    "        \n",
    "        # Append the newly created row (title_left, title_right, label) to the new dataframe\n",
    "        norm_computers = norm_computers.append(pd.DataFrame([[title_left, title_right, row.label]], columns=column_names))\n",
    "        \n",
    "    return norm_computers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_data():\n",
    "    \"\"\"\n",
    "    Creates and saves a simpler version of the original data that only contains the the two titles and the label.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the dataset of computer parts\n",
    "    computers_df = pd.read_json('data/train/computers_train_xlarge_normalized.json.gz',compression='gzip', lines=True)\n",
    "    norm_computers = preprocessing(computers_df)\n",
    "    \n",
    "    # Save the new normalized and simplified data to a CSV file to load later\n",
    "    norm_computers.to_csv('data/train/computers_train_xlarge_norm_simple.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the data if the simple and normalized data does not exist\n",
    "if not os.path.exists('data/train/computers_train_xlarge_norm_simple.csv'):\n",
    "    create_simple_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "computer_df = pd.read_csv('data/train/computers_train_xlarge_norm_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See some of the data. There is clearly a separation between the positive and negative examples\n",
    "computer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_df(df):\n",
    "    \"\"\"\n",
    "    Returns a shuffled dataframe with an equal amount of positive and negative examples\n",
    "    \"\"\"\n",
    "    # Get the positive and negative examples\n",
    "    pos_df = df.loc[df['label'] == 1]\n",
    "    neg_df = df.loc[df['label'] == 0]\n",
    "    \n",
    "    # Shuffle the data\n",
    "    pos_df = pos_df.sample(frac=1)\n",
    "    neg_df = neg_df.sample(frac=1)\n",
    "    \n",
    "    # Concatenate the positive and negative examples and \n",
    "    # make sure there are only as many negative examples as positive examples\n",
    "    final_df = pd.concat([pos_df[:min(len(pos_df), len(neg_df))], neg_df[:min(len(pos_df), len(neg_df))]])\n",
    "    \n",
    "    # Shuffle the final data once again\n",
    "    final_df.sample(frac=1)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the dataframe with equal numbers of positive and negative examples\n",
    "# and is shuffled\n",
    "if not os.path.exists('data/train/computers_train_bal_shuffle.csv'):\n",
    "    create_train_df(computer_df).to_csv('data/train/computers_train_bal_shuffle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_computer_df = pd.read_csv('data/train/computers_train_bal_shuffle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_one</th>\n",
       "      <th>title_two</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corsair carbide air 240 windowed</td>\n",
       "      <td>corsair carbide series air 240 cube micro atx ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a8 7670k black edition quad core amd cpu fan h...</td>\n",
       "      <td>amd a8 7650k 3 3ghz pccomponentes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazonbasics 13 3 inch laptop sleeve black acc...</td>\n",
       "      <td>amazonbasics 13 3 inch laptop sleeve black car...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eg0146fartr hp 146 gb 6g 10k 2 5 dp sas hdd ne...</td>\n",
       "      <td>eg0146fartr hp 146 gb 6g 10k 2 5 dp sas hdd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usb 3 0 external adapter cable 2 5 inch hard d...</td>\n",
       "      <td>transcend ssd370 solid state drive ssd 2 5 sat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19375</th>\n",
       "      <td>356816 001 ml350t g4p xeon 3 2 2mb 512mb whole...</td>\n",
       "      <td>409159 b21 hp xeon e5345 2 33ghz dl160 g3 new ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19376</th>\n",
       "      <td>buy online samsung 750 evo series 120gb ssd mz...</td>\n",
       "      <td>ssd 750 basic 120 gb tradineur com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19377</th>\n",
       "      <td>628061 s21 hp g8 g9 3 tb 6g 7 2k 5 sata sc new...</td>\n",
       "      <td>628061 s21 hp g8 g9 3 tb 6g 7 2k 5 sata sc new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19378</th>\n",
       "      <td>buy online zotac gtx 1060 6gb amp edition grap...</td>\n",
       "      <td>msi nvidia geforce gtx 1080 8gb gaming x rgb g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19379</th>\n",
       "      <td>hyperx fury blue 4gb 1600mhz ddr3 tradineur com</td>\n",
       "      <td>mem ria ram hyperx fury 4gb 1x4gb ddr3 1600mhz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title_one  \\\n",
       "0                       corsair carbide air 240 windowed   \n",
       "1      a8 7670k black edition quad core amd cpu fan h...   \n",
       "2      amazonbasics 13 3 inch laptop sleeve black acc...   \n",
       "3      eg0146fartr hp 146 gb 6g 10k 2 5 dp sas hdd ne...   \n",
       "4      usb 3 0 external adapter cable 2 5 inch hard d...   \n",
       "...                                                  ...   \n",
       "19375  356816 001 ml350t g4p xeon 3 2 2mb 512mb whole...   \n",
       "19376  buy online samsung 750 evo series 120gb ssd mz...   \n",
       "19377  628061 s21 hp g8 g9 3 tb 6g 7 2k 5 sata sc new...   \n",
       "19378  buy online zotac gtx 1060 6gb amp edition grap...   \n",
       "19379    hyperx fury blue 4gb 1600mhz ddr3 tradineur com   \n",
       "\n",
       "                                               title_two  label  \n",
       "0      corsair carbide series air 240 cube micro atx ...      1  \n",
       "1                      amd a8 7650k 3 3ghz pccomponentes      1  \n",
       "2      amazonbasics 13 3 inch laptop sleeve black car...      1  \n",
       "3            eg0146fartr hp 146 gb 6g 10k 2 5 dp sas hdd      1  \n",
       "4      transcend ssd370 solid state drive ssd 2 5 sat...      0  \n",
       "...                                                  ...    ...  \n",
       "19375  409159 b21 hp xeon e5345 2 33ghz dl160 g3 new ...      0  \n",
       "19376                 ssd 750 basic 120 gb tradineur com      1  \n",
       "19377  628061 s21 hp g8 g9 3 tb 6g 7 2k 5 sata sc new...      1  \n",
       "19378  msi nvidia geforce gtx 1080 8gb gaming x rgb g...      0  \n",
       "19379  mem ria ram hyperx fury 4gb 1x4gb ddr3 1600mhz...      1  \n",
       "\n",
       "[19380 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_computer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptop Data Preprocessing\n",
    "* Normalize the data\n",
    "* Create negative examples that represent when only a couple of attributes of the laptop data changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the laptop data\n",
    "laptop_df = pd.read_csv('data/train/laptops.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Inches</th>\n",
       "      <th>ScreenResolution</th>\n",
       "      <th>Cpu</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Gpu</th>\n",
       "      <th>OpSys</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price_euros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>IPS Panel Retina Display 2560x1600</td>\n",
       "      <td>Intel Core i5 2.3GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>128GB SSD</td>\n",
       "      <td>Intel Iris Plus Graphics 640</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.37kg</td>\n",
       "      <td>1339.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Macbook Air</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1440x900</td>\n",
       "      <td>Intel Core i5 1.8GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>128GB Flash Storage</td>\n",
       "      <td>Intel HD Graphics 6000</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.34kg</td>\n",
       "      <td>898.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HP</td>\n",
       "      <td>250 G6</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>Full HD 1920x1080</td>\n",
       "      <td>Intel Core i5 7200U 2.5GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>256GB SSD</td>\n",
       "      <td>Intel HD Graphics 620</td>\n",
       "      <td>No OS</td>\n",
       "      <td>1.86kg</td>\n",
       "      <td>575.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>15.4</td>\n",
       "      <td>IPS Panel Retina Display 2880x1800</td>\n",
       "      <td>Intel Core i7 2.7GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>512GB SSD</td>\n",
       "      <td>AMD Radeon Pro 455</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.83kg</td>\n",
       "      <td>2537.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Pro</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3</td>\n",
       "      <td>IPS Panel Retina Display 2560x1600</td>\n",
       "      <td>Intel Core i5 3.1GHz</td>\n",
       "      <td>8GB</td>\n",
       "      <td>256GB SSD</td>\n",
       "      <td>Intel Iris Plus Graphics 650</td>\n",
       "      <td>macOS</td>\n",
       "      <td>1.37kg</td>\n",
       "      <td>1803.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1316</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>Yoga 500-14ISK</td>\n",
       "      <td>2 in 1 Convertible</td>\n",
       "      <td>14.0</td>\n",
       "      <td>IPS Panel Full HD / Touchscreen 1920x1080</td>\n",
       "      <td>Intel Core i7 6500U 2.5GHz</td>\n",
       "      <td>4GB</td>\n",
       "      <td>128GB SSD</td>\n",
       "      <td>Intel HD Graphics 520</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.8kg</td>\n",
       "      <td>638.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1317</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>Yoga 900-13ISK</td>\n",
       "      <td>2 in 1 Convertible</td>\n",
       "      <td>13.3</td>\n",
       "      <td>IPS Panel Quad HD+ / Touchscreen 3200x1800</td>\n",
       "      <td>Intel Core i7 6500U 2.5GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>512GB SSD</td>\n",
       "      <td>Intel HD Graphics 520</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.3kg</td>\n",
       "      <td>1499.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1318</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>IdeaPad 100S-14IBR</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Celeron Dual Core N3050 1.6GHz</td>\n",
       "      <td>2GB</td>\n",
       "      <td>64GB Flash Storage</td>\n",
       "      <td>Intel HD Graphics</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.5kg</td>\n",
       "      <td>229.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1319</td>\n",
       "      <td>HP</td>\n",
       "      <td>15-AC110nv (i7-6500U/6GB/1TB/Radeon</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Core i7 6500U 2.5GHz</td>\n",
       "      <td>6GB</td>\n",
       "      <td>1TB HDD</td>\n",
       "      <td>AMD Radeon R5 M330</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.19kg</td>\n",
       "      <td>764.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1320</td>\n",
       "      <td>Asus</td>\n",
       "      <td>X553SA-XX031T (N3050/4GB/500GB/W10)</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Celeron Dual Core N3050 1.6GHz</td>\n",
       "      <td>4GB</td>\n",
       "      <td>500GB HDD</td>\n",
       "      <td>Intel HD Graphics</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.2kg</td>\n",
       "      <td>369.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Company                              Product  \\\n",
       "0              1   Apple                          MacBook Pro   \n",
       "1              2   Apple                          Macbook Air   \n",
       "2              3      HP                               250 G6   \n",
       "3              4   Apple                          MacBook Pro   \n",
       "4              5   Apple                          MacBook Pro   \n",
       "...          ...     ...                                  ...   \n",
       "1298        1316  Lenovo                       Yoga 500-14ISK   \n",
       "1299        1317  Lenovo                       Yoga 900-13ISK   \n",
       "1300        1318  Lenovo                   IdeaPad 100S-14IBR   \n",
       "1301        1319      HP  15-AC110nv (i7-6500U/6GB/1TB/Radeon   \n",
       "1302        1320    Asus  X553SA-XX031T (N3050/4GB/500GB/W10)   \n",
       "\n",
       "                TypeName  Inches                            ScreenResolution  \\\n",
       "0              Ultrabook    13.3          IPS Panel Retina Display 2560x1600   \n",
       "1              Ultrabook    13.3                                    1440x900   \n",
       "2               Notebook    15.6                           Full HD 1920x1080   \n",
       "3              Ultrabook    15.4          IPS Panel Retina Display 2880x1800   \n",
       "4              Ultrabook    13.3          IPS Panel Retina Display 2560x1600   \n",
       "...                  ...     ...                                         ...   \n",
       "1298  2 in 1 Convertible    14.0   IPS Panel Full HD / Touchscreen 1920x1080   \n",
       "1299  2 in 1 Convertible    13.3  IPS Panel Quad HD+ / Touchscreen 3200x1800   \n",
       "1300            Notebook    14.0                                    1366x768   \n",
       "1301            Notebook    15.6                                    1366x768   \n",
       "1302            Notebook    15.6                                    1366x768   \n",
       "\n",
       "                                       Cpu   Ram               Memory  \\\n",
       "0                     Intel Core i5 2.3GHz   8GB            128GB SSD   \n",
       "1                     Intel Core i5 1.8GHz   8GB  128GB Flash Storage   \n",
       "2               Intel Core i5 7200U 2.5GHz   8GB            256GB SSD   \n",
       "3                     Intel Core i7 2.7GHz  16GB            512GB SSD   \n",
       "4                     Intel Core i5 3.1GHz   8GB            256GB SSD   \n",
       "...                                    ...   ...                  ...   \n",
       "1298            Intel Core i7 6500U 2.5GHz   4GB            128GB SSD   \n",
       "1299            Intel Core i7 6500U 2.5GHz  16GB            512GB SSD   \n",
       "1300  Intel Celeron Dual Core N3050 1.6GHz   2GB   64GB Flash Storage   \n",
       "1301            Intel Core i7 6500U 2.5GHz   6GB              1TB HDD   \n",
       "1302  Intel Celeron Dual Core N3050 1.6GHz   4GB            500GB HDD   \n",
       "\n",
       "                               Gpu       OpSys  Weight  Price_euros  \n",
       "0     Intel Iris Plus Graphics 640       macOS  1.37kg      1339.69  \n",
       "1           Intel HD Graphics 6000       macOS  1.34kg       898.94  \n",
       "2            Intel HD Graphics 620       No OS  1.86kg       575.00  \n",
       "3               AMD Radeon Pro 455       macOS  1.83kg      2537.45  \n",
       "4     Intel Iris Plus Graphics 650       macOS  1.37kg      1803.60  \n",
       "...                            ...         ...     ...          ...  \n",
       "1298         Intel HD Graphics 520  Windows 10   1.8kg       638.00  \n",
       "1299         Intel HD Graphics 520  Windows 10   1.3kg      1499.00  \n",
       "1300             Intel HD Graphics  Windows 10   1.5kg       229.00  \n",
       "1301            AMD Radeon R5 M330  Windows 10  2.19kg       764.00  \n",
       "1302             Intel HD Graphics  Windows 10   2.2kg       369.00  \n",
       "\n",
       "[1303 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will be used in order to exchange the different attributes\n",
    "# to create negative examples\n",
    "class Attributes():\n",
    "    company = {'Apple'}\n",
    "    product = {'MacBook Pro'}\n",
    "    inches = {'13.3'}\n",
    "    cpu = {'Intel Core i5 2.3GHz'}\n",
    "    ram = {'4GB'}\n",
    "    memory = {'256GB SSD'}\n",
    "    gpu = {'Intel HD Graphics 520'}\n",
    "    screen = {'1440x900'}\n",
    "    \n",
    "    def get_all_data():\n",
    "        return {\n",
    "            'company': Attributes.company,\n",
    "            'product': Attributes.product,\n",
    "            'inches': Attributes.inches,\n",
    "            'cpu': Attributes.cpu,\n",
    "            'ram': Attributes.ram,\n",
    "            'memory': Attributes.memory,\n",
    "            'gpu': Attributes.gpu,\n",
    "            'screen': Attributes.screen\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attribute sets\n",
    "def create_attribute_sets(df):\n",
    "    Attributes.company.update([row.Company for row in laptop_df[['Company']].itertuples()])\n",
    "    Attributes.product.update([row.Product for row in laptop_df[['Product']].itertuples()])\n",
    "    Attributes.inches.update([str(row.Inches) for row in laptop_df[['Inches']].itertuples()])\n",
    "    Attributes.cpu.update([row.Cpu for row in laptop_df[['Cpu']].itertuples()])\n",
    "    Attributes.ram.update([row.Ram for row in laptop_df[['Ram']].itertuples()])\n",
    "    Attributes.memory.update([row.Memory for row in laptop_df[['Memory']].itertuples()])\n",
    "    Attributes.gpu.update([row.Gpu for row in laptop_df[['Gpu']].itertuples()])\n",
    "    Attributes.screen.update([row.ScreenResolution for row in laptop_df[['ScreenResolution']].itertuples()])\n",
    "\n",
    "create_attribute_sets(laptop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_row(row):\n",
    "    # Note: got rid of everything after the '(' because it has info about the actual specs of the laptop\n",
    "    # so if we change the specs, we need to fix that too\n",
    "    return ' '.join([row['Company'], row['Product'].split('(')[0], row['TypeName'], str(row['Inches']), 'inch',  row['ScreenResolution'], row['Cpu'], row['Ram'], 'ram', row['Memory'], 'ram', row['Gpu']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the negative examples for the laptop data\n",
    "# The laptop_df is the original data, the new_df is the dataframe to append the new data to\n",
    "# and the attributes are the attributes to swap for the new data\n",
    "def create_neg_laptop_data(laptop_df, attributes):\n",
    "    new_column_names = ['title_one', 'title_two', 'label']\n",
    "    negative_df = pd.DataFrame(columns = new_column_names)\n",
    "    for row in range(len(laptop_df)):\n",
    "        # Create a copy of the row for the negative example\n",
    "        neg_row = laptop_df.iloc[row]\n",
    "        for attribute_class in attributes:\n",
    "            # Get the row in the laptop_data\n",
    "            orig_row = laptop_df.iloc[row]\n",
    "            \n",
    "            # Get the attribute that we are trying to change\n",
    "            attribute_val = orig_row[attribute_class]\n",
    "            \n",
    "            # Temporarily value for the new value\n",
    "            new_val = attribute_val\n",
    "            \n",
    "            # Make sure we really get a new attribute\n",
    "            while new_val == attribute_val:\n",
    "                new_val = random.sample(Attributes.get_all_data()[attribute_class.lower()], 1)[0]\n",
    "            \n",
    "            # Change the value in the neg_row to the new value\n",
    "            neg_row[attribute_class] = new_val\n",
    "            \n",
    "            # Concatenate and normalize the data\n",
    "            title_one = remove_stop_words(concatenate_row(orig_row).lower())\n",
    "            title_two = remove_stop_words(concatenate_row(neg_row).lower())\n",
    "            \n",
    "            # Append the data to the new df\n",
    "            negative_df = negative_df.append(pd.DataFrame([[title_one, title_two, 0]], columns=new_column_names))\n",
    "    \n",
    "    return negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\miniconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "neg_df = create_neg_laptop_data(laptop_df, attributes=['Cpu', 'Memory', 'Ram', 'Inches', 'Product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_one</th>\n",
       "      <th>title_two</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple macbook pro ultrabook 18 4 inch ips pane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple ux410ua gv350t ultrabook 18 4 inch ips p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus x553sa xx031t notebook 11 6 inch 1366x768...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus portege x20w 10v notebook 11 6 inch 1366x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_one  \\\n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "..                                                ...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "\n",
       "                                            title_two label  \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...     0  \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...     0  \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...     0  \n",
       "0   apple macbook pro ultrabook 18 4 inch ips pane...     0  \n",
       "0   apple ux410ua gv350t ultrabook 18 4 inch ips p...     0  \n",
       "..                                                ...   ...  \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...     0  \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...     0  \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...     0  \n",
       "0   asus x553sa xx031t notebook 11 6 inch 1366x768...     0  \n",
       "0   asus portege x20w 10v notebook 11 6 inch 1366x...     0  \n",
       "\n",
       "[6515 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the postive examples for the laptop data\n",
    "# The laptop_df is the original data, the new_df is the dataframe to append the new data to\n",
    "# and the attributes are the attributes to swap or delete for the new data\n",
    "def create_pos_laptop_data(laptop_df, rm_attrs, add_attrs):\n",
    "    new_column_names = ['title_one', 'title_two', 'label']\n",
    "    pos_df = pd.DataFrame(columns = new_column_names)\n",
    "    for row in range(len(laptop_df)):\n",
    "        # Remove the attribute from the new title\n",
    "        for attr_list in rm_attrs:\n",
    "            # Create a copy of the row for the negative example\n",
    "            new_row = laptop_df.iloc[row]\n",
    "            orig_row = laptop_df.iloc[row]\n",
    "            for attr in attr_list:\n",
    "                new_row[attr] = ''\n",
    "        \n",
    "            title_one = remove_stop_words(concatenate_row(orig_row).lower())\n",
    "            title_two = remove_stop_words(concatenate_row(new_row).lower())\n",
    "\n",
    "            # Occassionally add in the operating system just to switch it up\n",
    "            if (random.sample([0, 1], 1)):\n",
    "                for attr in add_attrs:\n",
    "                    title_two += ' ' + orig_row[attr].lower()\n",
    "\n",
    "            pos_df = pos_df.append(pd.DataFrame([[title_one, title_two, 1]], columns=new_column_names))\n",
    "\n",
    "    return pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\miniconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pos_df = create_pos_laptop_data(laptop_df, rm_attrs = [['Company'], ['TypeName'], ['ScreenResolution'], ['Product'], ['TypeName', 'ScreenResolution']], add_attrs=['OpSys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_one</th>\n",
       "      <th>title_two</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>macbook pro ultrabook 13 3 inch ips panel reti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple macbook pro 13 3 inch ips panel retina d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch intel co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple ultrabook 13 3 inch ips panel retina dis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple macbook pro ultrabook 13 3 inch ips pane...</td>\n",
       "      <td>apple macbook pro 13 3 inch intel core i5 2 3g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>x553sa xx031t notebook 15 6 inch 1366x768 inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus x553sa xx031t 15 6 inch 1366x768 intel ce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch intel ce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus notebook 15 6 inch 1366x768 intel celeron...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus x553sa xx031t notebook 15 6 inch 1366x768...</td>\n",
       "      <td>asus x553sa xx031t 15 6 inch intel celeron dua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_one  \\\n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "0   apple macbook pro ultrabook 13 3 inch ips pane...   \n",
       "..                                                ...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "0   asus x553sa xx031t notebook 15 6 inch 1366x768...   \n",
       "\n",
       "                                            title_two label  \n",
       "0   macbook pro ultrabook 13 3 inch ips panel reti...     1  \n",
       "0   apple macbook pro 13 3 inch ips panel retina d...     1  \n",
       "0   apple macbook pro ultrabook 13 3 inch intel co...     1  \n",
       "0   apple ultrabook 13 3 inch ips panel retina dis...     1  \n",
       "0   apple macbook pro 13 3 inch intel core i5 2 3g...     1  \n",
       "..                                                ...   ...  \n",
       "0   x553sa xx031t notebook 15 6 inch 1366x768 inte...     1  \n",
       "0   asus x553sa xx031t 15 6 inch 1366x768 intel ce...     1  \n",
       "0   asus x553sa xx031t notebook 15 6 inch intel ce...     1  \n",
       "0   asus notebook 15 6 inch 1366x768 intel celeron...     1  \n",
       "0   asus x553sa xx031t 15 6 inch intel celeron dua...     1  \n",
       "\n",
       "[6515 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptop Data Concatenation\n",
    "Create on dataframe and shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_laptop_data(pos_df, neg_df):\n",
    "    pos_df.sample(frac=1)\n",
    "    neg_df.sample(frac=1)\n",
    "    final_laptop_df = pd.concat([pos_df[:min(len(pos_df), len(neg_df))], neg_df[:min(len(pos_df), len(neg_df))]])\n",
    "    final_laptop_df = final_laptop_df.sample(frac=1)\n",
    "    return final_laptop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_laptop_df = create_laptop_data(pos_df, neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_one</th>\n",
       "      <th>title_two</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acer chromebook c731 c78g netbook 11 6 inch ip...</td>\n",
       "      <td>acer vivobook max netbook 14 0 inch ips panel ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dell vostro 5471 ultrabook 14 0 inch full hd 1...</td>\n",
       "      <td>dell vostro 5471 14 0 inch intel core i5 8250u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acer aspire a517 51g notebook 15 6 inch ips pa...</td>\n",
       "      <td>acer aspire a517 51g notebook 15 6 inch intel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asus zenbook ux310uq gl026t ultrabook 13 3 inc...</td>\n",
       "      <td>asus zenbook ux310uq gl026t ultrabook 11 3 inc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dell inspiron 7577 gaming 15 6 inch ips panel ...</td>\n",
       "      <td>dell inspiron 7577 gaming 15 6 inch ips panel ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenovo ideapad 320 15ikbn notebook 15 6 inch f...</td>\n",
       "      <td>lenovo notebook 15 6 inch full hd 1920x1080 in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dell vostro 5568 notebook 15 6 inch full hd 19...</td>\n",
       "      <td>dell vostro 5568 notebook 15 6 inch full hd 19...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dell latitude 3570 notebook 15 6 inch 1366x768...</td>\n",
       "      <td>dell latitude 3570 notebook 15 6 inch 1366x768...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dell xps 13 ultrabook 13 3 inch quad hd touchs...</td>\n",
       "      <td>dell xps 13 13 3 inch quad hd touchscreen 3200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenovo legion y520 15ikbn gaming 15 6 inch ips...</td>\n",
       "      <td>lenovo legion y520 15ikbn gaming 15 6 inch ips...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13030 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_one  \\\n",
       "0   acer chromebook c731 c78g netbook 11 6 inch ip...   \n",
       "0   dell vostro 5471 ultrabook 14 0 inch full hd 1...   \n",
       "0   acer aspire a517 51g notebook 15 6 inch ips pa...   \n",
       "0   asus zenbook ux310uq gl026t ultrabook 13 3 inc...   \n",
       "0   dell inspiron 7577 gaming 15 6 inch ips panel ...   \n",
       "..                                                ...   \n",
       "0   lenovo ideapad 320 15ikbn notebook 15 6 inch f...   \n",
       "0   dell vostro 5568 notebook 15 6 inch full hd 19...   \n",
       "0   dell latitude 3570 notebook 15 6 inch 1366x768...   \n",
       "0   dell xps 13 ultrabook 13 3 inch quad hd touchs...   \n",
       "0   lenovo legion y520 15ikbn gaming 15 6 inch ips...   \n",
       "\n",
       "                                            title_two label  \n",
       "0   acer vivobook max netbook 14 0 inch ips panel ...     0  \n",
       "0   dell vostro 5471 14 0 inch intel core i5 8250u...     1  \n",
       "0   acer aspire a517 51g notebook 15 6 inch intel ...     1  \n",
       "0   asus zenbook ux310uq gl026t ultrabook 11 3 inc...     0  \n",
       "0   dell inspiron 7577 gaming 15 6 inch ips panel ...     0  \n",
       "..                                                ...   ...  \n",
       "0   lenovo notebook 15 6 inch full hd 1920x1080 in...     1  \n",
       "0   dell vostro 5568 notebook 15 6 inch full hd 19...     0  \n",
       "0   dell latitude 3570 notebook 15 6 inch 1366x768...     0  \n",
       "0   dell xps 13 13 3 inch quad hd touchscreen 3200...     1  \n",
       "0   lenovo legion y520 15ikbn gaming 15 6 inch ips...     0  \n",
       "\n",
       "[13030 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_laptop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Creation Functions\n",
    "Generates the embeddings and saves them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LEN: 42 EMBEDDING_SHAPE: (300,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Definitions of some sizes in the training set\n",
    "\"\"\"\n",
    "MAX_LEN = 42\n",
    "EMBEDDING_SHAPE = (300,)\n",
    "print('MAX_LEN: ' + str(MAX_LEN), 'EMBEDDING_SHAPE: ' + str(EMBEDDING_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the numpy files of all the training embedddings\n",
    "We will have two numpy files:\n",
    "1. The training/validation/test sets\n",
    "2. The labels\n",
    "\"\"\"\n",
    "\n",
    "def create_embeddings(df):\n",
    "    # Create the numpy arrays for storing the embeddings and labels\n",
    "    total_embeddings = np.zeros(shape=(len(df), 2, MAX_LEN, EMBEDDING_SHAPE[0]))\n",
    "    labels = np.zeros(shape=(len(df)))\n",
    "    \n",
    "    # I know this is a terrible way of doing this, but iterate over the dataframe\n",
    "    # and generate the embeddings to add to the numpy array\n",
    "    for idx, row in enumerate(df.itertuples()):\n",
    "        for word_idx, word in enumerate(row.title_one.split()):\n",
    "            total_embeddings[idx, 0, word_idx] = fasttext_model[word]\n",
    "            \n",
    "        for word_idx, word in enumerate(row.title_two.split()):\n",
    "            total_embeddings[idx, 1, word_idx] = fasttext_model[word]\n",
    "            \n",
    "        labels[idx] = row.label\n",
    "        \n",
    "    return total_embeddings, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(df, embeddings_name, labels_name):\n",
    "    \"\"\"\n",
    "    Saves the embeddings given the embeddings file name and labels file name\n",
    "    \"\"\"\n",
    "    if not os.path.exists('data/numpy_data/' + embeddings_name + '.npy'):\n",
    "        embeddings, labels = create_embeddings(df)\n",
    "        with open('data/numpy_data/' + embeddings_name + '.npy', 'wb') as f:\n",
    "            np.save(f, embeddings)\n",
    "\n",
    "        with open('data/numpy_data/' + labels_name + '.npy', 'wb') as f:\n",
    "            np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_and_labels(embeddings_name, labels_name):\n",
    "    loaded_embeddings = None\n",
    "    labels = None\n",
    "    with open('data/numpy_data/' + embeddings_name + '.npy', 'rb') as f:\n",
    "        loaded_embeddings = np.load(f)\n",
    "        loaded_embeddings = np.transpose(loaded_embeddings, (1, 0, 2, 3))\n",
    "    \n",
    "    with open('data/numpy_data/' + labels_name + '.npy', 'rb') as f:\n",
    "        labels = np.load(f)\n",
    "    \n",
    "    return loaded_embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(df):\n",
    "    max_len = 0\n",
    "    for row in df.itertuples():\n",
    "        if len(row.title_one.split(' ')) > max_len:\n",
    "            max_len = len(row.title_one.split(' '))\n",
    "            \n",
    "        if len(row.title_two.split(' ')) > max_len:\n",
    "            max_len = len(row.title_two.split(' '))\n",
    "    \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Embeddings\n",
    "Save the embeddings for the different types of data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate everything\n",
    "total_data = pd.concat([final_computer_df, final_laptop_df])\n",
    "total_data = total_data.sample(frac=1)\n",
    "save_embeddings(final_computer_df, 'bal_computers_embeddings', 'bal_computers_labels')\n",
    "save_embeddings(final_laptop_df, 'laptop_embeddings', 'laptop_labels')\n",
    "save_embeddings(total_data, 'all_embeddings', 'all_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels = load_embeddings_and_labels('all_embeddings', 'all_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32410"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_one</th>\n",
       "      <th>title_two</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16663</th>\n",
       "      <td>acer aspire es1 132 p194 business notebook 331...</td>\n",
       "      <td>acer aspire es1 132 p194 business notebook len...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenovo ideapad 310 15ikb notebook 15 6 inch fu...</td>\n",
       "      <td>lenovo ideapad 310 15ikb 15 6 inch intel core ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hp 250 g6 ultrabook 15 6 inch full hd 1920x108...</td>\n",
       "      <td>hp 250 g6 ultrabook 15 6 inch full hd 1920x108...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>corsair vengeance led 16gb 2x8gb ddr4pc4 21300...</td>\n",
       "      <td>corsair vengeance red led 16gb 2x8gb ddr4 pc4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>kingston datatraveler 100 g3 32 gb usb 3 0 dt1...</td>\n",
       "      <td>usb datatraveler 100 g3 3 0 stick 32 gb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>seagate laptop sshd 1 tb internal st1000lm014 ...</td>\n",
       "      <td>wd green wds240g1g0a ssd 240 go sata 6gb garan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenovo ideapad 320 17isk notebook 17 3 inch 16...</td>\n",
       "      <td>lenovo notebook 17 3 inch 1600x900 intel core ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>sandisk extreme microsdhc 64gb type 10 acheter...</td>\n",
       "      <td>sandisk extreme microsdhc 64gb type 10 kopen e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10730</th>\n",
       "      <td>dg0146famwl hp 146 gb 6g 10k 2 5 dp sas new pa...</td>\n",
       "      <td>dg0146famwl hp 146 gb 6g 10k 2 5 dp sas hdd ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hp probook x360 2 1 convertible 11 6 inch touc...</td>\n",
       "      <td>hp 2 1 convertible 11 6 inch touchscreen 1366x...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title_one  \\\n",
       "16663  acer aspire es1 132 p194 business notebook 331...   \n",
       "0      lenovo ideapad 310 15ikb notebook 15 6 inch fu...   \n",
       "0      hp 250 g6 ultrabook 15 6 inch full hd 1920x108...   \n",
       "3086   corsair vengeance led 16gb 2x8gb ddr4pc4 21300...   \n",
       "15990  kingston datatraveler 100 g3 32 gb usb 3 0 dt1...   \n",
       "...                                                  ...   \n",
       "11649  seagate laptop sshd 1 tb internal st1000lm014 ...   \n",
       "0      lenovo ideapad 320 17isk notebook 17 3 inch 16...   \n",
       "15592  sandisk extreme microsdhc 64gb type 10 acheter...   \n",
       "10730  dg0146famwl hp 146 gb 6g 10k 2 5 dp sas new pa...   \n",
       "0      hp probook x360 2 1 convertible 11 6 inch touc...   \n",
       "\n",
       "                                               title_two label  \n",
       "16663  acer aspire es1 132 p194 business notebook len...     1  \n",
       "0      lenovo ideapad 310 15ikb 15 6 inch intel core ...     1  \n",
       "0      hp 250 g6 ultrabook 15 6 inch full hd 1920x108...     0  \n",
       "3086   corsair vengeance red led 16gb 2x8gb ddr4 pc4 ...     1  \n",
       "15990            usb datatraveler 100 g3 3 0 stick 32 gb     1  \n",
       "...                                                  ...   ...  \n",
       "11649  wd green wds240g1g0a ssd 240 go sata 6gb garan...     0  \n",
       "0      lenovo notebook 17 3 inch 1600x900 intel core ...     1  \n",
       "15592  sandisk extreme microsdhc 64gb type 10 kopen e...     1  \n",
       "10730  dg0146famwl hp 146 gb 6g 10k 2 5 dp sas hdd ne...     1  \n",
       "0      hp 2 1 convertible 11 6 inch touchscreen 1366x...     1  \n",
       "\n",
       "[32410 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (2, 28410, 42, 300)\n",
      "Val shape: (2, 2000, 42, 300)\n",
      "Test shape: (2, 2000, 42, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train1 = embeddings[0, :len(labels) - 4000]\n",
    "X_train2 = embeddings[1, :len(labels) - 4000]\n",
    "X_train = np.stack((X_train1, X_train2))\n",
    "print('Training shape: ' + str(X_train.shape))\n",
    "\n",
    "X_val1 = embeddings[0, len(labels) - 4000:len(labels) - 2000]\n",
    "X_val2 = embeddings[1, len(labels) - 4000:len(labels) - 2000]\n",
    "X_val = np.stack((X_val1, X_val2))\n",
    "print('Val shape: ' + str(X_val.shape))\n",
    "\n",
    "X_test1 = embeddings[0, len(labels) - 2000:]\n",
    "X_test2 = embeddings[1, len(labels) - 2000:]\n",
    "X_test = np.stack((X_test1, X_test2))\n",
    "print('Test shape: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (28410,)\n",
      "Val shape: (2000,)\n",
      "Test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "Y_train = labels[:len(labels) - 4000]\n",
    "print('Training labels shape:', str(Y_train.shape))\n",
    "\n",
    "Y_val = labels[len(labels) - 4000:len(labels) - 2000]\n",
    "print('Val shape:', str(Y_val.shape))\n",
    "\n",
    "Y_test = labels[len(labels) - 2000:]\n",
    "print('Test shape:', str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = convert_to_one_hot(Y_train.astype(np.int32), 2)\n",
    "Y_val = convert_to_one_hot(Y_val.astype(np.int32), 2)\n",
    "Y_test = convert_to_one_hot(Y_test.astype(np.int32), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Info\n",
    "\n",
    "For the model, we are going to use LSTMs with a Constrastive Loss Function \n",
    "that will also be used to predict whether the two products are the same \n",
    "\n",
    "First, we have to convert the titles to embeddings through FastText before feeding into the LSTM.\n",
    "The embedding part of this model will not be a layer because:\n",
    "* The fasttext model would be time consuming and annoying to get to work with an embedding layer in Keras\n",
    "* The fasttext model is not going to be getting its embeddings optimized, so there is really no point in adding it as an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_distance(vectors):\n",
    "    x, y = vectors\n",
    "    return tf.square(x - y)\n",
    "\n",
    "def euclidean_dist_out_shape(shapes):\n",
    "    # Both inputs are fed in, so just use one of them and get the first value in the shape\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],)\n",
    "\n",
    "def siamese_network(input_shape):\n",
    "    # Defines our inputs\n",
    "    left_title = Input(input_shape, dtype='float32')\n",
    "    right_title = Input(input_shape, dtype='float32')\n",
    "    \n",
    "    # The LSTM units\n",
    "    model = tf.keras.Sequential(name='siamese_model')\n",
    "    model.add(LSTM(units=256, return_sequences=True, name='lstm_1'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(LSTM(units=128, return_sequences=True, name='lstm_2'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(LSTM(units=128, name='lstm_3'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    # The dense layers\n",
    "    model.add(Dense(units=1024, activation='elu', name='dense_1'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=512, activation='elu', name='dense_2'))\n",
    "    \n",
    "    # Forward propagate through the model to generate the encodings\n",
    "    encoded_left_title = model(left_title)\n",
    "    encoded_right_title = model(right_title)\n",
    "\n",
    "    SquareDistanceLayer = Lambda(square_distance)\n",
    "    distance = SquareDistanceLayer([encoded_left_title, encoded_right_title])\n",
    "    \n",
    "    prediction = Dense(units=2, activation='softmax')(distance)\n",
    "    # Create and return the network\n",
    "    siamese_net = tf.keras.Model(inputs=[left_title, right_title], outputs=prediction, name='siamese_network')\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: for the constrastive loss, because 0 denotes that they are from the same class\n",
    "# and one denotes they are from a different class, I swaped the (Y) and (1 - Y) terms\n",
    "\n",
    "def constrastive_loss(y_true, y_pred):\n",
    "    margin = 2.0\n",
    "    d = y_pred\n",
    "    d_sqrt = tf.sqrt(d)\n",
    "    #tf.print('\\nY Pred: ', d, 'Shape: ', tf.shape(d))\n",
    "    #tf.print('\\nY True: ', y_true, 'Shape: ', tf.shape(y_true))\n",
    "    \n",
    "    loss = (y_true * d) + ((1 - y_true) * tf.square(tf.maximum(0., margin - d_sqrt)))\n",
    "    \n",
    "    #tf.print('\\n Constrastive Loss: ', loss, 'Shape: ', tf.shape(loss))\n",
    "    loss = 0.5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metric for constrastive loss because values close to 0 are equal and values high are different\n",
    "# 0.5 is the threshold here\n",
    "def constrastive_accuracy(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_true, tf.cast(y_pred < 0.5, y_true.dtype)), y_true.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    \"\"\"\n",
    "    Saves a model with a particular name\n",
    "    \"\"\"\n",
    "    model.save('models/' + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"siamese_network\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 42, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 42, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "siamese_model (Sequential)      (None, 512)          1555968     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 512)          0           siamese_model[0][0]              \n",
      "                                                                 siamese_model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            1026        lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,556,994\n",
      "Trainable params: 1,556,994\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = siamese_network((MAX_LEN, EMBEDDING_SHAPE[0],))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "lr = 0.001\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28410 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "28410/28410 [==============================] - 266s 9ms/sample - loss: 0.5382 - accuracy: 0.6259 - val_loss: 0.3857 - val_accuracy: 0.4935\n",
      "Epoch 2/50\n",
      "28410/28410 [==============================] - 271s 10ms/sample - loss: 0.5155 - accuracy: 0.6437 - val_loss: 0.4205 - val_accuracy: 0.4930\n",
      "Epoch 3/50\n",
      "28410/28410 [==============================] - 271s 10ms/sample - loss: 0.5130 - accuracy: 0.6519 - val_loss: 0.3983 - val_accuracy: 0.4935\n",
      "Epoch 4/50\n",
      "28410/28410 [==============================] - 271s 10ms/sample - loss: 0.4827 - accuracy: 0.6550 - val_loss: 0.3809 - val_accuracy: 0.4930\n",
      "Epoch 5/50\n",
      "28410/28410 [==============================] - 274s 10ms/sample - loss: 0.4848 - accuracy: 0.6597 - val_loss: 0.3898 - val_accuracy: 0.4930\n",
      "Epoch 6/50\n",
      "28410/28410 [==============================] - 273s 10ms/sample - loss: 0.6718 - accuracy: 0.5325 - val_loss: 0.6914 - val_accuracy: 0.4930\n",
      "Epoch 7/50\n",
      "28410/28410 [==============================] - 272s 10ms/sample - loss: 0.5217 - accuracy: 0.6542 - val_loss: 0.3677 - val_accuracy: 0.5010\n",
      "Epoch 8/50\n",
      "28410/28410 [==============================] - 275s 10ms/sample - loss: 0.4840 - accuracy: 0.6583 - val_loss: 0.3600 - val_accuracy: 0.4995\n",
      "Epoch 9/50\n",
      "  768/28410 [..............................] - ETA: 4:18 - loss: 0.4651 - accuracy: 0.6534"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-a32595c54a3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x=[X_train1, X_train2], y=Y_train, batch_size=64, epochs=50, validation_data=([X_val[0], X_val[1]], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "results = model.evaluate([X_test1, X_test2], Y_test, batch_size=16)\n",
    "print('test loss, test acc: ', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jason\\miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model_name = 'Softmax-LSTM-_epochs_loss'\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Testing\n",
    "Converts titles into embeddings arrays and allow the model to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_one = 'True Wireless Earbuds VANKYO X200 Bluetooth 5 0 Earbuds in Ear TWS Stereo Headphones Smart LED Display Charging Case IPX8 Waterproof 120H Playtime Built Mic Deep Bass Sports Work'\n",
    "title_two = 'TOZO T10 Bluetooth 5 0 Wireless Earbuds Wireless Charging Case IPX8 Waterproof TWS Stereo Headphones Ear Built Mic Headset Premium Sound Deep Bass Sport Black'\n",
    "title_one_arr = np.zeros((1, 42, 300))\n",
    "title_two_arr = np.zeros((1, 42, 300))\n",
    "title_one.lower()\n",
    "title_two.lower()\n",
    "for idx, word in enumerate(title_one.split(' ')):\n",
    "    title_one_arr[0, idx] = fasttext_model[word]\n",
    "    \n",
    "for idx, word in enumerate(title_two.split(' ')):\n",
    "    title_two_arr[0, idx] = fasttext_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27092224, 0.7290778 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([title_one_arr, title_two_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
