{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"Local Imports\"\"\"\n",
    "from src.preprocessing import remove_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train/total_data.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69c8613047e404fb03a5eec03ba27ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=433.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6673e47eb9e44cc88ee65cac0b45379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a226cb30801a4dce80687b41199b5476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=440473133.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, h_size, max_length):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        # The hidden layer size for the classification token (CLS) in BERT\n",
    "        # In this case, it is 768\n",
    "        self.h_size = h_size\n",
    "        \n",
    "        # The max length a title could be for padding purposes\n",
    "        self.max_length = max_length * 2\n",
    "        \n",
    "        # BERT tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        # BERT model\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        # We want to freeze all parameters except the last couple for training\n",
    "        for idx, param in enumerate(self.bert.parameters()):\n",
    "            if idx < 170:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Fully-Connected layers\n",
    "        self.fc1 = nn.Linear(self.h_size, 384)\n",
    "        self.fc2 = nn.Linear(384, 2)\n",
    "        \n",
    "        # Dropout for overfitting\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Softmax for prediction\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is going to be a numpy array of [sentenceA, sentenceB].\n",
    "        Model using BERT to make a prediction of whether the two titles represent \n",
    "        the same entity.\n",
    "        \"\"\"\n",
    "        # BERT for title similarity works having the two sentences (sentence1, sentence2)\n",
    "        # and ordering them in both combinations that they could be (sentence1 + sentence2)\n",
    "        # and (sentence2 + sentence1). That is why we do np.flip() on x (the input sentences)\n",
    "        input1 = self.tokenizer(x.tolist(),\n",
    "                                return_tensors='pt',\n",
    "                                padding='max_length',\n",
    "                                truncation=True,\n",
    "                                max_length=self.max_length)\n",
    "\n",
    "        input2 = self.tokenizer(np.flip(x, 1).tolist(),\n",
    "                                return_tensors='pt',\n",
    "                                padding='max_length',\n",
    "                                truncation=True,\n",
    "                                max_length=self.max_length)\n",
    "        \n",
    "        # Send the inputs through BERT\n",
    "        # We index at 1 because that gives us the classification token (CLS)\n",
    "        # that BERT talks about in the paper (as opposed to each hidden layer for each)\n",
    "        # token embedding\n",
    "        output1 = self.bert(**input1)[1]\n",
    "        output2 = self.bert(**input2)[1]\n",
    "        \n",
    "        # BERT calls for the addition of both \n",
    "        addition = output1 + output2\n",
    "        \n",
    "        # Fully-Connected Layer 1 (input of 768 units and output of 384)\n",
    "        addition = self.fc1(addition)\n",
    "        \n",
    "        # ReLU Activation\n",
    "        additionn = F.relu(addition)\n",
    "        \n",
    "        # Dropout\n",
    "        addition = self.dropout(addition)\n",
    "        \n",
    "        # Fully-Connected Layer 2 (input of 384 units, out of 2 for Softmax)\n",
    "        addition = self.fc2(addition)\n",
    "        \n",
    "        # Dropout\n",
    "        addition = self.dropout(addition)\n",
    "        \n",
    "        # Softmax Activation to get predictions\n",
    "        addition = self.softmax(addition)\n",
    "        \n",
    "        return addition\n",
    "\n",
    "net = SiameseModel(768, 44)\n",
    "net.train()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cross-entropy because we are making a classifier\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Using Adam optimizer\n",
    "opt = AdamW(net.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch    10, loss: 0.747\n",
      "Epoch: 1, Batch    20, loss: 0.763\n",
      "Epoch: 1, Batch    30, loss: 0.766\n",
      "Epoch: 1, Batch    40, loss: 0.696\n",
      "Epoch: 1, Batch    50, loss: 0.745\n",
      "Epoch: 1, Batch    60, loss: 0.716\n",
      "Epoch: 1, Batch    70, loss: 0.696\n",
      "Epoch: 1, Batch    80, loss: 0.699\n",
      "Epoch: 1, Batch    90, loss: 0.712\n",
      "Epoch: 1, Batch   100, loss: 0.704\n",
      "Epoch: 1, Batch   110, loss: 0.697\n",
      "Epoch: 1, Batch   120, loss: 0.694\n",
      "Epoch: 1, Batch   130, loss: 0.710\n",
      "Epoch: 1, Batch   140, loss: 0.694\n",
      "Epoch: 1, Batch   150, loss: 0.699\n",
      "Epoch: 1, Batch   160, loss: 0.694\n",
      "Epoch: 1, Batch   170, loss: 0.688\n",
      "Epoch: 1, Batch   180, loss: 0.695\n",
      "Epoch: 1, Batch   190, loss: 0.683\n",
      "Epoch: 1, Batch   200, loss: 0.690\n",
      "Epoch: 1, Batch   210, loss: 0.693\n",
      "Epoch: 1, Batch   220, loss: 0.707\n",
      "Epoch: 1, Batch   230, loss: 0.691\n",
      "Epoch: 1, Batch   240, loss: 0.703\n",
      "Epoch: 1, Batch   250, loss: 0.697\n",
      "Epoch: 1, Batch   260, loss: 0.696\n",
      "Epoch: 1, Batch   270, loss: 0.696\n",
      "Epoch: 1, Batch   280, loss: 0.702\n",
      "Epoch: 1, Batch   290, loss: 0.688\n",
      "Epoch: 1, Batch   300, loss: 0.695\n",
      "Epoch: 1, Batch   310, loss: 0.684\n",
      "Epoch: 1, Batch   320, loss: 0.681\n",
      "Epoch: 1, Batch   330, loss: 0.681\n",
      "Epoch: 1, Batch   340, loss: 0.682\n",
      "Epoch: 1, Batch   350, loss: 0.686\n",
      "Epoch: 1, Batch   360, loss: 0.683\n",
      "Epoch: 1, Batch   370, loss: 0.692\n",
      "Epoch: 1, Batch   380, loss: 0.680\n",
      "Epoch: 1, Batch   390, loss: 0.685\n",
      "Epoch: 1, Batch   400, loss: 0.680\n",
      "Epoch: 1, Batch   410, loss: 0.687\n",
      "Epoch: 1, Batch   420, loss: 0.672\n",
      "Epoch: 1, Batch   430, loss: 0.693\n",
      "Epoch: 1, Batch   440, loss: 0.681\n",
      "Epoch: 1, Batch   450, loss: 0.678\n",
      "Epoch: 1, Batch   460, loss: 0.680\n",
      "Epoch: 1, Batch   470, loss: 0.689\n",
      "Epoch: 1, Batch   480, loss: 0.674\n",
      "Epoch: 1, Batch   490, loss: 0.675\n",
      "Epoch: 1, Batch   500, loss: 0.681\n",
      "Epoch: 1, Batch   510, loss: 0.674\n",
      "Epoch: 1, Batch   520, loss: 0.683\n",
      "Epoch: 1, Batch   530, loss: 0.689\n",
      "Epoch: 1, Batch   540, loss: 0.673\n",
      "Epoch: 1, Batch   550, loss: 0.669\n",
      "Epoch: 1, Batch   560, loss: 0.672\n",
      "Epoch: 1, Batch   570, loss: 0.658\n",
      "Epoch: 1, Batch   580, loss: 0.664\n",
      "Epoch: 1, Batch   590, loss: 0.661\n",
      "Epoch: 1, Batch   600, loss: 0.664\n",
      "Epoch: 1, Batch   610, loss: 0.660\n",
      "Epoch: 1, Batch   620, loss: 0.675\n",
      "Epoch: 1, Batch   630, loss: 0.663\n",
      "Epoch: 1, Batch   640, loss: 0.653\n",
      "Epoch: 1, Batch   650, loss: 0.675\n",
      "Epoch: 1, Batch   660, loss: 0.657\n",
      "Epoch: 1, Batch   670, loss: 0.649\n",
      "Epoch: 1, Batch   680, loss: 0.668\n",
      "Epoch: 1, Batch   690, loss: 0.662\n",
      "Epoch: 1, Batch   700, loss: 0.646\n",
      "Epoch: 1, Batch   710, loss: 0.656\n",
      "Epoch: 1, Batch   720, loss: 0.652\n",
      "Epoch: 1, Batch   730, loss: 0.655\n",
      "Epoch: 1, Batch   740, loss: 0.657\n",
      "Epoch: 1, Batch   750, loss: 0.643\n",
      "Epoch: 1, Batch   760, loss: 0.659\n",
      "Epoch: 1, Batch   770, loss: 0.646\n",
      "Epoch: 1, Batch   780, loss: 0.646\n",
      "Epoch: 1, Batch   790, loss: 0.656\n",
      "Epoch: 1, Batch   800, loss: 0.655\n",
      "Epoch: 1, Batch   810, loss: 0.627\n",
      "Epoch: 1, Batch   820, loss: 0.636\n",
      "Epoch: 1, Batch   830, loss: 0.647\n",
      "Epoch: 1, Batch   840, loss: 0.646\n",
      "Epoch: 1, Batch   850, loss: 0.625\n",
      "Epoch: 1, Batch   860, loss: 0.622\n",
      "Epoch: 1, Batch   870, loss: 0.607\n",
      "Epoch: 1, Batch   880, loss: 0.607\n",
      "Epoch: 1, Batch   890, loss: 0.637\n",
      "Epoch: 1, Batch   900, loss: 0.612\n",
      "Epoch: 1, Batch   910, loss: 0.624\n",
      "Epoch: 1, Batch   920, loss: 0.611\n",
      "Epoch: 1, Batch   930, loss: 0.623\n",
      "Epoch: 1, Batch   940, loss: 0.618\n",
      "Epoch: 1, Batch   950, loss: 0.610\n",
      "Epoch: 1, Batch   960, loss: 0.620\n",
      "Epoch: 1, Batch   970, loss: 0.586\n",
      "Epoch: 1, Batch   980, loss: 0.614\n",
      "Epoch: 1, Batch   990, loss: 0.584\n",
      "Epoch: 1, Batch  1000, loss: 0.616\n",
      "Epoch: 1, Batch  1010, loss: 0.593\n",
      "Epoch: 1, Batch  1020, loss: 0.608\n",
      "Epoch: 1, Batch  1030, loss: 0.608\n",
      "Epoch: 1, Batch  1040, loss: 0.621\n",
      "Epoch: 1, Batch  1050, loss: 0.574\n",
      "Epoch: 1, Batch  1060, loss: 0.595\n",
      "Epoch: 1, Batch  1070, loss: 0.584\n",
      "Epoch: 1, Batch  1080, loss: 0.575\n",
      "Epoch: 1, Batch  1090, loss: 0.588\n",
      "Epoch: 1, Batch  1100, loss: 0.562\n",
      "Epoch: 1, Batch  1110, loss: 0.607\n",
      "Epoch: 1, Batch  1120, loss: 0.575\n",
      "Epoch: 1, Batch  1130, loss: 0.575\n",
      "Epoch: 1, Batch  1140, loss: 0.546\n",
      "Epoch: 1, Batch  1150, loss: 0.572\n",
      "Epoch: 1, Batch  1160, loss: 0.587\n",
      "Epoch: 1, Batch  1170, loss: 0.537\n",
      "Epoch: 1, Batch  1180, loss: 0.561\n",
      "Epoch: 1, Batch  1190, loss: 0.561\n",
      "Epoch: 1, Batch  1200, loss: 0.580\n",
      "Epoch: 1, Batch  1210, loss: 0.602\n",
      "Epoch: 1, Batch  1220, loss: 0.577\n",
      "Epoch: 1, Batch  1230, loss: 0.594\n",
      "Epoch: 1, Batch  1240, loss: 0.553\n",
      "Epoch: 1, Batch  1250, loss: 0.553\n",
      "Epoch: 1, Batch  1260, loss: 0.558\n",
      "Epoch: 1, Batch  1270, loss: 0.564\n",
      "Epoch: 1, Batch  1280, loss: 0.537\n",
      "Epoch: 1, Batch  1290, loss: 0.537\n",
      "Epoch: 1, Batch  1300, loss: 0.527\n",
      "Epoch: 1, Batch  1310, loss: 0.540\n",
      "Epoch: 1, Batch  1320, loss: 0.545\n",
      "Epoch: 1, Batch  1330, loss: 0.532\n",
      "Epoch: 1, Batch  1340, loss: 0.546\n",
      "Epoch: 1, Batch  1350, loss: 0.539\n",
      "Epoch: 1, Batch  1360, loss: 0.520\n",
      "Epoch: 1, Batch  1370, loss: 0.525\n",
      "Epoch: 1, Batch  1380, loss: 0.500\n",
      "Epoch: 1, Batch  1390, loss: 0.546\n",
      "Epoch: 1, Batch  1400, loss: 0.502\n",
      "Epoch: 1, Batch  1410, loss: 0.501\n",
      "Epoch: 1, Batch  1420, loss: 0.539\n",
      "Epoch: 1, Batch  1430, loss: 0.531\n",
      "Epoch: 1, Batch  1440, loss: 0.509\n",
      "Epoch: 1, Batch  1450, loss: 0.505\n",
      "Epoch: 1, Batch  1460, loss: 0.491\n",
      "Epoch: 1, Batch  1470, loss: 0.507\n",
      "Epoch: 1, Batch  1480, loss: 0.515\n",
      "Epoch: 1, Batch  1490, loss: 0.499\n",
      "Epoch: 1, Batch  1500, loss: 0.472\n",
      "Epoch: 1, Batch  1510, loss: 0.551\n",
      "Epoch: 1, Batch  1520, loss: 0.495\n",
      "Epoch: 1, Batch  1530, loss: 0.482\n",
      "Epoch: 1, Batch  1540, loss: 0.509\n",
      "Epoch: 1, Batch  1550, loss: 0.509\n",
      "Epoch: 1, Batch  1560, loss: 0.485\n",
      "Epoch: 1, Batch  1570, loss: 0.530\n",
      "Epoch: 1, Batch  1580, loss: 0.482\n",
      "Epoch: 1, Batch  1590, loss: 0.490\n",
      "Epoch: 1, Batch  1600, loss: 0.502\n",
      "Epoch: 1, Batch  1610, loss: 0.518\n",
      "Epoch: 1, Batch  1620, loss: 0.492\n",
      "Epoch: 1, Batch  1630, loss: 0.475\n",
      "Epoch: 1, Batch  1640, loss: 0.520\n",
      "Epoch: 1, Batch  1650, loss: 0.464\n",
      "Epoch: 1, Batch  1660, loss: 0.466\n",
      "Epoch: 1, Batch  1670, loss: 0.484\n",
      "Epoch: 1, Batch  1680, loss: 0.445\n",
      "Epoch: 1, Batch  1690, loss: 0.461\n",
      "Epoch: 1, Batch  1700, loss: 0.495\n",
      "Epoch: 1, Batch  1710, loss: 0.488\n",
      "Epoch: 1, Batch  1720, loss: 0.490\n",
      "Epoch: 1, Batch  1730, loss: 0.469\n",
      "Epoch: 1, Batch  1740, loss: 0.474\n",
      "Epoch: 1, Batch  1750, loss: 0.467\n",
      "Epoch: 1, Batch  1760, loss: 0.453\n",
      "Epoch: 1, Batch  1770, loss: 0.479\n",
      "Epoch: 1, Batch  1780, loss: 0.491\n",
      "Epoch: 1, Batch  1790, loss: 0.452\n",
      "Epoch: 1, Batch  1800, loss: 0.484\n",
      "Epoch: 1, Batch  1810, loss: 0.431\n",
      "Epoch: 1, Batch  1820, loss: 0.514\n",
      "Epoch: 1, Batch  1830, loss: 0.501\n",
      "Epoch: 1, Batch  1840, loss: 0.462\n",
      "Epoch: 1, Batch  1850, loss: 0.488\n",
      "Epoch: 1, Batch  1860, loss: 0.449\n",
      "Epoch: 1, Batch  1870, loss: 0.469\n",
      "Epoch: 2, Batch    10, loss: 0.478\n",
      "Epoch: 2, Batch    20, loss: 0.486\n",
      "Epoch: 2, Batch    30, loss: 0.495\n",
      "Epoch: 2, Batch    40, loss: 0.482\n",
      "Epoch: 2, Batch    50, loss: 0.447\n",
      "Epoch: 2, Batch    60, loss: 0.453\n",
      "Epoch: 2, Batch    70, loss: 0.506\n",
      "Epoch: 2, Batch    80, loss: 0.493\n",
      "Epoch: 2, Batch    90, loss: 0.473\n",
      "Epoch: 2, Batch   100, loss: 0.488\n",
      "Epoch: 2, Batch   110, loss: 0.443\n",
      "Epoch: 2, Batch   120, loss: 0.484\n",
      "Epoch: 2, Batch   130, loss: 0.452\n",
      "Epoch: 2, Batch   140, loss: 0.416\n",
      "Epoch: 2, Batch   150, loss: 0.454\n",
      "Epoch: 2, Batch   160, loss: 0.518\n",
      "Epoch: 2, Batch   170, loss: 0.419\n",
      "Epoch: 2, Batch   180, loss: 0.464\n",
      "Epoch: 2, Batch   190, loss: 0.468\n",
      "Epoch: 2, Batch   200, loss: 0.498\n",
      "Epoch: 2, Batch   210, loss: 0.405\n",
      "Epoch: 2, Batch   220, loss: 0.453\n",
      "Epoch: 2, Batch   230, loss: 0.445\n",
      "Epoch: 2, Batch   240, loss: 0.467\n",
      "Epoch: 2, Batch   250, loss: 0.453\n",
      "Epoch: 2, Batch   260, loss: 0.463\n",
      "Epoch: 2, Batch   270, loss: 0.448\n",
      "Epoch: 2, Batch   280, loss: 0.454\n",
      "Epoch: 2, Batch   290, loss: 0.497\n",
      "Epoch: 2, Batch   300, loss: 0.427\n",
      "Epoch: 2, Batch   310, loss: 0.489\n",
      "Epoch: 2, Batch   320, loss: 0.454\n",
      "Epoch: 2, Batch   330, loss: 0.455\n",
      "Epoch: 2, Batch   340, loss: 0.462\n",
      "Epoch: 2, Batch   350, loss: 0.473\n",
      "Epoch: 2, Batch   360, loss: 0.402\n",
      "Epoch: 2, Batch   370, loss: 0.478\n",
      "Epoch: 2, Batch   380, loss: 0.427\n",
      "Epoch: 2, Batch   390, loss: 0.466\n",
      "Epoch: 2, Batch   400, loss: 0.435\n",
      "Epoch: 2, Batch   410, loss: 0.459\n",
      "Epoch: 2, Batch   420, loss: 0.446\n",
      "Epoch: 2, Batch   430, loss: 0.451\n",
      "Epoch: 2, Batch   440, loss: 0.433\n",
      "Epoch: 2, Batch   450, loss: 0.425\n",
      "Epoch: 2, Batch   460, loss: 0.425\n",
      "Epoch: 2, Batch   470, loss: 0.457\n",
      "Epoch: 2, Batch   480, loss: 0.416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch   490, loss: 0.431\n",
      "Epoch: 2, Batch   500, loss: 0.433\n",
      "Epoch: 2, Batch   510, loss: 0.435\n",
      "Epoch: 2, Batch   520, loss: 0.459\n",
      "Epoch: 2, Batch   530, loss: 0.418\n",
      "Epoch: 2, Batch   540, loss: 0.444\n",
      "Epoch: 2, Batch   550, loss: 0.471\n",
      "Epoch: 2, Batch   560, loss: 0.469\n",
      "Epoch: 2, Batch   570, loss: 0.430\n",
      "Epoch: 2, Batch   580, loss: 0.402\n",
      "Epoch: 2, Batch   590, loss: 0.419\n",
      "Epoch: 2, Batch   600, loss: 0.458\n",
      "Epoch: 2, Batch   610, loss: 0.401\n",
      "Epoch: 2, Batch   620, loss: 0.450\n",
      "Epoch: 2, Batch   630, loss: 0.435\n",
      "Epoch: 2, Batch   640, loss: 0.430\n",
      "Epoch: 2, Batch   650, loss: 0.439\n",
      "Epoch: 2, Batch   660, loss: 0.405\n",
      "Epoch: 2, Batch   670, loss: 0.381\n",
      "Epoch: 2, Batch   680, loss: 0.442\n",
      "Epoch: 2, Batch   690, loss: 0.410\n",
      "Epoch: 2, Batch   700, loss: 0.383\n",
      "Epoch: 2, Batch   710, loss: 0.426\n",
      "Epoch: 2, Batch   720, loss: 0.459\n",
      "Epoch: 2, Batch   730, loss: 0.432\n",
      "Epoch: 2, Batch   740, loss: 0.413\n",
      "Epoch: 2, Batch   750, loss: 0.421\n",
      "Epoch: 2, Batch   760, loss: 0.418\n",
      "Epoch: 2, Batch   770, loss: 0.426\n",
      "Epoch: 2, Batch   780, loss: 0.418\n",
      "Epoch: 2, Batch   790, loss: 0.413\n",
      "Epoch: 2, Batch   800, loss: 0.443\n",
      "Epoch: 2, Batch   810, loss: 0.455\n",
      "Epoch: 2, Batch   820, loss: 0.384\n",
      "Epoch: 2, Batch   830, loss: 0.425\n",
      "Epoch: 2, Batch   840, loss: 0.404\n",
      "Epoch: 2, Batch   850, loss: 0.403\n",
      "Epoch: 2, Batch   860, loss: 0.390\n",
      "Epoch: 2, Batch   870, loss: 0.433\n",
      "Epoch: 2, Batch   880, loss: 0.376\n",
      "Epoch: 2, Batch   890, loss: 0.418\n",
      "Epoch: 2, Batch   900, loss: 0.389\n",
      "Epoch: 2, Batch   910, loss: 0.401\n",
      "Epoch: 2, Batch   920, loss: 0.382\n",
      "Epoch: 2, Batch   930, loss: 0.423\n",
      "Epoch: 2, Batch   940, loss: 0.427\n",
      "Epoch: 2, Batch   950, loss: 0.414\n",
      "Epoch: 2, Batch   960, loss: 0.415\n",
      "Epoch: 2, Batch   970, loss: 0.379\n",
      "Epoch: 2, Batch   980, loss: 0.442\n",
      "Epoch: 2, Batch   990, loss: 0.387\n",
      "Epoch: 2, Batch  1000, loss: 0.426\n",
      "Epoch: 2, Batch  1010, loss: 0.382\n",
      "Epoch: 2, Batch  1020, loss: 0.409\n",
      "Epoch: 2, Batch  1030, loss: 0.429\n",
      "Epoch: 2, Batch  1040, loss: 0.462\n",
      "Epoch: 2, Batch  1050, loss: 0.357\n",
      "Epoch: 2, Batch  1060, loss: 0.417\n",
      "Epoch: 2, Batch  1070, loss: 0.459\n",
      "Epoch: 2, Batch  1080, loss: 0.386\n",
      "Epoch: 2, Batch  1090, loss: 0.460\n",
      "Epoch: 2, Batch  1100, loss: 0.405\n",
      "Epoch: 2, Batch  1110, loss: 0.436\n",
      "Epoch: 2, Batch  1120, loss: 0.430\n",
      "Epoch: 2, Batch  1130, loss: 0.400\n",
      "Epoch: 2, Batch  1140, loss: 0.378\n",
      "Epoch: 2, Batch  1150, loss: 0.396\n",
      "Epoch: 2, Batch  1160, loss: 0.456\n",
      "Epoch: 2, Batch  1170, loss: 0.384\n",
      "Epoch: 2, Batch  1180, loss: 0.367\n",
      "Epoch: 2, Batch  1190, loss: 0.371\n",
      "Epoch: 2, Batch  1200, loss: 0.411\n",
      "Epoch: 2, Batch  1210, loss: 0.406\n",
      "Epoch: 2, Batch  1220, loss: 0.407\n",
      "Epoch: 2, Batch  1230, loss: 0.454\n",
      "Epoch: 2, Batch  1240, loss: 0.460\n",
      "Epoch: 2, Batch  1250, loss: 0.366\n",
      "Epoch: 2, Batch  1260, loss: 0.389\n",
      "Epoch: 2, Batch  1270, loss: 0.386\n",
      "Epoch: 2, Batch  1280, loss: 0.404\n",
      "Epoch: 2, Batch  1290, loss: 0.406\n",
      "Epoch: 2, Batch  1300, loss: 0.364\n",
      "Epoch: 2, Batch  1310, loss: 0.371\n",
      "Epoch: 2, Batch  1320, loss: 0.410\n",
      "Epoch: 2, Batch  1330, loss: 0.351\n",
      "Epoch: 2, Batch  1340, loss: 0.409\n",
      "Epoch: 2, Batch  1350, loss: 0.385\n",
      "Epoch: 2, Batch  1360, loss: 0.364\n",
      "Epoch: 2, Batch  1370, loss: 0.376\n",
      "Epoch: 2, Batch  1380, loss: 0.367\n",
      "Epoch: 2, Batch  1390, loss: 0.408\n",
      "Epoch: 2, Batch  1400, loss: 0.383\n",
      "Epoch: 2, Batch  1410, loss: 0.357\n",
      "Epoch: 2, Batch  1420, loss: 0.443\n",
      "Epoch: 2, Batch  1430, loss: 0.403\n",
      "Epoch: 2, Batch  1440, loss: 0.379\n",
      "Epoch: 2, Batch  1450, loss: 0.420\n",
      "Epoch: 2, Batch  1460, loss: 0.374\n",
      "Epoch: 2, Batch  1470, loss: 0.384\n",
      "Epoch: 2, Batch  1480, loss: 0.399\n",
      "Epoch: 2, Batch  1490, loss: 0.407\n",
      "Epoch: 2, Batch  1500, loss: 0.356\n",
      "Epoch: 2, Batch  1510, loss: 0.411\n",
      "Epoch: 2, Batch  1520, loss: 0.374\n",
      "Epoch: 2, Batch  1530, loss: 0.406\n",
      "Epoch: 2, Batch  1540, loss: 0.429\n",
      "Epoch: 2, Batch  1550, loss: 0.406\n",
      "Epoch: 2, Batch  1560, loss: 0.365\n",
      "Epoch: 2, Batch  1570, loss: 0.395\n",
      "Epoch: 2, Batch  1580, loss: 0.355\n",
      "Epoch: 2, Batch  1590, loss: 0.344\n",
      "Epoch: 2, Batch  1600, loss: 0.386\n",
      "Epoch: 2, Batch  1610, loss: 0.410\n",
      "Epoch: 2, Batch  1620, loss: 0.397\n",
      "Epoch: 2, Batch  1630, loss: 0.342\n",
      "Epoch: 2, Batch  1640, loss: 0.405\n",
      "Epoch: 2, Batch  1650, loss: 0.395\n",
      "Epoch: 2, Batch  1660, loss: 0.362\n",
      "Epoch: 2, Batch  1670, loss: 0.376\n",
      "Epoch: 2, Batch  1680, loss: 0.406\n",
      "Epoch: 2, Batch  1690, loss: 0.375\n",
      "Epoch: 2, Batch  1700, loss: 0.410\n",
      "Epoch: 2, Batch  1710, loss: 0.389\n",
      "Epoch: 2, Batch  1720, loss: 0.412\n",
      "Epoch: 2, Batch  1730, loss: 0.390\n",
      "Epoch: 2, Batch  1740, loss: 0.385\n",
      "Epoch: 2, Batch  1750, loss: 0.392\n",
      "Epoch: 2, Batch  1760, loss: 0.354\n",
      "Epoch: 2, Batch  1770, loss: 0.391\n",
      "Epoch: 2, Batch  1780, loss: 0.440\n",
      "Epoch: 2, Batch  1790, loss: 0.373\n",
      "Epoch: 2, Batch  1800, loss: 0.379\n",
      "Epoch: 2, Batch  1810, loss: 0.361\n",
      "Epoch: 2, Batch  1820, loss: 0.385\n",
      "Epoch: 2, Batch  1830, loss: 0.404\n",
      "Epoch: 2, Batch  1840, loss: 0.385\n",
      "Epoch: 2, Batch  1850, loss: 0.367\n",
      "Epoch: 2, Batch  1860, loss: 0.399\n",
      "Epoch: 2, Batch  1870, loss: 0.375\n",
      "Epoch: 3, Batch    10, loss: 0.389\n",
      "Epoch: 3, Batch    20, loss: 0.420\n",
      "Epoch: 3, Batch    30, loss: 0.381\n",
      "Epoch: 3, Batch    40, loss: 0.431\n",
      "Epoch: 3, Batch    50, loss: 0.389\n",
      "Epoch: 3, Batch    60, loss: 0.389\n",
      "Epoch: 3, Batch    70, loss: 0.378\n",
      "Epoch: 3, Batch    80, loss: 0.425\n",
      "Epoch: 3, Batch    90, loss: 0.352\n",
      "Epoch: 3, Batch   100, loss: 0.398\n",
      "Epoch: 3, Batch   110, loss: 0.323\n",
      "Epoch: 3, Batch   120, loss: 0.400\n",
      "Epoch: 3, Batch   130, loss: 0.372\n",
      "Epoch: 3, Batch   140, loss: 0.328\n",
      "Epoch: 3, Batch   150, loss: 0.375\n",
      "Epoch: 3, Batch   160, loss: 0.405\n",
      "Epoch: 3, Batch   170, loss: 0.357\n",
      "Epoch: 3, Batch   180, loss: 0.414\n",
      "Epoch: 3, Batch   190, loss: 0.365\n",
      "Epoch: 3, Batch   200, loss: 0.422\n",
      "Epoch: 3, Batch   210, loss: 0.349\n",
      "Epoch: 3, Batch   220, loss: 0.373\n",
      "Epoch: 3, Batch   230, loss: 0.358\n",
      "Epoch: 3, Batch   240, loss: 0.384\n",
      "Epoch: 3, Batch   250, loss: 0.354\n",
      "Epoch: 3, Batch   260, loss: 0.373\n",
      "Epoch: 3, Batch   270, loss: 0.365\n",
      "Epoch: 3, Batch   280, loss: 0.431\n",
      "Epoch: 3, Batch   290, loss: 0.405\n",
      "Epoch: 3, Batch   300, loss: 0.394\n",
      "Epoch: 3, Batch   310, loss: 0.402\n",
      "Epoch: 3, Batch   320, loss: 0.394\n",
      "Epoch: 3, Batch   330, loss: 0.376\n",
      "Epoch: 3, Batch   340, loss: 0.400\n",
      "Epoch: 3, Batch   350, loss: 0.380\n",
      "Epoch: 3, Batch   360, loss: 0.334\n",
      "Epoch: 3, Batch   370, loss: 0.365\n",
      "Epoch: 3, Batch   380, loss: 0.370\n",
      "Epoch: 3, Batch   390, loss: 0.404\n",
      "Epoch: 3, Batch   400, loss: 0.321\n",
      "Epoch: 3, Batch   410, loss: 0.356\n",
      "Epoch: 3, Batch   420, loss: 0.396\n",
      "Epoch: 3, Batch   430, loss: 0.349\n",
      "Epoch: 3, Batch   440, loss: 0.368\n",
      "Epoch: 3, Batch   450, loss: 0.331\n",
      "Epoch: 3, Batch   460, loss: 0.339\n",
      "Epoch: 3, Batch   470, loss: 0.397\n",
      "Epoch: 3, Batch   480, loss: 0.360\n",
      "Epoch: 3, Batch   490, loss: 0.374\n",
      "Epoch: 3, Batch   500, loss: 0.372\n",
      "Epoch: 3, Batch   510, loss: 0.393\n",
      "Epoch: 3, Batch   520, loss: 0.444\n",
      "Epoch: 3, Batch   530, loss: 0.350\n",
      "Epoch: 3, Batch   540, loss: 0.375\n",
      "Epoch: 3, Batch   550, loss: 0.385\n",
      "Epoch: 3, Batch   560, loss: 0.379\n",
      "Epoch: 3, Batch   570, loss: 0.350\n",
      "Epoch: 3, Batch   580, loss: 0.385\n",
      "Epoch: 3, Batch   590, loss: 0.371\n",
      "Epoch: 3, Batch   600, loss: 0.383\n",
      "Epoch: 3, Batch   610, loss: 0.357\n",
      "Epoch: 3, Batch   620, loss: 0.413\n",
      "Epoch: 3, Batch   630, loss: 0.413\n",
      "Epoch: 3, Batch   640, loss: 0.348\n",
      "Epoch: 3, Batch   650, loss: 0.418\n",
      "Epoch: 3, Batch   660, loss: 0.342\n",
      "Epoch: 3, Batch   670, loss: 0.328\n",
      "Epoch: 3, Batch   680, loss: 0.408\n",
      "Epoch: 3, Batch   690, loss: 0.349\n",
      "Epoch: 3, Batch   700, loss: 0.354\n",
      "Epoch: 3, Batch   710, loss: 0.366\n",
      "Epoch: 3, Batch   720, loss: 0.391\n",
      "Epoch: 3, Batch   730, loss: 0.377\n",
      "Epoch: 3, Batch   740, loss: 0.375\n",
      "Epoch: 3, Batch   750, loss: 0.314\n",
      "Epoch: 3, Batch   760, loss: 0.341\n",
      "Epoch: 3, Batch   770, loss: 0.399\n",
      "Epoch: 3, Batch   780, loss: 0.386\n",
      "Epoch: 3, Batch   790, loss: 0.355\n",
      "Epoch: 3, Batch   800, loss: 0.361\n",
      "Epoch: 3, Batch   810, loss: 0.404\n",
      "Epoch: 3, Batch   820, loss: 0.350\n",
      "Epoch: 3, Batch   830, loss: 0.384\n",
      "Epoch: 3, Batch   840, loss: 0.326\n",
      "Epoch: 3, Batch   850, loss: 0.365\n",
      "Epoch: 3, Batch   860, loss: 0.332\n",
      "Epoch: 3, Batch   870, loss: 0.414\n",
      "Epoch: 3, Batch   880, loss: 0.360\n",
      "Epoch: 3, Batch   890, loss: 0.340\n",
      "Epoch: 3, Batch   900, loss: 0.318\n",
      "Epoch: 3, Batch   910, loss: 0.388\n",
      "Epoch: 3, Batch   920, loss: 0.352\n",
      "Epoch: 3, Batch   930, loss: 0.391\n",
      "Epoch: 3, Batch   940, loss: 0.377\n",
      "Epoch: 3, Batch   950, loss: 0.338\n",
      "Epoch: 3, Batch   960, loss: 0.380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch   970, loss: 0.367\n",
      "Epoch: 3, Batch   980, loss: 0.353\n",
      "Epoch: 3, Batch   990, loss: 0.335\n",
      "Epoch: 3, Batch  1000, loss: 0.332\n",
      "Epoch: 3, Batch  1010, loss: 0.375\n",
      "Epoch: 3, Batch  1020, loss: 0.349\n",
      "Epoch: 3, Batch  1030, loss: 0.383\n",
      "Epoch: 3, Batch  1040, loss: 0.412\n",
      "Epoch: 3, Batch  1050, loss: 0.347\n",
      "Epoch: 3, Batch  1060, loss: 0.337\n",
      "Epoch: 3, Batch  1070, loss: 0.368\n",
      "Epoch: 3, Batch  1080, loss: 0.347\n",
      "Epoch: 3, Batch  1090, loss: 0.427\n",
      "Epoch: 3, Batch  1100, loss: 0.349\n",
      "Epoch: 3, Batch  1110, loss: 0.380\n",
      "Epoch: 3, Batch  1120, loss: 0.360\n",
      "Epoch: 3, Batch  1130, loss: 0.393\n",
      "Epoch: 3, Batch  1140, loss: 0.347\n",
      "Epoch: 3, Batch  1150, loss: 0.346\n",
      "Epoch: 3, Batch  1160, loss: 0.413\n",
      "Epoch: 3, Batch  1170, loss: 0.346\n",
      "Epoch: 3, Batch  1180, loss: 0.308\n",
      "Epoch: 3, Batch  1190, loss: 0.358\n",
      "Epoch: 3, Batch  1200, loss: 0.405\n",
      "Epoch: 3, Batch  1210, loss: 0.386\n",
      "Epoch: 3, Batch  1220, loss: 0.361\n",
      "Epoch: 3, Batch  1230, loss: 0.342\n",
      "Epoch: 3, Batch  1240, loss: 0.388\n",
      "Epoch: 3, Batch  1250, loss: 0.342\n",
      "Epoch: 3, Batch  1260, loss: 0.371\n",
      "Epoch: 3, Batch  1270, loss: 0.359\n",
      "Epoch: 3, Batch  1280, loss: 0.336\n",
      "Epoch: 3, Batch  1290, loss: 0.354\n",
      "Epoch: 3, Batch  1300, loss: 0.339\n",
      "Epoch: 3, Batch  1310, loss: 0.365\n",
      "Epoch: 3, Batch  1320, loss: 0.373\n",
      "Epoch: 3, Batch  1330, loss: 0.338\n",
      "Epoch: 3, Batch  1340, loss: 0.344\n",
      "Epoch: 3, Batch  1350, loss: 0.357\n",
      "Epoch: 3, Batch  1360, loss: 0.343\n",
      "Epoch: 3, Batch  1370, loss: 0.365\n",
      "Epoch: 3, Batch  1380, loss: 0.346\n",
      "Epoch: 3, Batch  1390, loss: 0.348\n",
      "Epoch: 3, Batch  1400, loss: 0.291\n",
      "Epoch: 3, Batch  1410, loss: 0.321\n",
      "Epoch: 3, Batch  1420, loss: 0.344\n",
      "Epoch: 3, Batch  1430, loss: 0.387\n",
      "Epoch: 3, Batch  1440, loss: 0.329\n",
      "Epoch: 3, Batch  1450, loss: 0.330\n",
      "Epoch: 3, Batch  1460, loss: 0.326\n",
      "Epoch: 3, Batch  1470, loss: 0.353\n",
      "Epoch: 3, Batch  1480, loss: 0.378\n",
      "Epoch: 3, Batch  1490, loss: 0.387\n",
      "Epoch: 3, Batch  1500, loss: 0.302\n",
      "Epoch: 3, Batch  1510, loss: 0.349\n",
      "Epoch: 3, Batch  1520, loss: 0.317\n",
      "Epoch: 3, Batch  1530, loss: 0.325\n",
      "Epoch: 3, Batch  1540, loss: 0.370\n",
      "Epoch: 3, Batch  1550, loss: 0.386\n",
      "Epoch: 3, Batch  1560, loss: 0.310\n",
      "Epoch: 3, Batch  1570, loss: 0.342\n",
      "Epoch: 3, Batch  1580, loss: 0.352\n",
      "Epoch: 3, Batch  1590, loss: 0.354\n",
      "Epoch: 3, Batch  1600, loss: 0.354\n",
      "Epoch: 3, Batch  1610, loss: 0.406\n",
      "Epoch: 3, Batch  1620, loss: 0.364\n",
      "Epoch: 3, Batch  1630, loss: 0.340\n",
      "Epoch: 3, Batch  1640, loss: 0.372\n",
      "Epoch: 3, Batch  1650, loss: 0.345\n",
      "Epoch: 3, Batch  1660, loss: 0.304\n",
      "Epoch: 3, Batch  1670, loss: 0.318\n",
      "Epoch: 3, Batch  1680, loss: 0.368\n",
      "Epoch: 3, Batch  1690, loss: 0.363\n",
      "Epoch: 3, Batch  1700, loss: 0.372\n",
      "Epoch: 3, Batch  1710, loss: 0.367\n",
      "Epoch: 3, Batch  1720, loss: 0.380\n",
      "Epoch: 3, Batch  1730, loss: 0.380\n",
      "Epoch: 3, Batch  1740, loss: 0.332\n",
      "Epoch: 3, Batch  1750, loss: 0.357\n",
      "Epoch: 3, Batch  1760, loss: 0.308\n",
      "Epoch: 3, Batch  1770, loss: 0.366\n",
      "Epoch: 3, Batch  1780, loss: 0.358\n",
      "Epoch: 3, Batch  1790, loss: 0.323\n",
      "Epoch: 3, Batch  1800, loss: 0.364\n",
      "Epoch: 3, Batch  1810, loss: 0.288\n",
      "Epoch: 3, Batch  1820, loss: 0.353\n",
      "Epoch: 3, Batch  1830, loss: 0.376\n",
      "Epoch: 3, Batch  1840, loss: 0.363\n",
      "Epoch: 3, Batch  1850, loss: 0.319\n",
      "Epoch: 3, Batch  1860, loss: 0.352\n",
      "Epoch: 3, Batch  1870, loss: 0.393\n",
      "Epoch: 4, Batch    10, loss: 0.404\n",
      "Epoch: 4, Batch    20, loss: 0.377\n",
      "Epoch: 4, Batch    30, loss: 0.365\n",
      "Epoch: 4, Batch    40, loss: 0.390\n",
      "Epoch: 4, Batch    50, loss: 0.355\n",
      "Epoch: 4, Batch    60, loss: 0.333\n",
      "Epoch: 4, Batch    70, loss: 0.319\n",
      "Epoch: 4, Batch    80, loss: 0.364\n",
      "Epoch: 4, Batch    90, loss: 0.352\n",
      "Epoch: 4, Batch   100, loss: 0.325\n",
      "Epoch: 4, Batch   110, loss: 0.299\n",
      "Epoch: 4, Batch   120, loss: 0.356\n",
      "Epoch: 4, Batch   130, loss: 0.352\n",
      "Epoch: 4, Batch   140, loss: 0.296\n",
      "Epoch: 4, Batch   150, loss: 0.368\n",
      "Epoch: 4, Batch   160, loss: 0.372\n",
      "Epoch: 4, Batch   170, loss: 0.319\n",
      "Epoch: 4, Batch   180, loss: 0.354\n",
      "Epoch: 4, Batch   190, loss: 0.300\n",
      "Epoch: 4, Batch   200, loss: 0.419\n",
      "Epoch: 4, Batch   210, loss: 0.336\n",
      "Epoch: 4, Batch   220, loss: 0.355\n",
      "Epoch: 4, Batch   230, loss: 0.336\n",
      "Epoch: 4, Batch   240, loss: 0.376\n",
      "Epoch: 4, Batch   250, loss: 0.332\n",
      "Epoch: 4, Batch   260, loss: 0.346\n",
      "Epoch: 4, Batch   270, loss: 0.358\n",
      "Epoch: 4, Batch   280, loss: 0.374\n",
      "Epoch: 4, Batch   290, loss: 0.380\n",
      "Epoch: 4, Batch   300, loss: 0.344\n",
      "Epoch: 4, Batch   310, loss: 0.356\n",
      "Epoch: 4, Batch   320, loss: 0.358\n",
      "Epoch: 4, Batch   330, loss: 0.354\n",
      "Epoch: 4, Batch   340, loss: 0.355\n",
      "Epoch: 4, Batch   350, loss: 0.362\n",
      "Epoch: 4, Batch   360, loss: 0.314\n",
      "Epoch: 4, Batch   370, loss: 0.346\n",
      "Epoch: 4, Batch   380, loss: 0.323\n",
      "Epoch: 4, Batch   390, loss: 0.352\n",
      "Epoch: 4, Batch   400, loss: 0.305\n",
      "Epoch: 4, Batch   410, loss: 0.332\n",
      "Epoch: 4, Batch   420, loss: 0.354\n",
      "Epoch: 4, Batch   430, loss: 0.343\n",
      "Epoch: 4, Batch   440, loss: 0.337\n",
      "Epoch: 4, Batch   450, loss: 0.292\n",
      "Epoch: 4, Batch   460, loss: 0.326\n",
      "Epoch: 4, Batch   470, loss: 0.340\n",
      "Epoch: 4, Batch   480, loss: 0.321\n",
      "Epoch: 4, Batch   490, loss: 0.355\n",
      "Epoch: 4, Batch   500, loss: 0.356\n",
      "Epoch: 4, Batch   510, loss: 0.358\n",
      "Epoch: 4, Batch   520, loss: 0.390\n",
      "Epoch: 4, Batch   530, loss: 0.358\n",
      "Epoch: 4, Batch   540, loss: 0.386\n",
      "Epoch: 4, Batch   550, loss: 0.349\n",
      "Epoch: 4, Batch   560, loss: 0.367\n",
      "Epoch: 4, Batch   570, loss: 0.308\n",
      "Epoch: 4, Batch   580, loss: 0.327\n",
      "Epoch: 4, Batch   590, loss: 0.317\n",
      "Epoch: 4, Batch   600, loss: 0.346\n",
      "Epoch: 4, Batch   610, loss: 0.314\n",
      "Epoch: 4, Batch   620, loss: 0.372\n",
      "Epoch: 4, Batch   630, loss: 0.378\n",
      "Epoch: 4, Batch   640, loss: 0.345\n",
      "Epoch: 4, Batch   650, loss: 0.374\n",
      "Epoch: 4, Batch   660, loss: 0.314\n",
      "Epoch: 4, Batch   670, loss: 0.284\n",
      "Epoch: 4, Batch   680, loss: 0.348\n",
      "Epoch: 4, Batch   690, loss: 0.324\n",
      "Epoch: 4, Batch   700, loss: 0.331\n",
      "Epoch: 4, Batch   710, loss: 0.350\n",
      "Epoch: 4, Batch   720, loss: 0.338\n",
      "Epoch: 4, Batch   730, loss: 0.333\n",
      "Epoch: 4, Batch   740, loss: 0.370\n",
      "Epoch: 4, Batch   750, loss: 0.310\n",
      "Epoch: 4, Batch   760, loss: 0.348\n",
      "Epoch: 4, Batch   770, loss: 0.376\n",
      "Epoch: 4, Batch   780, loss: 0.369\n",
      "Epoch: 4, Batch   790, loss: 0.367\n",
      "Epoch: 4, Batch   800, loss: 0.337\n",
      "Epoch: 4, Batch   810, loss: 0.377\n",
      "Epoch: 4, Batch   820, loss: 0.334\n",
      "Epoch: 4, Batch   830, loss: 0.395\n",
      "Epoch: 4, Batch   840, loss: 0.304\n",
      "Epoch: 4, Batch   850, loss: 0.369\n",
      "Epoch: 4, Batch   860, loss: 0.361\n",
      "Epoch: 4, Batch   870, loss: 0.371\n",
      "Epoch: 4, Batch   880, loss: 0.330\n",
      "Epoch: 4, Batch   890, loss: 0.336\n",
      "Epoch: 4, Batch   900, loss: 0.277\n",
      "Epoch: 4, Batch   910, loss: 0.350\n",
      "Epoch: 4, Batch   920, loss: 0.306\n",
      "Epoch: 4, Batch   930, loss: 0.382\n",
      "Epoch: 4, Batch   940, loss: 0.309\n",
      "Epoch: 4, Batch   950, loss: 0.336\n",
      "Epoch: 4, Batch   960, loss: 0.320\n",
      "Epoch: 4, Batch   970, loss: 0.310\n",
      "Epoch: 4, Batch   980, loss: 0.352\n",
      "Epoch: 4, Batch   990, loss: 0.324\n",
      "Epoch: 4, Batch  1000, loss: 0.319\n",
      "Epoch: 4, Batch  1010, loss: 0.313\n",
      "Epoch: 4, Batch  1020, loss: 0.313\n",
      "Epoch: 4, Batch  1030, loss: 0.380\n",
      "Epoch: 4, Batch  1040, loss: 0.350\n",
      "Epoch: 4, Batch  1050, loss: 0.272\n",
      "Epoch: 4, Batch  1060, loss: 0.324\n",
      "Epoch: 4, Batch  1070, loss: 0.361\n",
      "Epoch: 4, Batch  1080, loss: 0.320\n",
      "Epoch: 4, Batch  1090, loss: 0.412\n",
      "Epoch: 4, Batch  1100, loss: 0.345\n",
      "Epoch: 4, Batch  1110, loss: 0.353\n",
      "Epoch: 4, Batch  1120, loss: 0.329\n",
      "Epoch: 4, Batch  1130, loss: 0.313\n",
      "Epoch: 4, Batch  1140, loss: 0.317\n",
      "Epoch: 4, Batch  1150, loss: 0.311\n",
      "Epoch: 4, Batch  1160, loss: 0.370\n",
      "Epoch: 4, Batch  1170, loss: 0.291\n",
      "Epoch: 4, Batch  1180, loss: 0.278\n",
      "Epoch: 4, Batch  1190, loss: 0.306\n",
      "Epoch: 4, Batch  1200, loss: 0.335\n",
      "Epoch: 4, Batch  1210, loss: 0.341\n",
      "Epoch: 4, Batch  1220, loss: 0.337\n",
      "Epoch: 4, Batch  1230, loss: 0.329\n",
      "Epoch: 4, Batch  1240, loss: 0.339\n",
      "Epoch: 4, Batch  1250, loss: 0.330\n",
      "Epoch: 4, Batch  1260, loss: 0.344\n",
      "Epoch: 4, Batch  1270, loss: 0.325\n",
      "Epoch: 4, Batch  1280, loss: 0.304\n",
      "Epoch: 4, Batch  1290, loss: 0.378\n",
      "Epoch: 4, Batch  1300, loss: 0.310\n",
      "Epoch: 4, Batch  1310, loss: 0.327\n",
      "Epoch: 4, Batch  1320, loss: 0.367\n",
      "Epoch: 4, Batch  1330, loss: 0.319\n",
      "Epoch: 4, Batch  1340, loss: 0.322\n",
      "Epoch: 4, Batch  1350, loss: 0.356\n",
      "Epoch: 4, Batch  1360, loss: 0.292\n",
      "Epoch: 4, Batch  1370, loss: 0.306\n",
      "Epoch: 4, Batch  1380, loss: 0.294\n",
      "Epoch: 4, Batch  1390, loss: 0.306\n",
      "Epoch: 4, Batch  1400, loss: 0.279\n",
      "Epoch: 4, Batch  1410, loss: 0.321\n",
      "Epoch: 4, Batch  1420, loss: 0.311\n",
      "Epoch: 4, Batch  1430, loss: 0.377\n",
      "Epoch: 4, Batch  1440, loss: 0.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch  1450, loss: 0.319\n",
      "Epoch: 4, Batch  1460, loss: 0.330\n",
      "Epoch: 4, Batch  1470, loss: 0.336\n",
      "Epoch: 4, Batch  1480, loss: 0.363\n",
      "Epoch: 4, Batch  1490, loss: 0.371\n",
      "Epoch: 4, Batch  1500, loss: 0.284\n",
      "Epoch: 4, Batch  1510, loss: 0.318\n",
      "Epoch: 4, Batch  1520, loss: 0.301\n",
      "Epoch: 4, Batch  1530, loss: 0.333\n",
      "Epoch: 4, Batch  1540, loss: 0.308\n",
      "Epoch: 4, Batch  1550, loss: 0.348\n",
      "Epoch: 4, Batch  1560, loss: 0.304\n",
      "Epoch: 4, Batch  1570, loss: 0.283\n",
      "Epoch: 4, Batch  1580, loss: 0.305\n",
      "Epoch: 4, Batch  1590, loss: 0.270\n",
      "Epoch: 4, Batch  1600, loss: 0.312\n",
      "Epoch: 4, Batch  1610, loss: 0.386\n",
      "Epoch: 4, Batch  1620, loss: 0.311\n",
      "Epoch: 4, Batch  1630, loss: 0.292\n",
      "Epoch: 4, Batch  1640, loss: 0.356\n",
      "Epoch: 4, Batch  1650, loss: 0.314\n",
      "Epoch: 4, Batch  1660, loss: 0.320\n",
      "Epoch: 4, Batch  1670, loss: 0.309\n",
      "Epoch: 4, Batch  1680, loss: 0.356\n",
      "Epoch: 4, Batch  1690, loss: 0.315\n",
      "Epoch: 4, Batch  1700, loss: 0.348\n",
      "Epoch: 4, Batch  1710, loss: 0.334\n",
      "Epoch: 4, Batch  1720, loss: 0.341\n",
      "Epoch: 4, Batch  1730, loss: 0.332\n",
      "Epoch: 4, Batch  1740, loss: 0.301\n",
      "Epoch: 4, Batch  1750, loss: 0.335\n",
      "Epoch: 4, Batch  1760, loss: 0.295\n",
      "Epoch: 4, Batch  1770, loss: 0.297\n",
      "Epoch: 4, Batch  1780, loss: 0.353\n",
      "Epoch: 4, Batch  1790, loss: 0.336\n",
      "Epoch: 4, Batch  1800, loss: 0.319\n",
      "Epoch: 4, Batch  1810, loss: 0.288\n",
      "Epoch: 4, Batch  1820, loss: 0.392\n",
      "Epoch: 4, Batch  1830, loss: 0.330\n",
      "Epoch: 4, Batch  1840, loss: 0.345\n",
      "Epoch: 4, Batch  1850, loss: 0.298\n",
      "Epoch: 4, Batch  1860, loss: 0.338\n",
      "Epoch: 4, Batch  1870, loss: 0.343\n",
      "Epoch: 5, Batch    10, loss: 0.386\n",
      "Epoch: 5, Batch    20, loss: 0.356\n",
      "Epoch: 5, Batch    30, loss: 0.345\n",
      "Epoch: 5, Batch    40, loss: 0.361\n",
      "Epoch: 5, Batch    50, loss: 0.352\n",
      "Epoch: 5, Batch    60, loss: 0.294\n",
      "Epoch: 5, Batch    70, loss: 0.299\n",
      "Epoch: 5, Batch    80, loss: 0.331\n",
      "Epoch: 5, Batch    90, loss: 0.335\n",
      "Epoch: 5, Batch   100, loss: 0.284\n",
      "Epoch: 5, Batch   110, loss: 0.270\n",
      "Epoch: 5, Batch   120, loss: 0.357\n",
      "Epoch: 5, Batch   130, loss: 0.337\n",
      "Epoch: 5, Batch   140, loss: 0.279\n",
      "Epoch: 5, Batch   150, loss: 0.304\n",
      "Epoch: 5, Batch   160, loss: 0.368\n",
      "Epoch: 5, Batch   170, loss: 0.282\n",
      "Epoch: 5, Batch   180, loss: 0.350\n",
      "Epoch: 5, Batch   190, loss: 0.308\n",
      "Epoch: 5, Batch   200, loss: 0.402\n",
      "Epoch: 5, Batch   210, loss: 0.327\n",
      "Epoch: 5, Batch   220, loss: 0.327\n",
      "Epoch: 5, Batch   230, loss: 0.308\n",
      "Epoch: 5, Batch   240, loss: 0.341\n",
      "Epoch: 5, Batch   250, loss: 0.298\n",
      "Epoch: 5, Batch   260, loss: 0.314\n",
      "Epoch: 5, Batch   270, loss: 0.286\n",
      "Epoch: 5, Batch   280, loss: 0.402\n",
      "Epoch: 5, Batch   290, loss: 0.317\n",
      "Epoch: 5, Batch   300, loss: 0.357\n",
      "Epoch: 5, Batch   310, loss: 0.325\n",
      "Epoch: 5, Batch   320, loss: 0.333\n",
      "Epoch: 5, Batch   330, loss: 0.312\n",
      "Epoch: 5, Batch   340, loss: 0.340\n",
      "Epoch: 5, Batch   350, loss: 0.330\n",
      "Epoch: 5, Batch   360, loss: 0.310\n",
      "Epoch: 5, Batch   370, loss: 0.291\n",
      "Epoch: 5, Batch   380, loss: 0.284\n",
      "Epoch: 5, Batch   390, loss: 0.323\n",
      "Epoch: 5, Batch   400, loss: 0.326\n",
      "Epoch: 5, Batch   410, loss: 0.300\n",
      "Epoch: 5, Batch   420, loss: 0.360\n",
      "Epoch: 5, Batch   430, loss: 0.297\n",
      "Epoch: 5, Batch   440, loss: 0.297\n",
      "Epoch: 5, Batch   450, loss: 0.298\n",
      "Epoch: 5, Batch   460, loss: 0.300\n",
      "Epoch: 5, Batch   470, loss: 0.322\n",
      "Epoch: 5, Batch   480, loss: 0.301\n",
      "Epoch: 5, Batch   490, loss: 0.349\n",
      "Epoch: 5, Batch   500, loss: 0.290\n",
      "Epoch: 5, Batch   510, loss: 0.349\n",
      "Epoch: 5, Batch   520, loss: 0.340\n",
      "Epoch: 5, Batch   530, loss: 0.285\n",
      "Epoch: 5, Batch   540, loss: 0.336\n",
      "Epoch: 5, Batch   550, loss: 0.354\n",
      "Epoch: 5, Batch   560, loss: 0.326\n",
      "Epoch: 5, Batch   570, loss: 0.282\n",
      "Epoch: 5, Batch   580, loss: 0.338\n",
      "Epoch: 5, Batch   590, loss: 0.287\n",
      "Epoch: 5, Batch   600, loss: 0.299\n",
      "Epoch: 5, Batch   610, loss: 0.307\n",
      "Epoch: 5, Batch   620, loss: 0.356\n",
      "Epoch: 5, Batch   630, loss: 0.368\n",
      "Epoch: 5, Batch   640, loss: 0.320\n",
      "Epoch: 5, Batch   650, loss: 0.321\n",
      "Epoch: 5, Batch   660, loss: 0.307\n",
      "Epoch: 5, Batch   670, loss: 0.250\n",
      "Epoch: 5, Batch   680, loss: 0.346\n",
      "Epoch: 5, Batch   690, loss: 0.321\n",
      "Epoch: 5, Batch   700, loss: 0.302\n",
      "Epoch: 5, Batch   710, loss: 0.326\n",
      "Epoch: 5, Batch   720, loss: 0.343\n",
      "Epoch: 5, Batch   730, loss: 0.291\n",
      "Epoch: 5, Batch   740, loss: 0.352\n",
      "Epoch: 5, Batch   750, loss: 0.313\n",
      "Epoch: 5, Batch   760, loss: 0.308\n",
      "Epoch: 5, Batch   770, loss: 0.318\n",
      "Epoch: 5, Batch   780, loss: 0.327\n",
      "Epoch: 5, Batch   790, loss: 0.381\n",
      "Epoch: 5, Batch   800, loss: 0.343\n",
      "Epoch: 5, Batch   810, loss: 0.367\n",
      "Epoch: 5, Batch   820, loss: 0.330\n",
      "Epoch: 5, Batch   830, loss: 0.344\n",
      "Epoch: 5, Batch   840, loss: 0.286\n",
      "Epoch: 5, Batch   850, loss: 0.345\n",
      "Epoch: 5, Batch   860, loss: 0.331\n",
      "Epoch: 5, Batch   870, loss: 0.329\n",
      "Epoch: 5, Batch   880, loss: 0.284\n",
      "Epoch: 5, Batch   890, loss: 0.311\n",
      "Epoch: 5, Batch   900, loss: 0.243\n",
      "Epoch: 5, Batch   910, loss: 0.293\n",
      "Epoch: 5, Batch   920, loss: 0.280\n",
      "Epoch: 5, Batch   930, loss: 0.321\n",
      "Epoch: 5, Batch   940, loss: 0.311\n",
      "Epoch: 5, Batch   950, loss: 0.269\n",
      "Epoch: 5, Batch   960, loss: 0.291\n",
      "Epoch: 5, Batch   970, loss: 0.283\n",
      "Epoch: 5, Batch   980, loss: 0.331\n",
      "Epoch: 5, Batch   990, loss: 0.284\n",
      "Epoch: 5, Batch  1000, loss: 0.318\n",
      "Epoch: 5, Batch  1010, loss: 0.322\n",
      "Epoch: 5, Batch  1020, loss: 0.283\n",
      "Epoch: 5, Batch  1030, loss: 0.359\n",
      "Epoch: 5, Batch  1040, loss: 0.346\n",
      "Epoch: 5, Batch  1050, loss: 0.249\n",
      "Epoch: 5, Batch  1060, loss: 0.294\n",
      "Epoch: 5, Batch  1070, loss: 0.333\n",
      "Epoch: 5, Batch  1080, loss: 0.314\n",
      "Epoch: 5, Batch  1090, loss: 0.415\n",
      "Epoch: 5, Batch  1100, loss: 0.324\n",
      "Epoch: 5, Batch  1110, loss: 0.357\n",
      "Epoch: 5, Batch  1120, loss: 0.309\n",
      "Epoch: 5, Batch  1130, loss: 0.295\n",
      "Epoch: 5, Batch  1140, loss: 0.288\n",
      "Epoch: 5, Batch  1150, loss: 0.291\n",
      "Epoch: 5, Batch  1160, loss: 0.336\n",
      "Epoch: 5, Batch  1170, loss: 0.269\n",
      "Epoch: 5, Batch  1180, loss: 0.255\n",
      "Epoch: 5, Batch  1190, loss: 0.272\n",
      "Epoch: 5, Batch  1200, loss: 0.308\n",
      "Epoch: 5, Batch  1210, loss: 0.348\n",
      "Epoch: 5, Batch  1220, loss: 0.302\n",
      "Epoch: 5, Batch  1230, loss: 0.280\n",
      "Epoch: 5, Batch  1240, loss: 0.336\n",
      "Epoch: 5, Batch  1250, loss: 0.293\n",
      "Epoch: 5, Batch  1260, loss: 0.303\n",
      "Epoch: 5, Batch  1270, loss: 0.298\n",
      "Epoch: 5, Batch  1280, loss: 0.348\n",
      "Epoch: 5, Batch  1290, loss: 0.358\n",
      "Epoch: 5, Batch  1300, loss: 0.284\n",
      "Epoch: 5, Batch  1310, loss: 0.313\n",
      "Epoch: 5, Batch  1320, loss: 0.335\n",
      "Epoch: 5, Batch  1330, loss: 0.303\n",
      "Epoch: 5, Batch  1340, loss: 0.324\n",
      "Epoch: 5, Batch  1350, loss: 0.347\n",
      "Epoch: 5, Batch  1360, loss: 0.283\n",
      "Epoch: 5, Batch  1370, loss: 0.294\n",
      "Epoch: 5, Batch  1380, loss: 0.284\n",
      "Epoch: 5, Batch  1390, loss: 0.330\n",
      "Epoch: 5, Batch  1400, loss: 0.290\n",
      "Epoch: 5, Batch  1410, loss: 0.294\n",
      "Epoch: 5, Batch  1420, loss: 0.271\n",
      "Epoch: 5, Batch  1430, loss: 0.337\n",
      "Epoch: 5, Batch  1440, loss: 0.318\n",
      "Epoch: 5, Batch  1450, loss: 0.299\n",
      "Epoch: 5, Batch  1460, loss: 0.286\n",
      "Epoch: 5, Batch  1470, loss: 0.271\n",
      "Epoch: 5, Batch  1480, loss: 0.312\n",
      "Epoch: 5, Batch  1490, loss: 0.364\n",
      "Epoch: 5, Batch  1500, loss: 0.264\n",
      "Epoch: 5, Batch  1510, loss: 0.346\n",
      "Epoch: 5, Batch  1520, loss: 0.266\n",
      "Epoch: 5, Batch  1530, loss: 0.310\n",
      "Epoch: 5, Batch  1540, loss: 0.323\n",
      "Epoch: 5, Batch  1550, loss: 0.349\n",
      "Epoch: 5, Batch  1560, loss: 0.299\n",
      "Epoch: 5, Batch  1570, loss: 0.304\n",
      "Epoch: 5, Batch  1580, loss: 0.292\n",
      "Epoch: 5, Batch  1590, loss: 0.285\n",
      "Epoch: 5, Batch  1600, loss: 0.274\n",
      "Epoch: 5, Batch  1610, loss: 0.355\n",
      "Epoch: 5, Batch  1620, loss: 0.334\n",
      "Epoch: 5, Batch  1630, loss: 0.291\n",
      "Epoch: 5, Batch  1640, loss: 0.351\n",
      "Epoch: 5, Batch  1650, loss: 0.296\n",
      "Epoch: 5, Batch  1660, loss: 0.277\n",
      "Epoch: 5, Batch  1670, loss: 0.257\n",
      "Epoch: 5, Batch  1680, loss: 0.313\n",
      "Epoch: 5, Batch  1690, loss: 0.316\n",
      "Epoch: 5, Batch  1700, loss: 0.320\n",
      "Epoch: 5, Batch  1710, loss: 0.292\n",
      "Epoch: 5, Batch  1720, loss: 0.347\n",
      "Epoch: 5, Batch  1730, loss: 0.306\n",
      "Epoch: 5, Batch  1740, loss: 0.280\n",
      "Epoch: 5, Batch  1750, loss: 0.258\n",
      "Epoch: 5, Batch  1760, loss: 0.302\n",
      "Epoch: 5, Batch  1770, loss: 0.316\n",
      "Epoch: 5, Batch  1780, loss: 0.320\n",
      "Epoch: 5, Batch  1790, loss: 0.267\n",
      "Epoch: 5, Batch  1800, loss: 0.314\n",
      "Epoch: 5, Batch  1810, loss: 0.261\n",
      "Epoch: 5, Batch  1820, loss: 0.363\n",
      "Epoch: 5, Batch  1830, loss: 0.326\n",
      "Epoch: 5, Batch  1840, loss: 0.317\n",
      "Epoch: 5, Batch  1850, loss: 0.270\n",
      "Epoch: 5, Batch  1860, loss: 0.323\n",
      "Epoch: 5, Batch  1870, loss: 0.334\n",
      "Epoch: 6, Batch    10, loss: 0.382\n",
      "Epoch: 6, Batch    20, loss: 0.312\n",
      "Epoch: 6, Batch    30, loss: 0.320\n",
      "Epoch: 6, Batch    40, loss: 0.336\n",
      "Epoch: 6, Batch    50, loss: 0.300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Batch    60, loss: 0.297\n",
      "Epoch: 6, Batch    70, loss: 0.281\n",
      "Epoch: 6, Batch    80, loss: 0.308\n",
      "Epoch: 6, Batch    90, loss: 0.289\n",
      "Epoch: 6, Batch   100, loss: 0.294\n",
      "Epoch: 6, Batch   110, loss: 0.277\n",
      "Epoch: 6, Batch   120, loss: 0.350\n",
      "Epoch: 6, Batch   130, loss: 0.326\n",
      "Epoch: 6, Batch   140, loss: 0.290\n",
      "Epoch: 6, Batch   150, loss: 0.301\n",
      "Epoch: 6, Batch   160, loss: 0.374\n",
      "Epoch: 6, Batch   170, loss: 0.297\n",
      "Epoch: 6, Batch   180, loss: 0.350\n",
      "Epoch: 6, Batch   190, loss: 0.319\n",
      "Epoch: 6, Batch   200, loss: 0.360\n",
      "Epoch: 6, Batch   210, loss: 0.300\n",
      "Epoch: 6, Batch   220, loss: 0.318\n",
      "Epoch: 6, Batch   230, loss: 0.272\n",
      "Epoch: 6, Batch   240, loss: 0.354\n",
      "Epoch: 6, Batch   250, loss: 0.312\n",
      "Epoch: 6, Batch   260, loss: 0.312\n",
      "Epoch: 6, Batch   270, loss: 0.330\n",
      "Epoch: 6, Batch   280, loss: 0.370\n",
      "Epoch: 6, Batch   290, loss: 0.286\n",
      "Epoch: 6, Batch   300, loss: 0.320\n",
      "Epoch: 6, Batch   310, loss: 0.348\n",
      "Epoch: 6, Batch   320, loss: 0.311\n",
      "Epoch: 6, Batch   330, loss: 0.299\n",
      "Epoch: 6, Batch   340, loss: 0.299\n",
      "Epoch: 6, Batch   350, loss: 0.286\n",
      "Epoch: 6, Batch   360, loss: 0.256\n",
      "Epoch: 6, Batch   370, loss: 0.292\n",
      "Epoch: 6, Batch   380, loss: 0.265\n",
      "Epoch: 6, Batch   390, loss: 0.312\n",
      "Epoch: 6, Batch   400, loss: 0.250\n",
      "Epoch: 6, Batch   410, loss: 0.346\n",
      "Epoch: 6, Batch   420, loss: 0.361\n",
      "Epoch: 6, Batch   430, loss: 0.279\n",
      "Epoch: 6, Batch   440, loss: 0.298\n",
      "Epoch: 6, Batch   450, loss: 0.292\n",
      "Epoch: 6, Batch   460, loss: 0.297\n",
      "Epoch: 6, Batch   470, loss: 0.280\n",
      "Epoch: 6, Batch   480, loss: 0.288\n",
      "Epoch: 6, Batch   490, loss: 0.322\n",
      "Epoch: 6, Batch   500, loss: 0.295\n",
      "Epoch: 6, Batch   510, loss: 0.353\n",
      "Epoch: 6, Batch   520, loss: 0.344\n",
      "Epoch: 6, Batch   530, loss: 0.294\n",
      "Epoch: 6, Batch   540, loss: 0.277\n",
      "Epoch: 6, Batch   550, loss: 0.346\n",
      "Epoch: 6, Batch   560, loss: 0.302\n",
      "Epoch: 6, Batch   570, loss: 0.274\n",
      "Epoch: 6, Batch   580, loss: 0.289\n",
      "Epoch: 6, Batch   590, loss: 0.274\n",
      "Epoch: 6, Batch   600, loss: 0.325\n",
      "Epoch: 6, Batch   610, loss: 0.307\n",
      "Epoch: 6, Batch   620, loss: 0.334\n",
      "Epoch: 6, Batch   630, loss: 0.354\n",
      "Epoch: 6, Batch   640, loss: 0.336\n",
      "Epoch: 6, Batch   650, loss: 0.330\n",
      "Epoch: 6, Batch   660, loss: 0.285\n",
      "Epoch: 6, Batch   670, loss: 0.244\n",
      "Epoch: 6, Batch   680, loss: 0.307\n",
      "Epoch: 6, Batch   690, loss: 0.300\n",
      "Epoch: 6, Batch   700, loss: 0.296\n",
      "Epoch: 6, Batch   710, loss: 0.342\n",
      "Epoch: 6, Batch   720, loss: 0.283\n",
      "Epoch: 6, Batch   730, loss: 0.305\n",
      "Epoch: 6, Batch   740, loss: 0.310\n",
      "Epoch: 6, Batch   750, loss: 0.306\n",
      "Epoch: 6, Batch   760, loss: 0.300\n",
      "Epoch: 6, Batch   770, loss: 0.308\n",
      "Epoch: 6, Batch   780, loss: 0.316\n",
      "Epoch: 6, Batch   790, loss: 0.332\n",
      "Epoch: 6, Batch   800, loss: 0.308\n",
      "Epoch: 6, Batch   810, loss: 0.303\n",
      "Epoch: 6, Batch   820, loss: 0.318\n",
      "Epoch: 6, Batch   830, loss: 0.317\n",
      "Epoch: 6, Batch   840, loss: 0.290\n",
      "Epoch: 6, Batch   850, loss: 0.315\n",
      "Epoch: 6, Batch   860, loss: 0.327\n",
      "Epoch: 6, Batch   870, loss: 0.312\n",
      "Epoch: 6, Batch   880, loss: 0.280\n",
      "Epoch: 6, Batch   890, loss: 0.295\n",
      "Epoch: 6, Batch   900, loss: 0.249\n",
      "Epoch: 6, Batch   910, loss: 0.329\n",
      "Epoch: 6, Batch   920, loss: 0.254\n",
      "Epoch: 6, Batch   930, loss: 0.324\n",
      "Epoch: 6, Batch   940, loss: 0.322\n",
      "Epoch: 6, Batch   950, loss: 0.263\n",
      "Epoch: 6, Batch   960, loss: 0.294\n",
      "Epoch: 6, Batch   970, loss: 0.280\n",
      "Epoch: 6, Batch   980, loss: 0.333\n",
      "Epoch: 6, Batch   990, loss: 0.276\n",
      "Epoch: 6, Batch  1000, loss: 0.266\n",
      "Epoch: 6, Batch  1010, loss: 0.268\n",
      "Epoch: 6, Batch  1020, loss: 0.290\n",
      "Epoch: 6, Batch  1030, loss: 0.321\n",
      "Epoch: 6, Batch  1040, loss: 0.323\n",
      "Epoch: 6, Batch  1050, loss: 0.240\n",
      "Epoch: 6, Batch  1060, loss: 0.310\n",
      "Epoch: 6, Batch  1070, loss: 0.328\n",
      "Epoch: 6, Batch  1080, loss: 0.313\n",
      "Epoch: 6, Batch  1090, loss: 0.391\n",
      "Epoch: 6, Batch  1100, loss: 0.306\n",
      "Epoch: 6, Batch  1110, loss: 0.335\n",
      "Epoch: 6, Batch  1120, loss: 0.311\n",
      "Epoch: 6, Batch  1130, loss: 0.335\n",
      "Epoch: 6, Batch  1140, loss: 0.268\n",
      "Epoch: 6, Batch  1150, loss: 0.279\n",
      "Epoch: 6, Batch  1160, loss: 0.355\n",
      "Epoch: 6, Batch  1170, loss: 0.257\n",
      "Epoch: 6, Batch  1180, loss: 0.259\n",
      "Epoch: 6, Batch  1190, loss: 0.288\n",
      "Epoch: 6, Batch  1200, loss: 0.379\n",
      "Epoch: 6, Batch  1210, loss: 0.296\n",
      "Epoch: 6, Batch  1220, loss: 0.308\n",
      "Epoch: 6, Batch  1230, loss: 0.243\n",
      "Epoch: 6, Batch  1240, loss: 0.292\n",
      "Epoch: 6, Batch  1250, loss: 0.274\n",
      "Epoch: 6, Batch  1260, loss: 0.295\n",
      "Epoch: 6, Batch  1270, loss: 0.276\n",
      "Epoch: 6, Batch  1280, loss: 0.295\n",
      "Epoch: 6, Batch  1290, loss: 0.309\n",
      "Epoch: 6, Batch  1300, loss: 0.260\n",
      "Epoch: 6, Batch  1310, loss: 0.355\n",
      "Epoch: 6, Batch  1320, loss: 0.298\n",
      "Epoch: 6, Batch  1330, loss: 0.245\n",
      "Epoch: 6, Batch  1340, loss: 0.296\n",
      "Epoch: 6, Batch  1350, loss: 0.297\n",
      "Epoch: 6, Batch  1360, loss: 0.244\n",
      "Epoch: 6, Batch  1370, loss: 0.291\n",
      "Epoch: 6, Batch  1380, loss: 0.233\n",
      "Epoch: 6, Batch  1390, loss: 0.287\n",
      "Epoch: 6, Batch  1400, loss: 0.245\n",
      "Epoch: 6, Batch  1410, loss: 0.278\n",
      "Epoch: 6, Batch  1420, loss: 0.295\n",
      "Epoch: 6, Batch  1430, loss: 0.310\n",
      "Epoch: 6, Batch  1440, loss: 0.318\n",
      "Epoch: 6, Batch  1450, loss: 0.273\n",
      "Epoch: 6, Batch  1460, loss: 0.312\n",
      "Epoch: 6, Batch  1470, loss: 0.298\n",
      "Epoch: 6, Batch  1480, loss: 0.304\n",
      "Epoch: 6, Batch  1490, loss: 0.346\n",
      "Epoch: 6, Batch  1500, loss: 0.227\n",
      "Epoch: 6, Batch  1510, loss: 0.307\n",
      "Epoch: 6, Batch  1520, loss: 0.263\n",
      "Epoch: 6, Batch  1530, loss: 0.333\n",
      "Epoch: 6, Batch  1540, loss: 0.337\n",
      "Epoch: 6, Batch  1550, loss: 0.281\n",
      "Epoch: 6, Batch  1560, loss: 0.274\n",
      "Epoch: 6, Batch  1570, loss: 0.276\n",
      "Epoch: 6, Batch  1580, loss: 0.262\n",
      "Epoch: 6, Batch  1590, loss: 0.255\n",
      "Epoch: 6, Batch  1600, loss: 0.297\n",
      "Epoch: 6, Batch  1610, loss: 0.332\n",
      "Epoch: 6, Batch  1620, loss: 0.315\n",
      "Epoch: 6, Batch  1630, loss: 0.267\n",
      "Epoch: 6, Batch  1640, loss: 0.342\n",
      "Epoch: 6, Batch  1650, loss: 0.255\n",
      "Epoch: 6, Batch  1660, loss: 0.218\n",
      "Epoch: 6, Batch  1670, loss: 0.259\n",
      "Epoch: 6, Batch  1680, loss: 0.287\n",
      "Epoch: 6, Batch  1690, loss: 0.319\n",
      "Epoch: 6, Batch  1700, loss: 0.299\n",
      "Epoch: 6, Batch  1710, loss: 0.268\n",
      "Epoch: 6, Batch  1720, loss: 0.314\n",
      "Epoch: 6, Batch  1730, loss: 0.282\n",
      "Epoch: 6, Batch  1740, loss: 0.283\n",
      "Epoch: 6, Batch  1750, loss: 0.282\n",
      "Epoch: 6, Batch  1760, loss: 0.270\n",
      "Epoch: 6, Batch  1770, loss: 0.282\n",
      "Epoch: 6, Batch  1780, loss: 0.328\n",
      "Epoch: 6, Batch  1790, loss: 0.284\n",
      "Epoch: 6, Batch  1800, loss: 0.329\n",
      "Epoch: 6, Batch  1810, loss: 0.277\n",
      "Epoch: 6, Batch  1820, loss: 0.312\n",
      "Epoch: 6, Batch  1830, loss: 0.287\n",
      "Epoch: 6, Batch  1840, loss: 0.317\n",
      "Epoch: 6, Batch  1850, loss: 0.258\n",
      "Epoch: 6, Batch  1860, loss: 0.328\n",
      "Epoch: 6, Batch  1870, loss: 0.304\n",
      "Epoch: 7, Batch    10, loss: 0.327\n",
      "Epoch: 7, Batch    20, loss: 0.310\n",
      "Epoch: 7, Batch    30, loss: 0.316\n",
      "Epoch: 7, Batch    40, loss: 0.323\n",
      "Epoch: 7, Batch    50, loss: 0.275\n",
      "Epoch: 7, Batch    60, loss: 0.273\n",
      "Epoch: 7, Batch    70, loss: 0.228\n",
      "Epoch: 7, Batch    80, loss: 0.323\n",
      "Epoch: 7, Batch    90, loss: 0.272\n",
      "Epoch: 7, Batch   100, loss: 0.298\n",
      "Epoch: 7, Batch   110, loss: 0.227\n",
      "Epoch: 7, Batch   120, loss: 0.288\n",
      "Epoch: 7, Batch   130, loss: 0.326\n",
      "Epoch: 7, Batch   140, loss: 0.263\n",
      "Epoch: 7, Batch   150, loss: 0.269\n",
      "Epoch: 7, Batch   160, loss: 0.290\n",
      "Epoch: 7, Batch   170, loss: 0.293\n",
      "Epoch: 7, Batch   180, loss: 0.322\n",
      "Epoch: 7, Batch   190, loss: 0.309\n",
      "Epoch: 7, Batch   200, loss: 0.341\n",
      "Epoch: 7, Batch   210, loss: 0.292\n",
      "Epoch: 7, Batch   220, loss: 0.304\n",
      "Epoch: 7, Batch   230, loss: 0.301\n",
      "Epoch: 7, Batch   240, loss: 0.323\n",
      "Epoch: 7, Batch   250, loss: 0.272\n",
      "Epoch: 7, Batch   260, loss: 0.293\n",
      "Epoch: 7, Batch   270, loss: 0.272\n",
      "Epoch: 7, Batch   280, loss: 0.323\n",
      "Epoch: 7, Batch   290, loss: 0.319\n",
      "Epoch: 7, Batch   300, loss: 0.315\n",
      "Epoch: 7, Batch   310, loss: 0.306\n",
      "Epoch: 7, Batch   320, loss: 0.265\n",
      "Epoch: 7, Batch   330, loss: 0.278\n",
      "Epoch: 7, Batch   340, loss: 0.305\n",
      "Epoch: 7, Batch   350, loss: 0.326\n",
      "Epoch: 7, Batch   360, loss: 0.220\n",
      "Epoch: 7, Batch   370, loss: 0.312\n",
      "Epoch: 7, Batch   380, loss: 0.264\n",
      "Epoch: 7, Batch   390, loss: 0.316\n",
      "Epoch: 7, Batch   400, loss: 0.257\n",
      "Epoch: 7, Batch   410, loss: 0.269\n",
      "Epoch: 7, Batch   420, loss: 0.314\n",
      "Epoch: 7, Batch   430, loss: 0.239\n",
      "Epoch: 7, Batch   440, loss: 0.268\n",
      "Epoch: 7, Batch   450, loss: 0.257\n",
      "Epoch: 7, Batch   460, loss: 0.298\n",
      "Epoch: 7, Batch   470, loss: 0.280\n",
      "Epoch: 7, Batch   480, loss: 0.266\n",
      "Epoch: 7, Batch   490, loss: 0.334\n",
      "Epoch: 7, Batch   500, loss: 0.257\n",
      "Epoch: 7, Batch   510, loss: 0.331\n",
      "Epoch: 7, Batch   520, loss: 0.312\n",
      "Epoch: 7, Batch   530, loss: 0.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Batch   540, loss: 0.308\n",
      "Epoch: 7, Batch   550, loss: 0.281\n",
      "Epoch: 7, Batch   560, loss: 0.284\n",
      "Epoch: 7, Batch   570, loss: 0.254\n",
      "Epoch: 7, Batch   580, loss: 0.308\n",
      "Epoch: 7, Batch   590, loss: 0.269\n",
      "Epoch: 7, Batch   600, loss: 0.287\n",
      "Epoch: 7, Batch   610, loss: 0.306\n",
      "Epoch: 7, Batch   620, loss: 0.322\n",
      "Epoch: 7, Batch   630, loss: 0.337\n",
      "Epoch: 7, Batch   640, loss: 0.287\n",
      "Epoch: 7, Batch   650, loss: 0.321\n",
      "Epoch: 7, Batch   660, loss: 0.262\n",
      "Epoch: 7, Batch   670, loss: 0.204\n",
      "Epoch: 7, Batch   680, loss: 0.280\n",
      "Epoch: 7, Batch   690, loss: 0.293\n",
      "Epoch: 7, Batch   700, loss: 0.320\n",
      "Epoch: 7, Batch   710, loss: 0.305\n",
      "Epoch: 7, Batch   720, loss: 0.299\n",
      "Epoch: 7, Batch   730, loss: 0.259\n",
      "Epoch: 7, Batch   740, loss: 0.301\n",
      "Epoch: 7, Batch   750, loss: 0.289\n",
      "Epoch: 7, Batch   760, loss: 0.260\n",
      "Epoch: 7, Batch   770, loss: 0.269\n",
      "Epoch: 7, Batch   780, loss: 0.286\n",
      "Epoch: 7, Batch   790, loss: 0.287\n",
      "Epoch: 7, Batch   800, loss: 0.288\n",
      "Epoch: 7, Batch   810, loss: 0.312\n",
      "Epoch: 7, Batch   820, loss: 0.281\n",
      "Epoch: 7, Batch   830, loss: 0.304\n",
      "Epoch: 7, Batch   840, loss: 0.256\n",
      "Epoch: 7, Batch   850, loss: 0.310\n",
      "Epoch: 7, Batch   860, loss: 0.296\n",
      "Epoch: 7, Batch   870, loss: 0.321\n",
      "Epoch: 7, Batch   880, loss: 0.252\n",
      "Epoch: 7, Batch   890, loss: 0.250\n",
      "Epoch: 7, Batch   900, loss: 0.251\n",
      "Epoch: 7, Batch   910, loss: 0.301\n",
      "Epoch: 7, Batch   920, loss: 0.236\n",
      "Epoch: 7, Batch   930, loss: 0.317\n",
      "Epoch: 7, Batch   940, loss: 0.287\n",
      "Epoch: 7, Batch   950, loss: 0.252\n",
      "Epoch: 7, Batch   960, loss: 0.235\n",
      "Epoch: 7, Batch   970, loss: 0.270\n",
      "Epoch: 7, Batch   980, loss: 0.293\n",
      "Epoch: 7, Batch   990, loss: 0.260\n",
      "Epoch: 7, Batch  1000, loss: 0.271\n",
      "Epoch: 7, Batch  1010, loss: 0.281\n",
      "Epoch: 7, Batch  1020, loss: 0.288\n",
      "Epoch: 7, Batch  1030, loss: 0.326\n",
      "Epoch: 7, Batch  1040, loss: 0.305\n",
      "Epoch: 7, Batch  1050, loss: 0.256\n",
      "Epoch: 7, Batch  1060, loss: 0.264\n",
      "Epoch: 7, Batch  1070, loss: 0.289\n",
      "Epoch: 7, Batch  1080, loss: 0.228\n",
      "Epoch: 7, Batch  1090, loss: 0.339\n",
      "Epoch: 7, Batch  1100, loss: 0.306\n",
      "Epoch: 7, Batch  1110, loss: 0.316\n",
      "Epoch: 7, Batch  1120, loss: 0.290\n",
      "Epoch: 7, Batch  1130, loss: 0.274\n",
      "Epoch: 7, Batch  1140, loss: 0.240\n",
      "Epoch: 7, Batch  1150, loss: 0.261\n",
      "Epoch: 7, Batch  1160, loss: 0.328\n",
      "Epoch: 7, Batch  1170, loss: 0.218\n",
      "Epoch: 7, Batch  1180, loss: 0.236\n",
      "Epoch: 7, Batch  1190, loss: 0.258\n",
      "Epoch: 7, Batch  1200, loss: 0.277\n",
      "Epoch: 7, Batch  1210, loss: 0.285\n",
      "Epoch: 7, Batch  1220, loss: 0.280\n",
      "Epoch: 7, Batch  1230, loss: 0.229\n",
      "Epoch: 7, Batch  1240, loss: 0.308\n",
      "Epoch: 7, Batch  1250, loss: 0.289\n",
      "Epoch: 7, Batch  1260, loss: 0.273\n",
      "Epoch: 7, Batch  1270, loss: 0.260\n",
      "Epoch: 7, Batch  1280, loss: 0.320\n",
      "Epoch: 7, Batch  1290, loss: 0.322\n",
      "Epoch: 7, Batch  1300, loss: 0.259\n",
      "Epoch: 7, Batch  1310, loss: 0.279\n",
      "Epoch: 7, Batch  1320, loss: 0.297\n",
      "Epoch: 7, Batch  1330, loss: 0.269\n",
      "Epoch: 7, Batch  1340, loss: 0.329\n",
      "Epoch: 7, Batch  1350, loss: 0.318\n",
      "Epoch: 7, Batch  1360, loss: 0.293\n",
      "Epoch: 7, Batch  1370, loss: 0.299\n",
      "Epoch: 7, Batch  1380, loss: 0.240\n",
      "Epoch: 7, Batch  1390, loss: 0.299\n",
      "Epoch: 7, Batch  1400, loss: 0.270\n",
      "Epoch: 7, Batch  1410, loss: 0.274\n",
      "Epoch: 7, Batch  1420, loss: 0.248\n",
      "Epoch: 7, Batch  1430, loss: 0.306\n",
      "Epoch: 7, Batch  1440, loss: 0.276\n",
      "Epoch: 7, Batch  1450, loss: 0.308\n",
      "Epoch: 7, Batch  1460, loss: 0.300\n",
      "Epoch: 7, Batch  1470, loss: 0.284\n",
      "Epoch: 7, Batch  1480, loss: 0.279\n",
      "Epoch: 7, Batch  1490, loss: 0.284\n",
      "Epoch: 7, Batch  1500, loss: 0.212\n",
      "Epoch: 7, Batch  1510, loss: 0.319\n",
      "Epoch: 7, Batch  1520, loss: 0.263\n",
      "Epoch: 7, Batch  1530, loss: 0.285\n",
      "Epoch: 7, Batch  1540, loss: 0.301\n",
      "Epoch: 7, Batch  1550, loss: 0.298\n",
      "Epoch: 7, Batch  1560, loss: 0.240\n",
      "Epoch: 7, Batch  1570, loss: 0.244\n",
      "Epoch: 7, Batch  1580, loss: 0.261\n",
      "Epoch: 7, Batch  1590, loss: 0.226\n",
      "Epoch: 7, Batch  1600, loss: 0.255\n",
      "Epoch: 7, Batch  1610, loss: 0.333\n",
      "Epoch: 7, Batch  1620, loss: 0.329\n",
      "Epoch: 7, Batch  1630, loss: 0.292\n",
      "Epoch: 7, Batch  1640, loss: 0.315\n",
      "Epoch: 7, Batch  1650, loss: 0.254\n",
      "Epoch: 7, Batch  1660, loss: 0.299\n",
      "Epoch: 7, Batch  1670, loss: 0.258\n",
      "Epoch: 7, Batch  1680, loss: 0.260\n",
      "Epoch: 7, Batch  1690, loss: 0.297\n",
      "Epoch: 7, Batch  1700, loss: 0.317\n",
      "Epoch: 7, Batch  1710, loss: 0.284\n",
      "Epoch: 7, Batch  1720, loss: 0.343\n",
      "Epoch: 7, Batch  1730, loss: 0.298\n",
      "Epoch: 7, Batch  1740, loss: 0.249\n",
      "Epoch: 7, Batch  1750, loss: 0.256\n",
      "Epoch: 7, Batch  1760, loss: 0.261\n",
      "Epoch: 7, Batch  1770, loss: 0.277\n",
      "Epoch: 7, Batch  1780, loss: 0.306\n",
      "Epoch: 7, Batch  1790, loss: 0.264\n",
      "Epoch: 7, Batch  1800, loss: 0.296\n",
      "Epoch: 7, Batch  1810, loss: 0.247\n",
      "Epoch: 7, Batch  1820, loss: 0.327\n",
      "Epoch: 7, Batch  1830, loss: 0.293\n",
      "Epoch: 7, Batch  1840, loss: 0.294\n",
      "Epoch: 7, Batch  1850, loss: 0.246\n",
      "Epoch: 7, Batch  1860, loss: 0.304\n",
      "Epoch: 7, Batch  1870, loss: 0.285\n",
      "Epoch: 8, Batch    10, loss: 0.333\n",
      "Epoch: 8, Batch    20, loss: 0.294\n",
      "Epoch: 8, Batch    30, loss: 0.290\n",
      "Epoch: 8, Batch    40, loss: 0.290\n",
      "Epoch: 8, Batch    50, loss: 0.296\n",
      "Epoch: 8, Batch    60, loss: 0.279\n",
      "Epoch: 8, Batch    70, loss: 0.237\n",
      "Epoch: 8, Batch    80, loss: 0.277\n",
      "Epoch: 8, Batch    90, loss: 0.258\n",
      "Epoch: 8, Batch   100, loss: 0.266\n",
      "Epoch: 8, Batch   110, loss: 0.224\n",
      "Epoch: 8, Batch   120, loss: 0.298\n",
      "Epoch: 8, Batch   130, loss: 0.276\n",
      "Epoch: 8, Batch   140, loss: 0.253\n",
      "Epoch: 8, Batch   150, loss: 0.288\n",
      "Epoch: 8, Batch   160, loss: 0.343\n",
      "Epoch: 8, Batch   170, loss: 0.285\n",
      "Epoch: 8, Batch   180, loss: 0.289\n",
      "Epoch: 8, Batch   190, loss: 0.275\n",
      "Epoch: 8, Batch   200, loss: 0.368\n",
      "Epoch: 8, Batch   210, loss: 0.253\n",
      "Epoch: 8, Batch   220, loss: 0.265\n",
      "Epoch: 8, Batch   230, loss: 0.264\n",
      "Epoch: 8, Batch   240, loss: 0.342\n",
      "Epoch: 8, Batch   250, loss: 0.268\n",
      "Epoch: 8, Batch   260, loss: 0.269\n",
      "Epoch: 8, Batch   270, loss: 0.233\n",
      "Epoch: 8, Batch   280, loss: 0.341\n",
      "Epoch: 8, Batch   290, loss: 0.266\n",
      "Epoch: 8, Batch   300, loss: 0.282\n",
      "Epoch: 8, Batch   310, loss: 0.288\n",
      "Epoch: 8, Batch   320, loss: 0.275\n",
      "Epoch: 8, Batch   330, loss: 0.225\n",
      "Epoch: 8, Batch   340, loss: 0.291\n",
      "Epoch: 8, Batch   350, loss: 0.298\n",
      "Epoch: 8, Batch   360, loss: 0.223\n",
      "Epoch: 8, Batch   370, loss: 0.270\n",
      "Epoch: 8, Batch   380, loss: 0.237\n",
      "Epoch: 8, Batch   390, loss: 0.302\n",
      "Epoch: 8, Batch   400, loss: 0.254\n",
      "Epoch: 8, Batch   410, loss: 0.260\n",
      "Epoch: 8, Batch   420, loss: 0.322\n",
      "Epoch: 8, Batch   430, loss: 0.220\n",
      "Epoch: 8, Batch   440, loss: 0.265\n",
      "Epoch: 8, Batch   450, loss: 0.263\n",
      "Epoch: 8, Batch   460, loss: 0.283\n",
      "Epoch: 8, Batch   470, loss: 0.259\n",
      "Epoch: 8, Batch   480, loss: 0.259\n",
      "Epoch: 8, Batch   490, loss: 0.296\n",
      "Epoch: 8, Batch   500, loss: 0.229\n",
      "Epoch: 8, Batch   510, loss: 0.308\n",
      "Epoch: 8, Batch   520, loss: 0.319\n",
      "Epoch: 8, Batch   530, loss: 0.263\n",
      "Epoch: 8, Batch   540, loss: 0.275\n",
      "Epoch: 8, Batch   550, loss: 0.324\n",
      "Epoch: 8, Batch   560, loss: 0.286\n",
      "Epoch: 8, Batch   570, loss: 0.263\n",
      "Epoch: 8, Batch   580, loss: 0.247\n",
      "Epoch: 8, Batch   590, loss: 0.248\n",
      "Epoch: 8, Batch   600, loss: 0.268\n",
      "Epoch: 8, Batch   610, loss: 0.251\n",
      "Epoch: 8, Batch   620, loss: 0.320\n",
      "Epoch: 8, Batch   630, loss: 0.337\n",
      "Epoch: 8, Batch   640, loss: 0.264\n",
      "Epoch: 8, Batch   650, loss: 0.289\n",
      "Epoch: 8, Batch   660, loss: 0.271\n",
      "Epoch: 8, Batch   670, loss: 0.222\n",
      "Epoch: 8, Batch   680, loss: 0.242\n",
      "Epoch: 8, Batch   690, loss: 0.296\n",
      "Epoch: 8, Batch   700, loss: 0.265\n",
      "Epoch: 8, Batch   710, loss: 0.332\n",
      "Epoch: 8, Batch   720, loss: 0.289\n",
      "Epoch: 8, Batch   730, loss: 0.314\n",
      "Epoch: 8, Batch   740, loss: 0.286\n",
      "Epoch: 8, Batch   750, loss: 0.276\n",
      "Epoch: 8, Batch   760, loss: 0.263\n",
      "Epoch: 8, Batch   770, loss: 0.324\n",
      "Epoch: 8, Batch   780, loss: 0.280\n",
      "Epoch: 8, Batch   790, loss: 0.315\n",
      "Epoch: 8, Batch   800, loss: 0.287\n",
      "Epoch: 8, Batch   810, loss: 0.305\n",
      "Epoch: 8, Batch   820, loss: 0.269\n",
      "Epoch: 8, Batch   830, loss: 0.286\n",
      "Epoch: 8, Batch   840, loss: 0.231\n",
      "Epoch: 8, Batch   850, loss: 0.316\n",
      "Epoch: 8, Batch   860, loss: 0.295\n",
      "Epoch: 8, Batch   870, loss: 0.329\n",
      "Epoch: 8, Batch   880, loss: 0.240\n",
      "Epoch: 8, Batch   890, loss: 0.250\n",
      "Epoch: 8, Batch   900, loss: 0.239\n",
      "Epoch: 8, Batch   910, loss: 0.281\n",
      "Epoch: 8, Batch   920, loss: 0.243\n",
      "Epoch: 8, Batch   930, loss: 0.298\n",
      "Epoch: 8, Batch   940, loss: 0.263\n",
      "Epoch: 8, Batch   950, loss: 0.250\n",
      "Epoch: 8, Batch   960, loss: 0.252\n",
      "Epoch: 8, Batch   970, loss: 0.237\n",
      "Epoch: 8, Batch   980, loss: 0.259\n",
      "Epoch: 8, Batch   990, loss: 0.223\n",
      "Epoch: 8, Batch  1000, loss: 0.238\n",
      "Epoch: 8, Batch  1010, loss: 0.264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Batch  1020, loss: 0.281\n",
      "Epoch: 8, Batch  1030, loss: 0.278\n",
      "Epoch: 8, Batch  1040, loss: 0.295\n",
      "Epoch: 8, Batch  1050, loss: 0.239\n",
      "Epoch: 8, Batch  1060, loss: 0.275\n",
      "Epoch: 8, Batch  1070, loss: 0.283\n",
      "Epoch: 8, Batch  1080, loss: 0.272\n",
      "Epoch: 8, Batch  1090, loss: 0.326\n",
      "Epoch: 8, Batch  1100, loss: 0.299\n",
      "Epoch: 8, Batch  1110, loss: 0.266\n",
      "Epoch: 8, Batch  1120, loss: 0.267\n",
      "Epoch: 8, Batch  1130, loss: 0.277\n",
      "Epoch: 8, Batch  1140, loss: 0.305\n",
      "Epoch: 8, Batch  1150, loss: 0.247\n",
      "Epoch: 8, Batch  1160, loss: 0.336\n",
      "Epoch: 8, Batch  1170, loss: 0.218\n",
      "Epoch: 8, Batch  1180, loss: 0.235\n",
      "Epoch: 8, Batch  1190, loss: 0.262\n",
      "Epoch: 8, Batch  1200, loss: 0.304\n",
      "Epoch: 8, Batch  1210, loss: 0.256\n",
      "Epoch: 8, Batch  1220, loss: 0.280\n",
      "Epoch: 8, Batch  1230, loss: 0.262\n",
      "Epoch: 8, Batch  1240, loss: 0.279\n",
      "Epoch: 8, Batch  1250, loss: 0.276\n",
      "Epoch: 8, Batch  1260, loss: 0.266\n",
      "Epoch: 8, Batch  1270, loss: 0.245\n",
      "Epoch: 8, Batch  1280, loss: 0.269\n",
      "Epoch: 8, Batch  1290, loss: 0.272\n",
      "Epoch: 8, Batch  1300, loss: 0.261\n",
      "Epoch: 8, Batch  1310, loss: 0.255\n",
      "Epoch: 8, Batch  1320, loss: 0.299\n",
      "Epoch: 8, Batch  1330, loss: 0.292\n",
      "Epoch: 8, Batch  1340, loss: 0.265\n",
      "Epoch: 8, Batch  1350, loss: 0.267\n",
      "Epoch: 8, Batch  1360, loss: 0.236\n",
      "Epoch: 8, Batch  1370, loss: 0.274\n",
      "Epoch: 8, Batch  1380, loss: 0.273\n",
      "Epoch: 8, Batch  1390, loss: 0.305\n",
      "Epoch: 8, Batch  1400, loss: 0.259\n",
      "Epoch: 8, Batch  1410, loss: 0.273\n",
      "Epoch: 8, Batch  1420, loss: 0.247\n",
      "Epoch: 8, Batch  1430, loss: 0.289\n",
      "Epoch: 8, Batch  1440, loss: 0.255\n",
      "Epoch: 8, Batch  1450, loss: 0.254\n",
      "Epoch: 8, Batch  1460, loss: 0.242\n",
      "Epoch: 8, Batch  1470, loss: 0.246\n",
      "Epoch: 8, Batch  1480, loss: 0.290\n",
      "Epoch: 8, Batch  1490, loss: 0.279\n",
      "Epoch: 8, Batch  1500, loss: 0.229\n",
      "Epoch: 8, Batch  1510, loss: 0.282\n",
      "Epoch: 8, Batch  1520, loss: 0.234\n",
      "Epoch: 8, Batch  1530, loss: 0.306\n",
      "Epoch: 8, Batch  1540, loss: 0.271\n",
      "Epoch: 8, Batch  1550, loss: 0.257\n",
      "Epoch: 8, Batch  1560, loss: 0.243\n",
      "Epoch: 8, Batch  1570, loss: 0.255\n",
      "Epoch: 8, Batch  1580, loss: 0.248\n",
      "Epoch: 8, Batch  1590, loss: 0.236\n",
      "Epoch: 8, Batch  1600, loss: 0.257\n",
      "Epoch: 8, Batch  1610, loss: 0.330\n",
      "Epoch: 8, Batch  1620, loss: 0.268\n",
      "Epoch: 8, Batch  1630, loss: 0.267\n",
      "Epoch: 8, Batch  1640, loss: 0.298\n",
      "Epoch: 8, Batch  1650, loss: 0.264\n",
      "Epoch: 8, Batch  1660, loss: 0.244\n",
      "Epoch: 8, Batch  1670, loss: 0.228\n",
      "Epoch: 8, Batch  1680, loss: 0.264\n",
      "Epoch: 8, Batch  1690, loss: 0.251\n",
      "Epoch: 8, Batch  1700, loss: 0.294\n",
      "Epoch: 8, Batch  1710, loss: 0.270\n",
      "Epoch: 8, Batch  1720, loss: 0.300\n",
      "Epoch: 8, Batch  1730, loss: 0.280\n",
      "Epoch: 8, Batch  1740, loss: 0.245\n",
      "Epoch: 8, Batch  1750, loss: 0.236\n",
      "Epoch: 8, Batch  1760, loss: 0.247\n",
      "Epoch: 8, Batch  1770, loss: 0.258\n",
      "Epoch: 8, Batch  1780, loss: 0.286\n",
      "Epoch: 8, Batch  1790, loss: 0.286\n",
      "Epoch: 8, Batch  1800, loss: 0.289\n",
      "Epoch: 8, Batch  1810, loss: 0.239\n",
      "Epoch: 8, Batch  1820, loss: 0.301\n",
      "Epoch: 8, Batch  1830, loss: 0.288\n",
      "Epoch: 8, Batch  1840, loss: 0.279\n",
      "Epoch: 8, Batch  1850, loss: 0.233\n",
      "Epoch: 8, Batch  1860, loss: 0.255\n",
      "Epoch: 8, Batch  1870, loss: 0.265\n",
      "Epoch: 9, Batch    10, loss: 0.281\n",
      "Epoch: 9, Batch    20, loss: 0.262\n",
      "Epoch: 9, Batch    30, loss: 0.244\n",
      "Epoch: 9, Batch    40, loss: 0.315\n",
      "Epoch: 9, Batch    50, loss: 0.289\n",
      "Epoch: 9, Batch    60, loss: 0.230\n",
      "Epoch: 9, Batch    70, loss: 0.199\n",
      "Epoch: 9, Batch    80, loss: 0.263\n",
      "Epoch: 9, Batch    90, loss: 0.252\n",
      "Epoch: 9, Batch   100, loss: 0.243\n",
      "Epoch: 9, Batch   110, loss: 0.187\n",
      "Epoch: 9, Batch   120, loss: 0.279\n",
      "Epoch: 9, Batch   130, loss: 0.278\n",
      "Epoch: 9, Batch   140, loss: 0.268\n",
      "Epoch: 9, Batch   150, loss: 0.261\n",
      "Epoch: 9, Batch   160, loss: 0.334\n",
      "Epoch: 9, Batch   170, loss: 0.259\n",
      "Epoch: 9, Batch   180, loss: 0.305\n",
      "Epoch: 9, Batch   190, loss: 0.277\n",
      "Epoch: 9, Batch   200, loss: 0.302\n",
      "Epoch: 9, Batch   210, loss: 0.302\n",
      "Epoch: 9, Batch   220, loss: 0.279\n",
      "Epoch: 9, Batch   230, loss: 0.269\n",
      "Epoch: 9, Batch   240, loss: 0.251\n",
      "Epoch: 9, Batch   250, loss: 0.227\n",
      "Epoch: 9, Batch   260, loss: 0.300\n",
      "Epoch: 9, Batch   270, loss: 0.271\n",
      "Epoch: 9, Batch   280, loss: 0.314\n",
      "Epoch: 9, Batch   290, loss: 0.272\n",
      "Epoch: 9, Batch   300, loss: 0.275\n",
      "Epoch: 9, Batch   310, loss: 0.297\n",
      "Epoch: 9, Batch   320, loss: 0.279\n",
      "Epoch: 9, Batch   330, loss: 0.269\n",
      "Epoch: 9, Batch   340, loss: 0.295\n",
      "Epoch: 9, Batch   350, loss: 0.286\n",
      "Epoch: 9, Batch   360, loss: 0.222\n",
      "Epoch: 9, Batch   370, loss: 0.267\n",
      "Epoch: 9, Batch   380, loss: 0.205\n",
      "Epoch: 9, Batch   390, loss: 0.261\n",
      "Epoch: 9, Batch   400, loss: 0.204\n",
      "Epoch: 9, Batch   410, loss: 0.244\n",
      "Epoch: 9, Batch   420, loss: 0.316\n",
      "Epoch: 9, Batch   430, loss: 0.221\n",
      "Epoch: 9, Batch   440, loss: 0.257\n",
      "Epoch: 9, Batch   450, loss: 0.288\n",
      "Epoch: 9, Batch   460, loss: 0.255\n",
      "Epoch: 9, Batch   470, loss: 0.245\n",
      "Epoch: 9, Batch   480, loss: 0.258\n",
      "Epoch: 9, Batch   490, loss: 0.320\n",
      "Epoch: 9, Batch   500, loss: 0.226\n",
      "Epoch: 9, Batch   510, loss: 0.314\n",
      "Epoch: 9, Batch   520, loss: 0.313\n",
      "Epoch: 9, Batch   530, loss: 0.240\n",
      "Epoch: 9, Batch   540, loss: 0.263\n",
      "Epoch: 9, Batch   550, loss: 0.267\n",
      "Epoch: 9, Batch   560, loss: 0.275\n",
      "Epoch: 9, Batch   570, loss: 0.248\n",
      "Epoch: 9, Batch   580, loss: 0.270\n",
      "Epoch: 9, Batch   590, loss: 0.278\n",
      "Epoch: 9, Batch   600, loss: 0.281\n",
      "Epoch: 9, Batch   610, loss: 0.242\n",
      "Epoch: 9, Batch   620, loss: 0.334\n",
      "Epoch: 9, Batch   630, loss: 0.359\n",
      "Epoch: 9, Batch   640, loss: 0.247\n",
      "Epoch: 9, Batch   650, loss: 0.266\n",
      "Epoch: 9, Batch   660, loss: 0.266\n",
      "Epoch: 9, Batch   670, loss: 0.219\n",
      "Epoch: 9, Batch   680, loss: 0.259\n",
      "Epoch: 9, Batch   690, loss: 0.272\n",
      "Epoch: 9, Batch   700, loss: 0.252\n",
      "Epoch: 9, Batch   710, loss: 0.282\n",
      "Epoch: 9, Batch   720, loss: 0.267\n",
      "Epoch: 9, Batch   730, loss: 0.227\n",
      "Epoch: 9, Batch   740, loss: 0.294\n",
      "Epoch: 9, Batch   750, loss: 0.258\n",
      "Epoch: 9, Batch   760, loss: 0.254\n",
      "Epoch: 9, Batch   770, loss: 0.317\n",
      "Epoch: 9, Batch   780, loss: 0.273\n",
      "Epoch: 9, Batch   790, loss: 0.263\n",
      "Epoch: 9, Batch   800, loss: 0.265\n",
      "Epoch: 9, Batch   810, loss: 0.268\n",
      "Epoch: 9, Batch   820, loss: 0.263\n",
      "Epoch: 9, Batch   830, loss: 0.290\n",
      "Epoch: 9, Batch   840, loss: 0.228\n",
      "Epoch: 9, Batch   850, loss: 0.274\n",
      "Epoch: 9, Batch   860, loss: 0.317\n",
      "Epoch: 9, Batch   870, loss: 0.261\n",
      "Epoch: 9, Batch   880, loss: 0.261\n",
      "Epoch: 9, Batch   890, loss: 0.246\n",
      "Epoch: 9, Batch   900, loss: 0.246\n",
      "Epoch: 9, Batch   910, loss: 0.261\n",
      "Epoch: 9, Batch   920, loss: 0.286\n",
      "Epoch: 9, Batch   930, loss: 0.288\n",
      "Epoch: 9, Batch   940, loss: 0.257\n",
      "Epoch: 9, Batch   950, loss: 0.257\n",
      "Epoch: 9, Batch   960, loss: 0.230\n",
      "Epoch: 9, Batch   970, loss: 0.212\n",
      "Epoch: 9, Batch   980, loss: 0.268\n",
      "Epoch: 9, Batch   990, loss: 0.204\n",
      "Epoch: 9, Batch  1000, loss: 0.247\n",
      "Epoch: 9, Batch  1010, loss: 0.281\n",
      "Epoch: 9, Batch  1020, loss: 0.245\n",
      "Epoch: 9, Batch  1030, loss: 0.299\n",
      "Epoch: 9, Batch  1040, loss: 0.286\n",
      "Epoch: 9, Batch  1050, loss: 0.227\n",
      "Epoch: 9, Batch  1060, loss: 0.223\n",
      "Epoch: 9, Batch  1070, loss: 0.302\n",
      "Epoch: 9, Batch  1080, loss: 0.241\n",
      "Epoch: 9, Batch  1090, loss: 0.294\n",
      "Epoch: 9, Batch  1100, loss: 0.274\n",
      "Epoch: 9, Batch  1110, loss: 0.315\n",
      "Epoch: 9, Batch  1120, loss: 0.274\n",
      "Epoch: 9, Batch  1130, loss: 0.279\n",
      "Epoch: 9, Batch  1140, loss: 0.235\n",
      "Epoch: 9, Batch  1150, loss: 0.243\n",
      "Epoch: 9, Batch  1160, loss: 0.301\n",
      "Epoch: 9, Batch  1170, loss: 0.203\n",
      "Epoch: 9, Batch  1180, loss: 0.218\n",
      "Epoch: 9, Batch  1190, loss: 0.280\n",
      "Epoch: 9, Batch  1200, loss: 0.279\n",
      "Epoch: 9, Batch  1210, loss: 0.247\n",
      "Epoch: 9, Batch  1220, loss: 0.270\n",
      "Epoch: 9, Batch  1230, loss: 0.251\n",
      "Epoch: 9, Batch  1240, loss: 0.265\n",
      "Epoch: 9, Batch  1250, loss: 0.235\n",
      "Epoch: 9, Batch  1260, loss: 0.266\n",
      "Epoch: 9, Batch  1270, loss: 0.250\n",
      "Epoch: 9, Batch  1280, loss: 0.270\n",
      "Epoch: 9, Batch  1290, loss: 0.299\n",
      "Epoch: 9, Batch  1300, loss: 0.216\n",
      "Epoch: 9, Batch  1310, loss: 0.282\n",
      "Epoch: 9, Batch  1320, loss: 0.266\n",
      "Epoch: 9, Batch  1330, loss: 0.279\n",
      "Epoch: 9, Batch  1340, loss: 0.251\n",
      "Epoch: 9, Batch  1350, loss: 0.271\n",
      "Epoch: 9, Batch  1360, loss: 0.254\n",
      "Epoch: 9, Batch  1370, loss: 0.255\n",
      "Epoch: 9, Batch  1380, loss: 0.230\n",
      "Epoch: 9, Batch  1390, loss: 0.277\n",
      "Epoch: 9, Batch  1400, loss: 0.258\n",
      "Epoch: 9, Batch  1410, loss: 0.258\n",
      "Epoch: 9, Batch  1420, loss: 0.261\n",
      "Epoch: 9, Batch  1430, loss: 0.274\n",
      "Epoch: 9, Batch  1440, loss: 0.273\n",
      "Epoch: 9, Batch  1450, loss: 0.266\n",
      "Epoch: 9, Batch  1460, loss: 0.260\n",
      "Epoch: 9, Batch  1470, loss: 0.255\n",
      "Epoch: 9, Batch  1480, loss: 0.273\n",
      "Epoch: 9, Batch  1490, loss: 0.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Batch  1500, loss: 0.253\n",
      "Epoch: 9, Batch  1510, loss: 0.291\n",
      "Epoch: 9, Batch  1520, loss: 0.230\n",
      "Epoch: 9, Batch  1530, loss: 0.284\n",
      "Epoch: 9, Batch  1540, loss: 0.270\n",
      "Epoch: 9, Batch  1550, loss: 0.299\n",
      "Epoch: 9, Batch  1560, loss: 0.258\n",
      "Epoch: 9, Batch  1570, loss: 0.277\n",
      "Epoch: 9, Batch  1580, loss: 0.258\n",
      "Epoch: 9, Batch  1590, loss: 0.244\n",
      "Epoch: 9, Batch  1600, loss: 0.272\n",
      "Epoch: 9, Batch  1610, loss: 0.297\n",
      "Epoch: 9, Batch  1620, loss: 0.269\n",
      "Epoch: 9, Batch  1630, loss: 0.275\n",
      "Epoch: 9, Batch  1640, loss: 0.289\n",
      "Epoch: 9, Batch  1650, loss: 0.235\n",
      "Epoch: 9, Batch  1660, loss: 0.222\n",
      "Epoch: 9, Batch  1670, loss: 0.221\n",
      "Epoch: 9, Batch  1680, loss: 0.243\n",
      "Epoch: 9, Batch  1690, loss: 0.253\n",
      "Epoch: 9, Batch  1700, loss: 0.274\n",
      "Epoch: 9, Batch  1710, loss: 0.275\n",
      "Epoch: 9, Batch  1720, loss: 0.296\n",
      "Epoch: 9, Batch  1730, loss: 0.233\n",
      "Epoch: 9, Batch  1740, loss: 0.219\n",
      "Epoch: 9, Batch  1750, loss: 0.239\n",
      "Epoch: 9, Batch  1760, loss: 0.230\n",
      "Epoch: 9, Batch  1770, loss: 0.266\n",
      "Epoch: 9, Batch  1780, loss: 0.288\n",
      "Epoch: 9, Batch  1790, loss: 0.291\n",
      "Epoch: 9, Batch  1800, loss: 0.252\n",
      "Epoch: 9, Batch  1810, loss: 0.224\n",
      "Epoch: 9, Batch  1820, loss: 0.331\n",
      "Epoch: 9, Batch  1830, loss: 0.283\n",
      "Epoch: 9, Batch  1840, loss: 0.231\n",
      "Epoch: 9, Batch  1850, loss: 0.239\n",
      "Epoch: 9, Batch  1860, loss: 0.277\n",
      "Epoch: 9, Batch  1870, loss: 0.307\n",
      "Epoch: 10, Batch    10, loss: 0.257\n",
      "Epoch: 10, Batch    20, loss: 0.261\n",
      "Epoch: 10, Batch    30, loss: 0.244\n",
      "Epoch: 10, Batch    40, loss: 0.262\n",
      "Epoch: 10, Batch    50, loss: 0.229\n",
      "Epoch: 10, Batch    60, loss: 0.231\n",
      "Epoch: 10, Batch    70, loss: 0.217\n",
      "Epoch: 10, Batch    80, loss: 0.238\n",
      "Epoch: 10, Batch    90, loss: 0.231\n",
      "Epoch: 10, Batch   100, loss: 0.262\n",
      "Epoch: 10, Batch   110, loss: 0.177\n",
      "Epoch: 10, Batch   120, loss: 0.272\n",
      "Epoch: 10, Batch   130, loss: 0.255\n",
      "Epoch: 10, Batch   140, loss: 0.215\n",
      "Epoch: 10, Batch   150, loss: 0.243\n",
      "Epoch: 10, Batch   160, loss: 0.334\n",
      "Epoch: 10, Batch   170, loss: 0.230\n",
      "Epoch: 10, Batch   180, loss: 0.277\n",
      "Epoch: 10, Batch   190, loss: 0.279\n",
      "Epoch: 10, Batch   200, loss: 0.307\n",
      "Epoch: 10, Batch   210, loss: 0.282\n",
      "Epoch: 10, Batch   220, loss: 0.254\n",
      "Epoch: 10, Batch   230, loss: 0.275\n",
      "Epoch: 10, Batch   240, loss: 0.320\n",
      "Epoch: 10, Batch   250, loss: 0.273\n",
      "Epoch: 10, Batch   260, loss: 0.271\n",
      "Epoch: 10, Batch   270, loss: 0.244\n",
      "Epoch: 10, Batch   280, loss: 0.300\n",
      "Epoch: 10, Batch   290, loss: 0.255\n",
      "Epoch: 10, Batch   300, loss: 0.297\n",
      "Epoch: 10, Batch   310, loss: 0.282\n",
      "Epoch: 10, Batch   320, loss: 0.289\n",
      "Epoch: 10, Batch   330, loss: 0.248\n",
      "Epoch: 10, Batch   340, loss: 0.266\n",
      "Epoch: 10, Batch   350, loss: 0.314\n",
      "Epoch: 10, Batch   360, loss: 0.262\n",
      "Epoch: 10, Batch   370, loss: 0.254\n",
      "Epoch: 10, Batch   380, loss: 0.218\n",
      "Epoch: 10, Batch   390, loss: 0.246\n",
      "Epoch: 10, Batch   400, loss: 0.241\n",
      "Epoch: 10, Batch   410, loss: 0.229\n",
      "Epoch: 10, Batch   420, loss: 0.313\n",
      "Epoch: 10, Batch   430, loss: 0.242\n",
      "Epoch: 10, Batch   440, loss: 0.254\n",
      "Epoch: 10, Batch   450, loss: 0.248\n",
      "Epoch: 10, Batch   460, loss: 0.284\n",
      "Epoch: 10, Batch   470, loss: 0.268\n",
      "Epoch: 10, Batch   480, loss: 0.255\n",
      "Epoch: 10, Batch   490, loss: 0.275\n",
      "Epoch: 10, Batch   500, loss: 0.268\n",
      "Epoch: 10, Batch   510, loss: 0.296\n",
      "Epoch: 10, Batch   520, loss: 0.298\n",
      "Epoch: 10, Batch   530, loss: 0.271\n",
      "Epoch: 10, Batch   540, loss: 0.250\n",
      "Epoch: 10, Batch   550, loss: 0.271\n",
      "Epoch: 10, Batch   560, loss: 0.248\n",
      "Epoch: 10, Batch   570, loss: 0.245\n",
      "Epoch: 10, Batch   580, loss: 0.228\n",
      "Epoch: 10, Batch   590, loss: 0.234\n",
      "Epoch: 10, Batch   600, loss: 0.257\n",
      "Epoch: 10, Batch   610, loss: 0.244\n",
      "Epoch: 10, Batch   620, loss: 0.287\n",
      "Epoch: 10, Batch   630, loss: 0.318\n",
      "Epoch: 10, Batch   640, loss: 0.256\n",
      "Epoch: 10, Batch   650, loss: 0.274\n",
      "Epoch: 10, Batch   660, loss: 0.248\n",
      "Epoch: 10, Batch   670, loss: 0.211\n",
      "Epoch: 10, Batch   680, loss: 0.222\n",
      "Epoch: 10, Batch   690, loss: 0.242\n",
      "Epoch: 10, Batch   700, loss: 0.236\n",
      "Epoch: 10, Batch   710, loss: 0.287\n",
      "Epoch: 10, Batch   720, loss: 0.246\n",
      "Epoch: 10, Batch   730, loss: 0.245\n",
      "Epoch: 10, Batch   740, loss: 0.280\n",
      "Epoch: 10, Batch   750, loss: 0.282\n",
      "Epoch: 10, Batch   760, loss: 0.255\n",
      "Epoch: 10, Batch   770, loss: 0.327\n",
      "Epoch: 10, Batch   780, loss: 0.265\n",
      "Epoch: 10, Batch   790, loss: 0.261\n",
      "Epoch: 10, Batch   800, loss: 0.259\n",
      "Epoch: 10, Batch   810, loss: 0.276\n",
      "Epoch: 10, Batch   820, loss: 0.287\n",
      "Epoch: 10, Batch   830, loss: 0.276\n",
      "Epoch: 10, Batch   840, loss: 0.189\n",
      "Epoch: 10, Batch   850, loss: 0.266\n",
      "Epoch: 10, Batch   860, loss: 0.273\n",
      "Epoch: 10, Batch   870, loss: 0.264\n",
      "Epoch: 10, Batch   880, loss: 0.213\n",
      "Epoch: 10, Batch   890, loss: 0.241\n",
      "Epoch: 10, Batch   900, loss: 0.222\n",
      "Epoch: 10, Batch   910, loss: 0.276\n",
      "Epoch: 10, Batch   920, loss: 0.221\n",
      "Epoch: 10, Batch   930, loss: 0.259\n",
      "Epoch: 10, Batch   940, loss: 0.257\n",
      "Epoch: 10, Batch   950, loss: 0.215\n",
      "Epoch: 10, Batch   960, loss: 0.243\n",
      "Epoch: 10, Batch   970, loss: 0.232\n",
      "Epoch: 10, Batch   980, loss: 0.286\n",
      "Epoch: 10, Batch   990, loss: 0.199\n",
      "Epoch: 10, Batch  1000, loss: 0.235\n",
      "Epoch: 10, Batch  1010, loss: 0.238\n",
      "Epoch: 10, Batch  1020, loss: 0.253\n",
      "Epoch: 10, Batch  1030, loss: 0.311\n",
      "Epoch: 10, Batch  1040, loss: 0.285\n",
      "Epoch: 10, Batch  1050, loss: 0.180\n",
      "Epoch: 10, Batch  1060, loss: 0.234\n",
      "Epoch: 10, Batch  1070, loss: 0.283\n",
      "Epoch: 10, Batch  1080, loss: 0.231\n",
      "Epoch: 10, Batch  1090, loss: 0.258\n",
      "Epoch: 10, Batch  1100, loss: 0.260\n",
      "Epoch: 10, Batch  1110, loss: 0.287\n",
      "Epoch: 10, Batch  1120, loss: 0.258\n",
      "Epoch: 10, Batch  1130, loss: 0.253\n",
      "Epoch: 10, Batch  1140, loss: 0.208\n",
      "Epoch: 10, Batch  1150, loss: 0.260\n",
      "Epoch: 10, Batch  1160, loss: 0.274\n",
      "Epoch: 10, Batch  1170, loss: 0.242\n",
      "Epoch: 10, Batch  1180, loss: 0.215\n",
      "Epoch: 10, Batch  1190, loss: 0.253\n",
      "Epoch: 10, Batch  1200, loss: 0.253\n",
      "Epoch: 10, Batch  1210, loss: 0.224\n",
      "Epoch: 10, Batch  1220, loss: 0.243\n",
      "Epoch: 10, Batch  1230, loss: 0.225\n",
      "Epoch: 10, Batch  1240, loss: 0.276\n",
      "Epoch: 10, Batch  1250, loss: 0.261\n",
      "Epoch: 10, Batch  1260, loss: 0.257\n",
      "Epoch: 10, Batch  1270, loss: 0.206\n",
      "Epoch: 10, Batch  1280, loss: 0.266\n",
      "Epoch: 10, Batch  1290, loss: 0.310\n",
      "Epoch: 10, Batch  1300, loss: 0.259\n",
      "Epoch: 10, Batch  1310, loss: 0.254\n",
      "Epoch: 10, Batch  1320, loss: 0.299\n",
      "Epoch: 10, Batch  1330, loss: 0.260\n",
      "Epoch: 10, Batch  1340, loss: 0.251\n",
      "Epoch: 10, Batch  1350, loss: 0.317\n",
      "Epoch: 10, Batch  1360, loss: 0.220\n",
      "Epoch: 10, Batch  1370, loss: 0.248\n",
      "Epoch: 10, Batch  1380, loss: 0.220\n",
      "Epoch: 10, Batch  1390, loss: 0.288\n",
      "Epoch: 10, Batch  1400, loss: 0.250\n",
      "Epoch: 10, Batch  1410, loss: 0.281\n",
      "Epoch: 10, Batch  1420, loss: 0.253\n",
      "Epoch: 10, Batch  1430, loss: 0.301\n",
      "Epoch: 10, Batch  1440, loss: 0.293\n",
      "Epoch: 10, Batch  1450, loss: 0.217\n",
      "Epoch: 10, Batch  1460, loss: 0.221\n",
      "Epoch: 10, Batch  1470, loss: 0.229\n",
      "Epoch: 10, Batch  1480, loss: 0.283\n",
      "Epoch: 10, Batch  1490, loss: 0.271\n",
      "Epoch: 10, Batch  1500, loss: 0.216\n",
      "Epoch: 10, Batch  1510, loss: 0.280\n",
      "Epoch: 10, Batch  1520, loss: 0.191\n",
      "Epoch: 10, Batch  1530, loss: 0.256\n",
      "Epoch: 10, Batch  1540, loss: 0.281\n",
      "Epoch: 10, Batch  1550, loss: 0.263\n",
      "Epoch: 10, Batch  1560, loss: 0.221\n",
      "Epoch: 10, Batch  1570, loss: 0.213\n",
      "Epoch: 10, Batch  1580, loss: 0.234\n",
      "Epoch: 10, Batch  1590, loss: 0.238\n",
      "Epoch: 10, Batch  1600, loss: 0.243\n",
      "Epoch: 10, Batch  1610, loss: 0.304\n",
      "Epoch: 10, Batch  1620, loss: 0.267\n",
      "Epoch: 10, Batch  1630, loss: 0.267\n",
      "Epoch: 10, Batch  1640, loss: 0.253\n",
      "Epoch: 10, Batch  1650, loss: 0.249\n",
      "Epoch: 10, Batch  1660, loss: 0.212\n",
      "Epoch: 10, Batch  1670, loss: 0.208\n",
      "Epoch: 10, Batch  1680, loss: 0.259\n",
      "Epoch: 10, Batch  1690, loss: 0.271\n",
      "Epoch: 10, Batch  1700, loss: 0.230\n",
      "Epoch: 10, Batch  1710, loss: 0.275\n",
      "Epoch: 10, Batch  1720, loss: 0.316\n",
      "Epoch: 10, Batch  1730, loss: 0.241\n",
      "Epoch: 10, Batch  1740, loss: 0.207\n",
      "Epoch: 10, Batch  1750, loss: 0.240\n",
      "Epoch: 10, Batch  1760, loss: 0.247\n",
      "Epoch: 10, Batch  1770, loss: 0.274\n",
      "Epoch: 10, Batch  1780, loss: 0.260\n",
      "Epoch: 10, Batch  1790, loss: 0.222\n",
      "Epoch: 10, Batch  1800, loss: 0.302\n",
      "Epoch: 10, Batch  1810, loss: 0.267\n",
      "Epoch: 10, Batch  1820, loss: 0.306\n",
      "Epoch: 10, Batch  1830, loss: 0.256\n",
      "Epoch: 10, Batch  1840, loss: 0.287\n",
      "Epoch: 10, Batch  1850, loss: 0.198\n",
      "Epoch: 10, Batch  1860, loss: 0.286\n",
      "Epoch: 10, Batch  1870, loss: 0.245\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "# 5 epochs\n",
    "for epoch in range(10):\n",
    "    # Keep track of loss for each mini-batch\n",
    "    # Each mini-batch is going to be 32 examples\n",
    "    BATCH_SIZE = 32# 5 epochs\n",
    "for epoch in range(10):\n",
    "    # Keep track of loss for each mini-batch\n",
    "    # Each mini-batch is going to be 32 examples\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    losses = 0\n",
    "    accuracies = 0\n",
    "    for i, position in enumerate(range(0, len(train_data), BATCH_SIZE)):\n",
    "        if (position + BATCH_SIZE > len(train_data)):\n",
    "            batch_data = train_data[position:]\n",
    "            batch_labels = train_labels[position:]\n",
    "        else:\n",
    "            batch_data = train_data[position:position + BATCH_SIZE]\n",
    "            batch_labels = train_labels[position:position + BATCH_SIZE]\n",
    "            \n",
    "        # Zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        forward = net(batch_data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(forward, torch.from_numpy(batch_labels).view(-1).long())\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        \n",
    "        # Apply the gradients\n",
    "        opt.step()\n",
    "        \n",
    "        losses += loss.item()\n",
    "        if (i % 10 == 9):\n",
    "            # Print statistics every batch\n",
    "            print('Epoch: %d, Batch %5d, loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, losses/10))\n",
    "            \n",
    "            losses = 0\n",
    "\n",
    "print('Finished training')\n",
    "    \n",
    "    losses = 0\n",
    "    accuracies = 0\n",
    "    for i, position in enumerate(range(0, len(train_data), BATCH_SIZE)):\n",
    "        if (position + BATCH_SIZE > len(train_data)):\n",
    "            batch_data = train_data[position:]\n",
    "            batch_labels = train_labels[position:]\n",
    "        else:\n",
    "            batch_data = train_data[position:position + BATCH_SIZE]\n",
    "            batch_labels = train_labels[position:position + BATCH_SIZE]\n",
    "            \n",
    "        # Zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        forward = net(batch_data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(forward, torch.from_numpy(batch_labels).view(-1).long())\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        \n",
    "        # Apply the gradients\n",
    "        opt.step()\n",
    "        \n",
    "        losses += loss.item()\n",
    "        if (i % 10 == 9):\n",
    "            # Print statistics every batch\n",
    "            print('Epoch: %d, Batch %5d, loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, losses/10))\n",
    "            \n",
    "            losses = 0\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 Accuracy: 0.875\n",
      "Batch: 2 Accuracy: 0.90625\n",
      "Batch: 3 Accuracy: 0.890625\n",
      "Batch: 4 Accuracy: 0.890625\n",
      "Batch: 5 Accuracy: 0.984375\n",
      "Batch: 6 Accuracy: 0.9375\n",
      "Batch: 7 Accuracy: 0.921875\n",
      "Batch: 8 Accuracy: 0.890625\n",
      "Batch: 9 Accuracy: 0.90625\n",
      "Batch: 10 Accuracy: 0.90625\n",
      "Batch: 11 Accuracy: 0.9375\n",
      "Batch: 12 Accuracy: 0.96875\n",
      "Batch: 13 Accuracy: 0.875\n",
      "Batch: 14 Accuracy: 0.859375\n",
      "Batch: 15 Accuracy: 0.96875\n",
      "Batch: 16 Accuracy: 0.921875\n",
      "Batch: 17 Accuracy: 0.890625\n",
      "Batch: 18 Accuracy: 0.953125\n",
      "Batch: 19 Accuracy: 0.96875\n",
      "Batch: 20 Accuracy: 0.921875\n",
      "Batch: 21 Accuracy: 0.890625\n",
      "Batch: 22 Accuracy: 0.859375\n",
      "Batch: 23 Accuracy: 0.921875\n",
      "Batch: 24 Accuracy: 0.90625\n",
      "Batch: 25 Accuracy: 0.9375\n",
      "Batch: 26 Accuracy: 0.9375\n",
      "Batch: 27 Accuracy: 0.9375\n",
      "Batch: 28 Accuracy: 0.84375\n",
      "Batch: 29 Accuracy: 0.953125\n",
      "Batch: 30 Accuracy: 0.90625\n",
      "Batch: 31 Accuracy: 0.90625\n",
      "Batch: 32 Accuracy: 0.90625\n",
      "Batch: 33 Accuracy: 0.953125\n",
      "Batch: 34 Accuracy: 0.9375\n",
      "Batch: 35 Accuracy: 0.9375\n",
      "Batch: 36 Accuracy: 0.90625\n",
      "Batch: 37 Accuracy: 0.9375\n",
      "Batch: 38 Accuracy: 0.90625\n",
      "Batch: 39 Accuracy: 0.953125\n",
      "Batch: 40 Accuracy: 0.921875\n",
      "Batch: 41 Accuracy: 0.9375\n",
      "Batch: 42 Accuracy: 0.859375\n",
      "Batch: 43 Accuracy: 0.859375\n",
      "Batch: 44 Accuracy: 0.9375\n",
      "Batch: 45 Accuracy: 0.9375\n",
      "Batch: 46 Accuracy: 0.890625\n",
      "Batch: 47 Accuracy: 0.9375\n",
      "Batch: 48 Accuracy: 0.953125\n",
      "Batch: 49 Accuracy: 0.921875\n",
      "Batch: 50 Accuracy: 0.90625\n",
      "Batch: 51 Accuracy: 0.953125\n",
      "Batch: 52 Accuracy: 0.96875\n",
      "Batch: 53 Accuracy: 0.859375\n",
      "Batch: 54 Accuracy: 0.921875\n",
      "Batch: 55 Accuracy: 0.953125\n",
      "Batch: 56 Accuracy: 0.9375\n",
      "Batch: 57 Accuracy: 0.9375\n",
      "Batch: 58 Accuracy: 0.859375\n",
      "Batch: 59 Accuracy: 0.90625\n",
      "Batch: 60 Accuracy: 0.921875\n",
      "Batch: 61 Accuracy: 0.96875\n",
      "Batch: 62 Accuracy: 0.890625\n",
      "Batch: 63 Accuracy: 1.0\n",
      "Batch: 64 Accuracy: 0.890625\n",
      "Batch: 65 Accuracy: 0.859375\n",
      "Batch: 66 Accuracy: 0.890625\n",
      "Batch: 67 Accuracy: 0.90625\n",
      "Batch: 68 Accuracy: 0.9375\n",
      "Batch: 69 Accuracy: 0.859375\n",
      "Batch: 70 Accuracy: 0.90625\n",
      "Batch: 71 Accuracy: 0.890625\n",
      "Batch: 72 Accuracy: 0.890625\n",
      "Batch: 73 Accuracy: 0.921875\n",
      "Batch: 74 Accuracy: 0.859375\n",
      "Batch: 75 Accuracy: 0.90625\n",
      "Batch: 76 Accuracy: 0.890625\n",
      "Batch: 77 Accuracy: 0.921875\n",
      "Batch: 78 Accuracy: 0.828125\n",
      "Batch: 79 Accuracy: 0.921875\n",
      "Batch: 80 Accuracy: 0.9375\n",
      "Batch: 81 Accuracy: 0.921875\n",
      "Batch: 82 Accuracy: 0.8125\n",
      "Batch: 83 Accuracy: 0.890625\n",
      "Batch: 84 Accuracy: 0.875\n",
      "Batch: 85 Accuracy: 0.953125\n",
      "Batch: 86 Accuracy: 0.9375\n",
      "Batch: 87 Accuracy: 0.875\n",
      "Batch: 88 Accuracy: 0.9375\n",
      "Batch: 89 Accuracy: 0.859375\n",
      "Batch: 90 Accuracy: 0.953125\n",
      "Batch: 91 Accuracy: 0.875\n",
      "Batch: 92 Accuracy: 0.90625\n",
      "Batch: 93 Accuracy: 0.96875\n",
      "Batch: 94 Accuracy: 0.90625\n",
      "Batch: 95 Accuracy: 0.9375\n",
      "Batch: 96 Accuracy: 0.96875\n",
      "Batch: 97 Accuracy: 0.90625\n",
      "Batch: 98 Accuracy: 0.953125\n",
      "Batch: 99 Accuracy: 0.9375\n",
      "Batch: 100 Accuracy: 0.953125\n",
      "Batch: 101 Accuracy: 0.9375\n",
      "Batch: 102 Accuracy: 0.953125\n",
      "Batch: 103 Accuracy: 0.859375\n",
      "Batch: 104 Accuracy: 0.875\n",
      "Batch: 105 Accuracy: 0.953125\n",
      "Batch: 106 Accuracy: 0.828125\n",
      "Batch: 107 Accuracy: 0.859375\n",
      "Batch: 108 Accuracy: 0.890625\n",
      "Batch: 109 Accuracy: 0.9375\n",
      "Batch: 110 Accuracy: 0.859375\n",
      "Batch: 111 Accuracy: 0.953125\n",
      "Batch: 112 Accuracy: 0.875\n",
      "Batch: 113 Accuracy: 0.9375\n",
      "Batch: 114 Accuracy: 0.890625\n",
      "Batch: 115 Accuracy: 0.921875\n",
      "Batch: 116 Accuracy: 0.921875\n",
      "Batch: 117 Accuracy: 0.90625\n",
      "Batch: 118 Accuracy: 0.890625\n",
      "Batch: 119 Accuracy: 0.9375\n",
      "Batch: 120 Accuracy: 0.875\n",
      "Batch: 121 Accuracy: 0.921875\n",
      "Batch: 122 Accuracy: 0.9375\n",
      "Batch: 123 Accuracy: 0.890625\n",
      "Batch: 124 Accuracy: 0.921875\n",
      "Batch: 125 Accuracy: 0.859375\n",
      "Batch: 126 Accuracy: 0.796875\n",
      "Batch: 127 Accuracy: 0.9375\n",
      "Batch: 128 Accuracy: 0.953125\n",
      "Batch: 129 Accuracy: 0.96875\n",
      "Batch: 130 Accuracy: 0.90625\n",
      "Batch: 131 Accuracy: 0.90625\n",
      "Batch: 132 Accuracy: 0.9375\n",
      "Batch: 133 Accuracy: 0.90625\n",
      "Batch: 134 Accuracy: 0.890625\n",
      "Batch: 135 Accuracy: 0.90625\n",
      "Batch: 136 Accuracy: 0.953125\n",
      "Batch: 137 Accuracy: 0.890625\n",
      "Batch: 138 Accuracy: 0.90625\n",
      "Batch: 139 Accuracy: 0.96875\n",
      "Batch: 140 Accuracy: 0.96875\n",
      "Batch: 141 Accuracy: 0.921875\n",
      "Batch: 142 Accuracy: 0.90625\n",
      "Batch: 143 Accuracy: 0.90625\n",
      "Batch: 144 Accuracy: 0.890625\n",
      "Batch: 145 Accuracy: 0.9375\n",
      "Batch: 146 Accuracy: 0.921875\n",
      "Batch: 147 Accuracy: 0.921875\n",
      "Batch: 148 Accuracy: 0.953125\n",
      "Batch: 149 Accuracy: 0.828125\n",
      "Batch: 150 Accuracy: 0.9375\n",
      "Batch: 151 Accuracy: 0.921875\n",
      "Batch: 152 Accuracy: 0.90625\n",
      "Batch: 153 Accuracy: 0.90625\n",
      "Batch: 154 Accuracy: 0.828125\n",
      "Batch: 155 Accuracy: 0.9375\n",
      "Batch: 156 Accuracy: 0.953125\n",
      "Batch: 157 Accuracy: 0.96875\n",
      "Batch: 158 Accuracy: 0.90625\n",
      "Batch: 159 Accuracy: 0.921875\n",
      "Batch: 160 Accuracy: 0.875\n",
      "Batch: 161 Accuracy: 0.9375\n",
      "Batch: 162 Accuracy: 0.859375\n",
      "Batch: 163 Accuracy: 0.90625\n",
      "Batch: 164 Accuracy: 0.921875\n",
      "Batch: 165 Accuracy: 0.890625\n",
      "Batch: 166 Accuracy: 0.890625\n",
      "Batch: 167 Accuracy: 0.953125\n",
      "Batch: 168 Accuracy: 0.890625\n",
      "Batch: 169 Accuracy: 0.890625\n",
      "Batch: 170 Accuracy: 0.90625\n",
      "Batch: 171 Accuracy: 0.953125\n",
      "Batch: 172 Accuracy: 0.9375\n",
      "Batch: 173 Accuracy: 0.9375\n",
      "Batch: 174 Accuracy: 0.890625\n",
      "Batch: 175 Accuracy: 0.9375\n",
      "Batch: 176 Accuracy: 0.890625\n",
      "Batch: 177 Accuracy: 0.890625\n",
      "Batch: 178 Accuracy: 0.921875\n",
      "Batch: 179 Accuracy: 1.0\n",
      "Batch: 180 Accuracy: 0.875\n",
      "Batch: 181 Accuracy: 0.953125\n",
      "Batch: 182 Accuracy: 0.9375\n",
      "Batch: 183 Accuracy: 0.890625\n",
      "Batch: 184 Accuracy: 0.875\n",
      "Batch: 185 Accuracy: 0.890625\n",
      "Batch: 186 Accuracy: 0.9375\n",
      "Batch: 187 Accuracy: 0.890625\n",
      "Batch: 188 Accuracy: 0.90625\n",
      "Batch: 189 Accuracy: 0.84375\n",
      "Batch: 190 Accuracy: 0.921875\n",
      "Batch: 191 Accuracy: 0.9375\n",
      "Batch: 192 Accuracy: 0.9375\n",
      "Batch: 193 Accuracy: 0.859375\n",
      "Batch: 194 Accuracy: 0.921875\n",
      "Batch: 195 Accuracy: 0.875\n",
      "Batch: 196 Accuracy: 0.90625\n",
      "Batch: 197 Accuracy: 0.875\n",
      "Batch: 198 Accuracy: 0.921875\n",
      "Batch: 199 Accuracy: 0.9375\n",
      "Batch: 200 Accuracy: 0.875\n",
      "Batch: 201 Accuracy: 0.859375\n",
      "Batch: 202 Accuracy: 0.921875\n",
      "Batch: 203 Accuracy: 0.953125\n",
      "Batch: 204 Accuracy: 0.90625\n",
      "Batch: 205 Accuracy: 0.921875\n",
      "Batch: 206 Accuracy: 0.96875\n",
      "Batch: 207 Accuracy: 1.0\n",
      "Batch: 208 Accuracy: 0.875\n",
      "Batch: 209 Accuracy: 0.921875\n",
      "Batch: 210 Accuracy: 0.9375\n",
      "Batch: 211 Accuracy: 0.859375\n",
      "Batch: 212 Accuracy: 0.890625\n",
      "Batch: 213 Accuracy: 0.921875\n",
      "Batch: 214 Accuracy: 0.828125\n",
      "Batch: 215 Accuracy: 0.875\n",
      "Batch: 216 Accuracy: 0.84375\n",
      "Batch: 217 Accuracy: 0.953125\n",
      "Batch: 218 Accuracy: 0.9375\n",
      "Batch: 219 Accuracy: 0.9375\n",
      "Batch: 220 Accuracy: 0.875\n",
      "Batch: 221 Accuracy: 0.90625\n",
      "Batch: 222 Accuracy: 0.90625\n",
      "Batch: 223 Accuracy: 0.890625\n",
      "Batch: 224 Accuracy: 0.890625\n",
      "Batch: 225 Accuracy: 0.921875\n",
      "Batch: 226 Accuracy: 0.921875\n",
      "Batch: 227 Accuracy: 0.953125\n",
      "Batch: 228 Accuracy: 0.921875\n",
      "Batch: 229 Accuracy: 0.875\n",
      "Batch: 230 Accuracy: 0.921875\n",
      "Batch: 231 Accuracy: 0.90625\n",
      "Batch: 232 Accuracy: 0.921875\n",
      "Batch: 233 Accuracy: 0.921875\n",
      "Batch: 234 Accuracy: 0.9375\n",
      "Batch: 235 Accuracy: 0.890625\n",
      "Batch: 236 Accuracy: 0.84375\n",
      "Batch: 237 Accuracy: 0.9375\n",
      "Batch: 238 Accuracy: 0.875\n",
      "Batch: 239 Accuracy: 0.96875\n",
      "Batch: 240 Accuracy: 0.890625\n",
      "Batch: 241 Accuracy: 0.921875\n",
      "Batch: 242 Accuracy: 0.921875\n",
      "Batch: 243 Accuracy: 0.9375\n",
      "Batch: 244 Accuracy: 0.9375\n",
      "Batch: 245 Accuracy: 0.90625\n",
      "Batch: 246 Accuracy: 0.921875\n",
      "Batch: 247 Accuracy: 0.9375\n",
      "Batch: 248 Accuracy: 0.921875\n",
      "Batch: 249 Accuracy: 0.90625\n",
      "Batch: 250 Accuracy: 0.875\n",
      "Batch: 251 Accuracy: 0.921875\n",
      "Batch: 252 Accuracy: 0.921875\n",
      "Batch: 253 Accuracy: 0.875\n",
      "Batch: 254 Accuracy: 0.90625\n",
      "Batch: 255 Accuracy: 0.890625\n",
      "Batch: 256 Accuracy: 0.953125\n",
      "Batch: 257 Accuracy: 0.90625\n",
      "Batch: 258 Accuracy: 0.9375\n",
      "Batch: 259 Accuracy: 0.90625\n",
      "Batch: 260 Accuracy: 0.828125\n",
      "Batch: 261 Accuracy: 0.921875\n",
      "Batch: 262 Accuracy: 0.9375\n",
      "Batch: 263 Accuracy: 0.953125\n",
      "Batch: 264 Accuracy: 0.90625\n",
      "Batch: 265 Accuracy: 0.90625\n",
      "Batch: 266 Accuracy: 0.875\n",
      "Batch: 267 Accuracy: 0.90625\n",
      "Batch: 268 Accuracy: 0.90625\n",
      "Batch: 269 Accuracy: 0.9375\n",
      "Batch: 270 Accuracy: 0.84375\n",
      "Batch: 271 Accuracy: 0.890625\n",
      "Batch: 272 Accuracy: 0.953125\n",
      "Batch: 273 Accuracy: 0.921875\n",
      "Batch: 274 Accuracy: 0.96875\n",
      "Batch: 275 Accuracy: 0.90625\n",
      "Batch: 276 Accuracy: 0.96875\n",
      "Batch: 277 Accuracy: 0.90625\n",
      "Batch: 278 Accuracy: 0.921875\n",
      "Batch: 279 Accuracy: 0.71875\n",
      "Total Accuracy: 0.9117943644523621\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "BATCH_SIZE = 64\n",
    "accuracies = 0\n",
    "for i, position in enumerate(range(0, len(test_data), BATCH_SIZE)):\n",
    "    if (position + BATCH_SIZE > len(test_data)):\n",
    "        batch_data = test_data[position:]\n",
    "        batch_labels = test_labels[position:]\n",
    "    else:\n",
    "        batch_data = test_data[position:position + BATCH_SIZE]\n",
    "        batch_labels = test_labels[position:position + BATCH_SIZE]\n",
    "    \n",
    "    batch_labels = torch.from_numpy(batch_labels).view(-1).long()\n",
    "    \n",
    "    # Forward propagation\n",
    "    forward = net(batch_data)\n",
    "    \n",
    "    accuracy = torch.sum(torch.argmax(forward, dim=1) == batch_labels) / float(BATCH_SIZE)\n",
    "    accuracies += accuracy\n",
    "    print(\"Batch: {}\".format(i + 1), \"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "print(\"Total Accuracy: {}\".format(accuracies / (len(test_data) // BATCH_SIZE + 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './bert_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./models/bert_model.pt'))\n",
    "net.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference():\n",
    "    title1 = input('First title: ')\n",
    "    title2 = input('Second title: ')\n",
    "    \n",
    "    title1 = remove_stop_words(title1)\n",
    "    title2 = remove_stop_words(title2)\n",
    "    \n",
    "    data = np.array([title1, title2]).reshape(1, 2)\n",
    "    forward = net(data)\n",
    "    \n",
    "    print('Output: {}'.format(torch.argmax(forward)))\n",
    "    print('Softmax: {}'.format(forward))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First title: 128 gb ssd\n",
      "Second title: 256 gb ssd\n",
      "Output: 0\n",
      "Softmax: tensor([[-0.0200, -3.9226]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First title: ASUS F512DA-EB51 VivoBook 15 Thin And Light Laptop, 15.6” Full HD, AMD Quad Core R5-3500U CPU, 8GB DDR4 RAM\n",
      "Second title: ASUS F512DA-EB51 VivoBook 15 Thin And Light Laptop, 15.6” Full HD, intel core i7 7700k cpu, 8GB DDR4 RAM\n",
      "Output: 1\n",
      "Softmax: tensor([[-2.4919, -0.0864]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
