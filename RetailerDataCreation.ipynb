{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "sys.path.append(os.getcwd())\n",
    "from src.data_creation.laptop_data_creation import LaptopAttributes, populate_spec\n",
    "from src.preprocessing import unit_matcher, remove_misc\n",
    "from src.common import create_final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(phrase):\n",
    "    '''\n",
    "    Removes the stop words from a string\n",
    "    '''\n",
    "\n",
    "    # Creates the stopwords\n",
    "    to_stop = stopwords.words('english')\n",
    "    punctuation = \"!”#$%&’()*+,-/:;<=>?@[\\]^_`{|}~ \"\n",
    "    for c in punctuation:\n",
    "        to_stop.append(c)\n",
    "    to_stop.append('null')\n",
    "    \n",
    "    for punc in punctuation:\n",
    "        phrase = phrase.replace(punc, ' ')\n",
    "    \n",
    "    return ' '.join((' '.join([x for x in phrase.split(' ') if x not in to_stop])).split()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'17.0', '13.9', '13.3', '13.5', '18.4', '14.1', '15.6', '12.5', '13.0', '15.4', '14.0', '17.3', '10.1', '11.3', '15.0', '11.6', '12.0', '12.3'}\n"
     ]
    }
   ],
   "source": [
    "populate_spec()\n",
    "print(LaptopAttributes.inches)\n",
    "\n",
    "\"\"\"\" Set up sets \"\"\"\n",
    "laptop_brands = {'gateway', 'panasonic', 'toughbook', 'msi'}\n",
    "product_attrs = {'vivobook'}\n",
    "cpu_attributes = {'intel'}\n",
    "\n",
    "for brand in LaptopAttributes.laptop_brands:\n",
    "    laptop_brands.add(brand.split(' ')[0].lower())\n",
    "    product_attrs.add(' '.join(brand.split(' ')[1: ]).lower())\n",
    "\n",
    "intel_cpu_df = pd.read_csv('data/base/intel_cpus.csv')\n",
    "intel_cpu_df = intel_cpu_df['title'].map(lambda x: remove_stop_words(x).split(' '))\n",
    "for i in range(len(intel_cpu_df)):\n",
    "    cpu_attributes.update(intel_cpu_df.iloc[i])\n",
    "\n",
    "amd_cpu_df = pd.read_csv('data/base/amd_cpus.csv')\n",
    "amd_cpu_df = amd_cpu_df['title'].map(lambda x: remove_stop_words(x).split(' '))\n",
    "for i in range(len(amd_cpu_df)):\n",
    "    cpu_attributes.update(amd_cpu_df.iloc[i])\n",
    "\n",
    "laptop_brands = list(laptop_brands)\n",
    "laptop_brands.sort(key=len, reverse=True)\n",
    "\n",
    "product_attrs = list(product_attrs)\n",
    "product_attrs.sort(key=len, reverse=True)\n",
    "\n",
    "cpu_attributes = list(cpu_attributes)\n",
    "cpu_attributes.sort(key=len, reverse=True)\n",
    "\n",
    "cpu_matcher = re.compile(\"\\\\b\" + \"(?!\\S)|\\\\b\".join(cpu_attributes) + \"(?!\\S)\", re.IGNORECASE)\n",
    "brand_matcher = re.compile(\"\\\\b\" + \"(?!\\S)|\\\\b\".join(laptop_brands) + \"(?!\\S)\", re.IGNORECASE)\n",
    "product_attr_matcher = re.compile(\"\\\\b\" + \"(?!\\S)|\\\\b\".join(product_attrs) + \"(?!\\S)\", re.IGNORECASE)\n",
    "gb_matcher = unit_matcher('gb')\n",
    "tb_matcher = unit_matcher('tb')\n",
    "#inch_matcher = re.compile('[1][0-9]\\\"?\"? [0-9]?\\\"?\"?(?!\\S)', re.IGNORECASE)\n",
    "inch_matcher = re.compile('[1][0-9]\\\"?\"?\\.?[0-9]?\\\"?\"?(?!\\S)', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  title\n",
       "0     hp 2021 premium 14\" hd touchscreen laptop comp...\n",
       "1     2021 newest asus tuf gaming laptop 15.6\" ips f...\n",
       "2     acer aspire 5 slim laptop 15.6 inches full hd ...\n",
       "3     hp chromebook 11 inch laptop up 15 hour batter...\n",
       "4     hp chromebook 14 inch hd laptop intel celeron ...\n",
       "...                                                 ...\n",
       "3614  lenovo thinkpad p71 workstation laptop windows...\n",
       "3615  lenovo thinkpad t480s windows 10 pro laptop in...\n",
       "3616  newest dell inspiron 5000 15.6\" touchscreen le...\n",
       "3617  lenovo thinkpad p71 workstation laptop windows...\n",
       "3618  lenovo thinkpad t490s laptop 14.0\" fhd ips 250...\n",
       "\n",
       "[4088 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hp 2021 premium 14\" hd touchscreen laptop comp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021 newest asus tuf gaming laptop 15.6\" ips f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>acer aspire 5 slim laptop 15.6 inches full hd ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hp chromebook 11 inch laptop up 15 hour batter...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hp chromebook 14 inch hd laptop intel celeron ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3614</th>\n      <td>lenovo thinkpad p71 workstation laptop windows...</td>\n    </tr>\n    <tr>\n      <th>3615</th>\n      <td>lenovo thinkpad t480s windows 10 pro laptop in...</td>\n    </tr>\n    <tr>\n      <th>3616</th>\n      <td>newest dell inspiron 5000 15.6\" touchscreen le...</td>\n    </tr>\n    <tr>\n      <th>3617</th>\n      <td>lenovo thinkpad p71 workstation laptop windows...</td>\n    </tr>\n    <tr>\n      <th>3618</th>\n      <td>lenovo thinkpad t490s laptop 14.0\" fhd ips 250...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4088 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 226
    }
   ],
   "source": [
    "amazon_laptops = pd.read_csv('data/base/amazon_laptop_titles.csv')\n",
    "walmart_laptops = pd.read_csv('data/base/walmart_laptop_titles.csv')\n",
    "newegg_laptops = pd.read_csv('data/base/newegg_laptop_titles.csv')\n",
    "\n",
    "laptops = remove_misc(pd.concat([amazon_laptops, walmart_laptops, newegg_laptops]))\n",
    "laptops['title'] = laptops['title'].apply(lambda x: remove_stop_words(x))\n",
    "laptops = laptops.drop_duplicates(subset=['title'])\n",
    "laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = remove_stop_words('\"Acer Predator Helios 300 15.6\"\" Gaming Laptop i7-10750H 16GB DDR4 1TB SSD\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"acer predator helios 300 15.6\"\" gaming laptop i7 10750h 16gb ddr4 1tb ssd\"'"
      ]
     },
     "metadata": {},
     "execution_count": 228
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['acer']"
      ]
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "source": [
    "brand_matcher.findall(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['predator']"
      ]
     },
     "metadata": {},
     "execution_count": 230
    }
   ],
   "source": [
    "product_attr_matcher.findall(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['15.6\"\"']"
      ]
     },
     "metadata": {},
     "execution_count": 231
    }
   ],
   "source": [
    "inch_matcher.findall(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['i7', '10750h']"
      ]
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "source": [
    "cpu_matcher.findall(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[' 16gb']"
      ]
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "source": [
    "gb_matcher.findall(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[' 1tb']"
      ]
     },
     "metadata": {},
     "execution_count": 234
    }
   ],
   "source": [
    "tb_matcher.findall(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_laptop_data(df):\n",
    "    MAX_POS_TITLES = 5\n",
    "    temp = []\n",
    "    for title in df['title']:\n",
    "        # Get each major attribute of a laptop\n",
    "        brand = brand_matcher.findall(title)\n",
    "        product_attr = product_attr_matcher.findall(title)\n",
    "        inch = inch_matcher.findall(title)\n",
    "        cpu = cpu_matcher.findall(title)\n",
    "        gb = gb_matcher.findall(title)\n",
    "        tb = tb_matcher.findall(title)\n",
    "\n",
    "        # Make sure the product is actually a laptop\n",
    "        if gb == [] and tb == []:\n",
    "            continue\n",
    "        \n",
    "        # Create a \"simple\" version of the title using only the major attributes\n",
    "        shuffle = [cpu, gb, tb]\n",
    "        random.shuffle(shuffle)\n",
    "        pos_title1 = brand + product_attr + inch + shuffle[0] + shuffle[1] + shuffle[2]\n",
    "        \n",
    "        # Get all of the filler words (words that are not major attributes)\n",
    "        orig_title = title.split(' ')\n",
    "        filler_tokens = []\n",
    "        for i, token in enumerate(orig_title):\n",
    "            if token not in pos_title1:\n",
    "                filler_tokens.append(token)\n",
    "        \n",
    "        # Generate a list of titles that do not have filler words\n",
    "        new_titles = []\n",
    "        new_title = orig_title.copy()\n",
    "        while True:\n",
    "            if (len(filler_tokens) > 1):\n",
    "                filler = random.choice(filler_tokens)\n",
    "                new_title.remove(filler)\n",
    "                filler_tokens.remove(filler)\n",
    "                new_titles.append(' '.join(new_title))\n",
    "            else:\n",
    "                break \n",
    "        \n",
    "        # Choose how many combos we're going to have\n",
    "        amt_new_titles = MAX_POS_TITLES\n",
    "        if (len(new_titles) < MAX_POS_TITLES):\n",
    "            amt_new_titles = len(new_titles)\n",
    "        \n",
    "        temp.append([title, ' '.join(pos_title1), 1])\n",
    "        for x in range(amt_new_titles):\n",
    "            if len(new_titles) - MAX_POS_TITLES > 0:\n",
    "                pos = random.choice(new_titles[len(new_titles) - MAX_POS_TITLES - random.randint(0, len(new_titles) - MAX_POS_TITLES):])\n",
    "            else:\n",
    "                pos = random.choice(new_titles[len(new_titles) - MAX_POS_TITLES:])\n",
    "            temp.append([title, pos, 1])\n",
    "            new_titles.remove(pos)\n",
    "        \n",
    "    return pd.DataFrame(temp, columns=['title_one', 'title_two', 'label'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_titles = create_pos_laptop_data(laptops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_titles = pos_titles.drop_duplicates(subset=['title_two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}